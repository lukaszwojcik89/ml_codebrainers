{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1154e1e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#  Konwolucyjne sieci neuronowe (Convolutional Neural Network - CNN)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26da17ff",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "## Convolutional Neural Networks (CNN) – Szczegółowe Omówienie\n",
    "\n",
    "- Konwolucyjne sieci neuronowe (CNN) stanowią fundament współczesnej wizji komputerowej i przetwarzania obrazów.\n",
    "- CNN zastępują tradycyjne warstwy gęste (fully-connected) warstwami konwolucyjnymi, co pozwala sieci uczyć się hierarchii cech wizualnych bez ręcznej inżynierii.\n",
    "- CNN wykorzystują operacje konwolucyjne i filtry (kernels), które analizują lokalne fragmenty obrazu, wykrywając wzorce takie jak krawędzie, linie, tekstury i kształty.\n",
    "- Hierarchia cech: dolne warstwy rozpoznają proste wzorce, wyższe łączą je w bardziej złożone struktury, pozwalając na rozpoznawanie złożonych obiektów.\n",
    "- Dzięki translacyjnej niezmienności wzorców, CNN są odporne na przesunięcia czy drobne modyfikacje obrazu.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2c0f9d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![Untitled](https://i.ibb.co/3N7DQ9q/Untitled-11.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bcbb4b2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## **Warstwy konwolucyjne**\n",
    "\n",
    "- Konwolucyjne sieci neuronowe składają się z kilku warstw, z których najważniejsze są warstwy konwolucyjne.\n",
    "- Warstwy konwolucyjne wykorzystują operację konwolucji, która pozwala na ekstrakcję cech z obrazów.\n",
    "- Operacja konwolucji polega na przesuwaniu filtra po obrazie i obliczaniu iloczynów skalarnych między elementami filtra i obrazu.\n",
    "- Wynik operacji konwolucji jest mapą cech, która może być dalej przetwarzana przez kolejne warstwy sieci.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0117ca66",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## **Operacja konwolucji**\n",
    "\n",
    "- Operacja konwolucji pozwala na ekstrakcję cech z obrazów i jest kluczowa dla konwolucyjnych sieci neuronowych (CNN).\n",
    "- Operacja konwolucji wykorzystuje filtry, które są przesuwane po obrazie, a każdy element filtra jest mnożony przez piksel obrazu.\n",
    "- Operacja konwolucji prowadzi do utworzenia map cech, które następnie mogą być przetwarzane przez kolejne warstwy sieci.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92021ac0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "[https://miro.medium.com/v2/resize:fit:1052/0*jLoqqFsO-52KHTn9.gif](https://miro.medium.com/v2/resize:fit:1052/0*jLoqqFsO-52KHTn9.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d4f862",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "[Convolutional Neural Network Visualization by Otavio Good - YouTube](https://www.youtube.com/watch?v=f0t-OCG79-U)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1493cb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![Untitled](https://i.ibb.co/CQGCxmp/Untitled-12.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84bfe0c4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "## **Filtry/Kernele**\n",
    "\n",
    "- Filtry (kernel) to macierze wag, które są przesuwane po obrazie w operacji konwolucji.\n",
    "- Filtry pozwalają na wykrywanie cech w obrazach, takich jak krawędzie, linie, tekstury i kształty.\n",
    "- Filtry są trenowane w procesie uczenia, aby znaleźć najlepsze wagi, które pozwalają na wykrycie istotnych cech.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1f346f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "## **Dlaczego stosujemy padding?**\n",
    "\n",
    "- Padding to technika polegająca na dodaniu zerowych pikseli wokół obrazu wejściowego, aby zwiększyć wymiar obrazu.\n",
    "- Padding jest stosowany, aby zachować rozmiar obrazu po przeprowadzeniu operacji konwolucji.\n",
    "- Bez paddingu, rozmiar obrazu może zmniejszać się wraz z każdą warstwą konwolucyjną, co może prowadzić do utraty informacji i utrudnienia uczenia."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fffd10a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## **Rodzaje paddingu**\n",
    "\n",
    "- Padding może być dodawany do krawędzi obrazu na różne sposoby, w zależności od zastosowania.\n",
    "- Zero padding to najczęściej stosowany rodzaj paddingu, w którym piksele wokół obrazu są uzupełniane zerami.\n",
    "- Valid padding, nazywany też 'no padding', oznacza brak dodatkowych pikseli wokół obrazu i prowadzi do zmniejszenia rozmiaru obrazu.\n",
    "- Same padding oznacza, że piksele wokół obrazu są uzupełniane w taki sposób, aby zachować rozmiar obrazu.\n",
    "    \n",
    "    ![Untitled](https://i.ibb.co/Rpnhtjn/Untitled-13.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb7b0ae",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## **Co to jest Stride?**\n",
    "\n",
    "- Stride to odstęp między kolejnymi pozycjami filtra podczas przesuwania po obrazie.\n",
    "- Stride wpływa na rozmiar mapy cech wyjściowych z warstwy konwolucyjnej.\n",
    "- Większy stride oznacza mniejszą liczbę pozycji filtra na obrazie i prowadzi do zmniejszenia rozmiaru mapy cech wyjściowych.\n",
    "\n",
    "![Untitled](https://i0.wp.com/www.brilliantcode.net/wp-content/uploads/2019/08/CNN_Tutorial_stride.png?resize=800%2C713&ssl=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff58a23",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## **Warstwy grupujące**\n",
    "\n",
    "- Warstwy grupujące, zwane też warstwami pooling, służą do zmniejszania wymiarowości danych.\n",
    "- Najczęściej stosowaną operacją w warstwach grupujących jest operacja maksymalizacji (max pooling), która wybiera maksymalną wartość z danego regionu.\n",
    "- W Max Pooling, największy element jest brany z mapy cech. Średnie wartości są obliczane w Average Pooling dla elementów znajdujących się w zdefiniowanym obszarze obrazu. Całkowita suma elementów w zdefiniowanym obszarze jest obliczana w Sum Pooling.\n",
    "- Warstwa Pooling zazwyczaj służy jako połączenie między warstwą konwolucyjną a warstwą FC.\n",
    "- Warstwy grupujące pomagają zwiększyć odporność sieci na przesunięcia, zmiany skali i inne transformacje obrazu.\n",
    "\n",
    "![Untitled](https://i.ibb.co/dKyjVhF/Untitled-15.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e17f37",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## **Warstwy gęste**\n",
    "\n",
    "- Warstwy gęste (fully connected layers) są końcową częścią konwolucyjnych sieci neuronowych i służą do klasyfikacji lub regresji.\n",
    "- W warstwach gęstych każdy neuron jest połączony z każdym neuronem z poprzedniej warstwy.\n",
    "- Warstwy gęste służą do mapowania wejściowego sygnału na wektor wyjściowy o odpowiedniej liczbie wymiarów."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9ced17",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## **Activation Functions**\n",
    "\n",
    "- Jednym z najważniejszych parametrów modelu CNN jest funkcja aktywacji.\n",
    "- Służy ona do uczenia i przybliżania różnych ciągłych i złożonych zależności między zmiennymi w sieci.\n",
    "- W prostych słowach, decyduje ona, które informacje z modelu powinny zostać aktywowane w kierunku przodu, a które nie na końcu sieci.\n",
    "- Funkcja aktywacji wprowadza nieliniowość do sieci.\n",
    "- Istnieje kilka powszechnie stosowanych funkcji aktywacji, takich jak ReLU, Softmax, tanH i funkcje Sigmoid.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba2814a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![Untitled](https://i.ibb.co/vBFD2zw/Untitled-16.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78ac855",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Każda z tych funkcji ma specyficzne zastosowanie.\n",
    "- Dla modelu CNN klasyfikacji binarnej preferowane są funkcje sigmoidalne i softmax, a dla klasyfikacji wieloklasowej zazwyczaj stosuje się softmax.\n",
    "- W prostych słowach, funkcje aktywacji w modelu CNN decydują, czy neuron powinien być aktywowany czy nie.\n",
    "- To określa, czy dane wejściowe są istotne, czy nie, dla przewidywania za pomocą operacji matematycznych.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2249000",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## **Standardowa sieć CNN składa się z następujących warstw CNN**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b002de1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![Untitled](https://i.ibb.co/yh6wXYn/Untitled-17.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32cb2c52",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Wejściowy obraz poddawany jest wielu filtrom, aby wygenerować różne mapy cech.\n",
    "- Każda mapa cech o wymiarze (C, C) jest następnie łączona, tworząc wyjście o wymiarze (C/2, C/2) (dla standardowego łączenia 2×2).\n",
    "- Powyższy wzór nazywa się warstwą neuronową konwolucyjną lub jednostką. Wiele takich warstw CNN jest umieszczanych na siebie, tworząc głębokie sieci neuronowe konwolucyjne.\n",
    "- Wyjście z warstwy splotowej zawiera cechy, które są wprowadzane do gęstej sieci neuronowej.."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e442461",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Regularyzacja i stabilizacja treningu w CNN\n",
    "\n",
    "### Regularyzacja i Stabilizacja Treningu\n",
    "\n",
    "- Głębokie sieci (w tym CNN) mają miliony parametrów, podatne na overfitting.\n",
    "- Techniki regularyzacji:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa49a746",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "  - L1/L2 regularyzacje penalizują duże wartości wag\n",
    "![Untitled](https://i.ibb.co/g4fc8cN/Untitled-2.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b637eaf7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "  - Dropout losowo wyłącza neurony, wymuszając bardziej zróżnicowane i odporne reprezentacje\n",
    "![Untitled](https://i.ibb.co/HnwzL9h/Untitled-4.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef32113",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## **Dodawanie Dropout**\n",
    "\n",
    "W Kerasie argument `rate` definiuje procent jednostek wejściowych do wyłączenia. Warstwę `Dropout` umieszczamy tuż przed warstwą, do której chcemy zastosować Dropout:\n",
    "\n",
    "```python\n",
    "keras.Sequential([\n",
    "    # ...\n",
    "    layers.Dropout(rate=0.3), # zastosuj 30% dropout do następnej warstwy\n",
    "    layers.Dense(16),\n",
    "    # ...\n",
    "])\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41fb5136",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "\n",
    "### **Batch Normalization**\n",
    "\n",
    "- Batch Normalization to technika, która normalizuje wejście do każdej warstwy sieci.\n",
    "- Normalizacja wsadowa może poprawić skuteczność uczenia się, ponieważ zapobiega zanikaniu lub eksplodowaniu gradientu i przyspiesza proces uczenia się.\n",
    "\n",
    "![Untitled](https://i.ibb.co/MfbXDVm/Untitled-5.png)\n",
    "\n",
    "\n",
    "## **Dodawanie normalizacji wsadowej**\n",
    "\n",
    "Wygląda na to, że Batch Normalization może być stosowana niemal w dowolnym miejscu w sieci. Można ją umieścić po warstwie...\n",
    "\n",
    "```\n",
    "layers.Dense(16, activation='relu'),\n",
    "layers.BatchNormalization(),\n",
    "\n",
    "```\n",
    "\n",
    "... lub między warstwą a jej funkcją aktywacji:\n",
    "\n",
    "```\n",
    "layers.Dense(16),\n",
    "layers.BatchNormalization(),\n",
    "layers.Activation('relu'),\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41cf0252",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#  Data Augmentation – sztuczne wzbogacanie zbioru treningowego\n",
    "\n",
    "### Data Augmentation\n",
    "\n",
    "- Data Augmentation zwiększa różnorodność danych treningowych, poprawiając zdolność modelu do generalizacji.\n",
    "- Techniki augmentacji:\n",
    "  - Obrót, przesunięcie, zmiana skali, odbicie lustrzane\n",
    "  - Zmiany jasności, kontrastu, dodawanie szumu\n",
    "- Dzięki augmentacji model widzi więcej wariantów obiektów, staje się odporniejszy na zmiany w danych wejściowych i redukuje ryzyko overfittingu.\n",
    "- Jest standardowym elementem workflow w projektach wizji komputerowej.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6be0f4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![Untitled](https://i.ibb.co/pWngtvh/Untitled-6.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92c8164",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Podsumowanie koncepcji CNN \n",
    "\n",
    "- CNN umożliwiają automatyczną ekstrakcję cech z obrazów:\n",
    "  - Konwolucje i filtry: detekcja wzorców\n",
    "  - Pooling: redukcja wymiarowości i odporność na przesunięcia\n",
    "  - Regularyzacja (Dropout, BN, L1/L2) i augmentacja danych dla lepszej generalizacji\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8cb175",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
