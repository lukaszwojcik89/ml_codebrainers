{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27a49adc",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Transfer Learning&#x20;\n",
    "\n",
    "&#x20;\n",
    "\n",
    "## Wprowadzenie teoretyczne do transfer learningu\n",
    "\n",
    "Uczenie transferowe (**Transfer Learning**) to technika uczenia maszynowego polegająca na wykorzystaniu wiedzy zdobytej podczas rozwiązywania jednego zadania do przyspieszenia i ułatwienia uczenia modelu na innym, **powiązanym zadaniu**. Zamiast trenować sieć neuronową od zera dla nowego problemu, możemy **przenieść** wiedzę (parametry modelu) z wcześniej wytrenowanego modelu na nowy model. Dzięki temu:\n",
    "\n",
    "* **Szybsze trenowanie:** Model zaczyna z lepszymi parametrami początkowymi, co skraca czas potrzebny do osiągnięcia wysokiej skuteczności.\n",
    "* **Mniej danych:** Wymagane jest mniej danych treningowych, ponieważ model **zna już** wiele przydatnych reprezentacji (cech) z poprzedniego zadania.\n",
    "* **Lepsza skuteczność:** Często uzyskujemy wyższą dokładność, szczególnie gdy zbiór danych dla nowego zadania jest niewielki. Pretrenowane modele nabyły już umiejętność rozpoznawania ogólnych wzorców, co poprawia wyniki na nowym zadaniu."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b7a005",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "![What Is Transfer Learning? \\[Examples & Newbie-Friendly Guide\\]](https://framerusercontent.com/images/7INIdkIR6fGLVB3OKx3SACpwkI.png \"What Is Transfer Learning? \\[Examples & Newbie-Friendly Guide]\")\n",
    "\n",
    "**Przykład:** Wyobraź sobie model sieci neuronowej nauczony rozpoznawać tysiące kategorii obrazów (np. na zbiorze ImageNet, który zawiera 1,2 miliona obrazów w 1000 kategoriach). Taki model nauczył się w pierwszych warstwach wykrywać bardzo **ogólne cechy** obrazów, takie jak krawędzie, tekstury czy proste kształty. W kolejnych warstwach łączy te proste cechy w bardziej złożone (np. fragmenty obiektów), a w ostatnich warstwach rozpoznaje specyficzne elementy odpowiadające klasom, na których był trenowany. Jeśli teraz chcemy zbudować model do rozpoznawania np. gatunków kwiatów, możemy wykorzystać **wiedzę** z modelu wytrenowanego na ImageNet. W praktyce oznacza to, że większość warstw takiego modelu wykorzystamy bez zmian (bo **umieją** już rozpoznawać ogólne wzorce na obrazach), a tylko ostatnią warstwę (odpowiedzialną za klasyfikację na oryginalne 1000 klas) zastąpimy nową warstwą wyjściową dostosowaną do rozpoznawania naszych gatunków kwiatów. W ten sposób **transferujemy** wiedzę z zadania rozpoznawania ogólnych obiektów do zadania rozpoznawania kwiatów."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9c4bce",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "\n",
    "<br />\n",
    "\n",
    "Transfer learning jest szeroko stosowany nie tylko w rozpoznawaniu obrazów, ale także w innych dziedzinach **Data Science**. W przetwarzaniu języka naturalnego modele językowe (np. BERT, GPT) wytrenowane na ogromnych korpusach tekstu są następnie dostrajane do konkretnych zadań (np. analiza sentymentu, odpowiadanie na pytania). W dziedzinie rozpoznawania mowy modele akustyczne wytrenowane na dużych zbiorach danych mogą być adaptowane do nowych języków lub akcentów. We wszystkich tych przypadkach idea jest podobna: wykorzystać istniejącą wiedzę modelu, zamiast zaczynać od zupełnie losowych parametrów.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4565ff66",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "![The Illustrated BERT, ELMo, and co. (How NLP Cracked Transfer Learning) –  Jay Alammar – Visualizing machine learning one concept at a time.](https://jalammar.github.io/images/bert-transfer-learning.png \"The Illustrated BERT, ELMo, and co. (How NLP Cracked Transfer Learning) –  Jay Alammar – Visualizing machine learning one concept at a time.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b426614e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "\n",
    "![Chapter 7 Transfer Learning for NLP I | Modern Approaches in Natural  Language Processing](https://slds-lmu.github.io/seminar_nlp_ss20/figures/02-01-transfer-learning-for-nlp-1/sequential-transfer-learning-gpt.PNG \"Chapter 7 Transfer Learning for NLP I | Modern Approaches in Natural  Language Processing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3bfc39",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "<br />\n",
    "\n",
    "**Kiedy Transfer Learning jest szczególnie przydatny?** Gdy mamy ograniczoną ilość danych dla nowego zadania lub trenowanie od zera byłoby zbyt czasochłonne lub kosztowne. Zamiast zbierać setki tysięcy danych i trenować model przez wiele godzin/dni, możemy użyć modelu pretrenowanego na podobnym zadaniu i dostosować go do naszego problemu. W praktyce, transfer learning pozwala osiągnąć dobre wyniki nawet na małych zbiorach danych – coś, co byłoby bardzo trudne przy trenowaniu modelu od podstaw (tzw. **from scratch**)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff8f244",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Warto jednak pamiętać, że transfer learning najlepiej sprawdza się, gdy **zadanie źródłowe** (to, na którym model został pierwotnie wytrenowany) i **zadanie docelowe** (to, na którym go użyjemy) są stosunkowo zbliżone. Jeśli różnica między zadaniami jest zbyt duża (np. model trenowany na zdjęciach zwierząt użyty do analizy zdjęć medycznych rentgenowskich), to przenoszona wiedza może okazać się mało przydatna lub wymagać głębszego dostrojenia modelu."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca300dfa",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "\n",
    "\n",
    "## Kluczowe pojęcia w transfer learningu\n",
    "\n",
    "W transfer learningu pojawia się kilka kluczowych pojęć i strategii, które należy zrozumieć:\n",
    "\n",
    "* **Model pretrenowany:** Jest to model już **wcześniej wytrenowany** na dużym zbiorze danych do jakiegoś zadania. Przykładem może być sieć **ResNet50** wytrenowana na ImageNet (rozpoznawanie 1000 klas obrazów) lub model **BERT** wytrenowany na zadaniu maskowania wyrazów w ogromnym zbiorze tekstów. Taki model posiada już wagi (parametry), które zawierają *wiedzę* zdobytą podczas tego wcześniejszego treningu. W transfer learningu wykorzystujemy te wagi jako punkt wyjścia dla nowego zadania, zamiast inicjalizować model losowo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e497c0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "* **Ekstrakcja cech (feature extraction):** Strategia, w której używamy modelu pretrenowanego jako **ekstraktora cech**. Polega ona na **zamrożeniu** (ang. *freeze*) wszystkich (lub większości) warstw pretrenowanego modelu, tak aby ich wagi **nie ulegały zmianie** podczas trenowania na nowym zadaniu. Następnie do tak *zamrożonego* modelu dodajemy jedynie nową warstwę (lub kilka warstw) wyjściową dostosowaną do naszego zadania i trenujemy **tylko te nowe warstwy**. W praktyce model działa wtedy tak: obraz (lub inny sygnał) przechodzi przez sieć pretrenowaną, która wylicza **wysokopoziomowe cechy** (feature'y) tego obrazu, a nowo dodana warstwa na końcu przekształca te cechy na przewidywaną klasę (lub inną pożądaną odpowiedź). Ten sposób wykorzystuje fakt, że **pierwsze warstwy sieci uczą się bardzo ogólnych cech**, przydatnych w wielu zadaniach. Ekstrakcja cech jest szczególnie przydatna, gdy mamy **bardzo mało danych** – ograniczamy wtedy liczbę parametrów, które muszą się nauczyć (uczymy tylko ostatnią warstwę), co zmniejsza ryzyko przeuczenia."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dde1d26",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "* **Fine-tuning (dostrajanie modelu):** Strategia, w której **dodatkowo trenujemy (dostrajamy)** część (lub wszystkie) warstwy modelu pretrenowanego na nowym zadaniu. Zazwyczaj fine-tuning wykonuje się **po uprzednim** etapie ekstrakcji cech. To znaczy, najpierw dodajemy nową warstwę wyjściową i trenujemy ją, trzymając resztę sieci zamrożoną (to pozwala sieci nauczyć się wstępnie dostosowanych wag na nowy problem). Następnie **odmrażamy** niektóre z wyższych (bliżej wyjścia) warstw oryginalnego modelu i trenujemy ponownie całość (lub część warstw) przy **bardzo niskiej szybkości uczenia (learning rate)**. Fine-tuning pozwala modelowi **delikatnie dostosować** wcześniej nauczone cechy do specyfiki nowego zadania. Ważne jest, by nie użyć zbyt wysokiej stopy uczenia – w przeciwnym razie istnieje ryzyko \"nadpisania\" (utracenia) wcześniej wyuczonej wiedzy. Zwykle fine-tuning stosujemy, gdy nowy zbiór danych jest w miarę duży lub zadanie jest dostatecznie podobne do oryginalnego – wówczas **dodatkowe dostrajanie** może poprawić wyniki ponad to, co uzyskaliśmy przy samej ekstrakcji cech."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85805652",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "* **Zamrażanie i odmrażanie warstw:** \"Zamrozić\" warstwy znaczy ustawić je jako nieuczony (niezmienne) podczas trenowania – w praktyce w frameworkach oznacza to ustawienie atrybutu, który sprawia, że optymalizator nie będzie aktualizował wag tych warstw. \"Odmrozić\" to ponownie zezwolić na uczenie (aktualizację wag) wybranych warstw. Typowym podejściem jest zamrożenie **wszystkich** warstw modelu bazowego podczas trenowania nowej warstwy wyjściowej, a następnie odmrożenie **ostatnich kilku** warstw modelu bazowego i kontynuacja trenowania (fine-tuning). Ilość odmrażanych warstw zależy od wielkości i podobieństwa nowego zbioru danych – można np. odmrozić tylko ostatni **blok** sieci (np. ostatnie 2-3 warstwy konwolucyjne), pozostawiając resztę zamrożoną.\n",
    "* ![Transfer learning. Concepts: | by Saba Hesaraki | Medium](https://miro.medium.com/v2/resize:fit:1200/1*rInXt5nkZfPL7H95pS5QPA.jpeg \"Transfer learning. Concepts: | by Saba Hesaraki | Medium\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07aa81a8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "\n",
    "\n",
    "Podsumowując, **transfer learning** w praktyce sprowadza się do dwóch głównych etapów:\n",
    "\n",
    "1. **Wykorzystanie modelu pretrenowanego jako bazowego:** Wczytujemy model z wytrenowanymi wagami i wykorzystujemy jego strukturę oraz *wiedzę*. Dodajemy na końcu nową warstwę/warstwy dopasowane do naszego zadania (np. warstwa klasyfikująca określoną liczbę nowych klas).\n",
    "2. **Trenowanie modelu w nowym zadaniu:** Możemy najpierw trenować tylko nowe warstwy (feature extraction), a następnie ewentualnie trenować wspólnie część starych i nowych warstw (fine-tuning) dla lepszego dostosowania.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dacadb4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "\n",
    "\n",
    "W kolejnej sekcji zobaczymy **praktyczny przykład** ilustrujący powyższe pojęcia z użyciem kodu w Pythonie (biblioteka TensorFlow/Keras)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e8595c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "\n",
    "## Transfer learning z użyciem modelu pretrenowanego\n",
    "\n",
    "W tym przykładzie pokażemy, jak skorzystać z pretrenowanego modelu sieci konwolucyjnej do zbudowania nowego modelu rozwiązującego inne zadanie. Posłużymy się biblioteką **TensorFlow 2.x** z interfejsem **Keras** (wysokopoziomowe API do budowy i trenowania sieci neuronowych). Podobne kroki można zrealizować w PyTorch – idee są analogiczne, ale składnia jest nieco inna.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f463509",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "Załóżmy następujący scenariusz: Mamy nowy problem klasyfikacji obrazów z, powiedzmy, 5 klasami (np. chcemy rozpoznawać 5 gatunków kwiatów). Dysponujemy jednak ograniczoną liczbą obrazów treningowych dla tych klas. Wykorzystamy model **MobileNetV2** pretrenowany na ImageNet jako bazę. MobileNetV2 to względnie lekka sieć konwolucyjna, która była trenowana do klasyfikacji obrazów na 1000 klas z ImageNet – w efekcie nauczyła się wielu przydatnych reprezentacji wizualnych. Nasz plan:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60f0837",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "\n",
    "\n",
    "1. **Wczytać model MobileNetV2 z pretrenowanymi wagami** (bez ostatniej warstwy, bo oryginalnie służyła do 1000-klasowej klasyfikacji).\n",
    "2. **Zamrozić** wszystkie jego warstwy, aby podczas wstępnego trenowania nowego modelu te wagi się nie zmieniały.\n",
    "3. **Dodać nowe warstwy** na wyjściu – w szczególności warstwę, która będzie przewidywać 5 klas (w naszym hipotetycznym zadaniu).\n",
    "4. **Skompilować model** (ustalić funkcję straty, optymalizator, metryki) i przeprowadzić **trening** nowej warstwy wyjściowej na naszym zbiorze danych.\n",
    "5. (Opcjonalnie) **Fine-tuning:** Odmrozić część warstw bazowego modelu i dalej trenować całość bardzo wolno, aby nieznacznie poprawić jakość modelu dostosowując wcześniej nauczone cechy do naszych danych."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e432737",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "\n",
    "Poniżej znajduje się kod realizujący te kroki, wraz z objaśnieniami:\n",
    "\n",
    "### 1. Wczytanie modelu bazowego i zamrożenie jego warstw (Feature Extraction)\n",
    "\n",
    "Najpierw zaimportujemy potrzebne biblioteki i wczytamy pretrenowany model. Użyjemy `tf.keras.applications.MobileNetV2` z wagami z ImageNet. Ustawimy `include_top=False`, aby pominąć oryginalną warstwę klasyfikacyjną (tzw. top) modelu, ponieważ i tak chcemy zastąpić ją własną. Zdefiniujemy też `input_shape=(224, 224, 3)`, bo takie wejście oczekuje MobileNetV2 (obrazy 224x224 z 3 kanałami koloru). Następnie *zamrozimy* model bazowy (`base_model.trainable = False`), aby jego wagi nie ulegały zmianie podczas trenowania nowej warstwy wyjściowej."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11507d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# 1. Wczytujemy pretrenowany model MobileNetV2 (bez oryginalnej warstwy klasyfikującej).\n",
    "base_model = tf.keras.applications.MobileNetV2(weights='imagenet',\n",
    "                                              include_top=False,\n",
    "                                              input_shape=(224, 224, 3))\n",
    "# 2. Zamrażamy wszystkie warstwy modelu bazowego, aby nie były trenowane.\n",
    "base_model.trainable = False\n",
    "\n",
    "# Sprawdźmy dla pewności, ile warstw ma model bazowy i czy są zamrożone:\n",
    "print(f\"Liczba warstw w modelu bazowym: {len(base_model.layers)}\")\n",
    "print(f\"Czy pierwsza warstwa jest trenowalna? {base_model.layers[0].trainable}\")\n",
    "print(f\"Czy ostatnia warstwa jest trenowalna? {base_model.layers[-1].trainable}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19042bb9",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "* `tf.keras.applications.MobileNetV2(...)` zwraca nam obiekt modelu Keras z załadowanymi wagami wytrenowanymi na ImageNet. Parametr `include_top=False` oznacza, że **nie dołączamy** ostatniej warstwy w pełni połączonej (Dense), odpowiedzialnej za 1000 klas w ImageNet. W ten sposób model `base_model` będzie zwracał **mapy cech (feature maps)** z ostatniej warstwy konwolucyjnej, które my wykorzystamy.\n",
    "* `base_model.trainable = False` ustawia cały model bazowy jako nie-trenowalny. W Keras oznacza to, że żadna z jego wag nie będzie aktualizowana podczas treningu (model zachowa umiejętności zdobyte na ImageNet).\n",
    "* Wydruk kontroli (`print`) ma pokazać, ile warstw ma model bazowy i czy pierwsza oraz ostatnia z tych warstw są trenowalne. Dla zamrożonego modelu oczekujemy, że zwróci `False` (nie trenowalna) dla tych warstw. (Pierwsza warstwa to zwykle warstwa wejściowa lub pierwsza konwolucyjna, ostatnia to ostatnia konwolucyjna / pooling z MobileNetV2)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6055c0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "\n",
    "**Uwaga:** Modele z `tf.keras.applications` często wymagają wstępnego przetwarzania danych wejściowych w taki sam sposób, w jaki były trenowane. Dla MobileNetV2 wejścia powinny być skalowane do przedziału \\[-1, 1] (zamiast typowego \\[0, 255] dla pikseli). TensorFlow udostępnia funkcję `tf.keras.applications.mobilenet_v2.preprocess_input`, którą należałoby zastosować do naszych obrazów przed podaniem ich do modelu. W naszym pseudokodzie pominiemy szczegóły wczytywania i przetwarzania obrazów, ale warto pamiętać o tej kwestii podczas praktycznej realizacji."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45bf89b1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### 2. Dodanie nowej warstwy klasyfikującej (tzw. \"głowy\" modelu)\n",
    "\n",
    "Mając zamrożony model bazowy, dodamy teraz na jego wyjściu nowe warstwy, które będą uczyć się naszego zadania. W przypadku klasyfikacji dodajemy zazwyczaj warstwę typu **GlobalAveragePooling2D** albo **Flatten**, aby przekształcić trójwymiarowe mapy cech z sieci konwolucyjnej w wektor cech. Następnie dodajemy **warstwę Dense** (w pełni połączoną) z liczbą neuronów równą liczbie nowych klas i z odpowiednią funkcją aktywacji (softmax dla klasyfikacji wieloklasowej). Załóżmy, że w naszym nowym zadaniu mamy `num_classes = 5` (5 klas do rozróżnienia)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25942c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Dodajemy nową warstwę Pooling, aby spłaszczyć mapy cech do jednego wektora\n",
    "global_avg_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "# Stosujemy ją do wyjścia modelu bazowego\n",
    "feature_vector = global_avg_layer(base_model.output)\n",
    "\n",
    "# 4. Dodajemy nową warstwę w pełni połączoną (Dense) jako warstwę wyjściową.\n",
    "num_classes = 5  # przykładowa liczba klas w nowym zadaniu\n",
    "output_layer = tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "outputs = output_layer(feature_vector)\n",
    "\n",
    "# 5. Tworzymy nowy model, łącząc bazowy model i nową warstwę wyjściową.\n",
    "model = tf.keras.Model(inputs=base_model.input, outputs=outputs)\n",
    "\n",
    "# Sprawdźmy architekturę naszego modelu:\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d21348",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "\n",
    "Wyjaśnienie powyższego kodu:\n",
    "\n",
    "* Tworzymy warstwę `GlobalAveragePooling2D()` i stosujemy ją do wyjścia modelu bazowego: `feature_vector = global_avg_layer(base_model.output)`. Warstwa global average pooling weźmie mapy cech o wymiarach `(7,7,1280)` (dla MobileNetV2 ostatnia konwolucja ma takie wymiary wyjściowe) i zamieni je na wektor o długości 1280, uśredniając wartości w każdym kanale cech. Alternatywnie, moglibyśmy użyć `Flatten()`, aby po prostu spłaszczyć tensor do rozmiaru `7*7*1280`, ale global average pooling zmniejsza liczbę parametrów i często działa lepiej zapobiegając przeuczeniu.\n",
    "* Następnie tworzymy warstwę Dense: `output_layer = tf.keras.layers.Dense(num_classes, activation='softmax')`. Ma ona `num_classes` neuronów i funkcję softmax, co jest standardem dla klasyfikacji wieloklasowej (softmax da rozkład prawdopodobieństwa na klasy).\n",
    "* Stosujemy tę warstwę do naszego wektora cech: `outputs = output_layer(feature_vector)`. Teraz `outputs` to już wyjście naszego nowego modelu – wektor długości 5 z przewidywanymi prawdopodobieństwami klas.\n",
    "* Tworzymy obiekt modelu Keras: `model = tf.keras.Model(inputs=base_model.input, outputs=outputs)`. Łączy on wejście oryginalnego modelu bazowego z naszym nowym wyjściem, tworząc spójny model end-to-end. Ten model składa się z **zamrożonego** modelu bazowego MobileNetV2 oraz nowej, trenowalnej warstwy na końcu.\n",
    "* `model.summary()` wypisze podsumowanie warstw modelu. Zobaczymy listę warstw MobileNetV2 (wszystkie nie-trenowalne, parametry\\*\\*=0\\*\\* do trenowania), następnie warstwę GlobalAveragePooling2D i Dense (te na końcu będą miały **parametry do trenowania** odpowiadające nowej warstwie). Liczba parametrów do trenowania powinna być stosunkowo niewielka (tylko to, co w ostatniej warstwie Dense, czyli `1280 * num_classes + num_classes` wag oraz biasów)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7327ebfe",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "\n",
    "### 3. Kompilacja i trening nowego modelu (trening tylko nowej warstwy)\n",
    "\n",
    "Zanim rozpoczniemy trenowanie, musimy skompilować model, wybierając **funkcję straty**, **optymalizator** i ewentualne **metryki**, które chcemy śledzić. Dla klasyfikacji wieloklasowej użyjemy typowej straty `categorical_crossentropy`. Jako optymalizator wybierzemy `Adam` (często dobrze się sprawdza), a jako metrykę – **accuracy** (dokładność klasyfikacji). Założymy, że mamy przygotowane dane treningowe i walidacyjne (`train_dataset`, `val_dataset`) w postaci np. obiektów tf.data Dataset lub numpy (dla prostoty detali wczytywania danych pominiemy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ddc843e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Kompilujemy model z odpowiednią funkcją straty i optymalizatorem.\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=tf.keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 7. Trenujemy model na nowych danych (tylko ostatnia warstwa będzie się uczyć, reszta modelu jest zamrożona).\n",
    "# Poniższa linia to pseudokod - zakładamy, że train_dataset i val_dataset są przygotowane.\n",
    "history = model.fit(train_dataset, \n",
    "                    epochs=10, \n",
    "                    validation_data=val_dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02bba100",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "\n",
    "Objaśnienie:\n",
    "\n",
    "* `model.compile(...)` – konfigurujemy uczenie modelu. Ustawiamy funkcję straty (loss) na `categorical_crossentropy` (zakładamy, że etykiety klas są zakodowane one-hot lub że używamy generatora dającego one-hot vektory; jeśli używaliśmy etykiet liczbowych i chcieliśmy skorzystać z `sparse_categorical_crossentropy`, też byłoby ok – to szczegół implementacyjny). Optymalizator Adam z domyślnymi parametrami sprawdzi się dość dobrze na początek. Metryka `accuracy` pozwoli nam obserwować dokładność klasyfikacji podczas treningu."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9280f71",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "* `model.fit(...)` – rozpoczynamy proces trenowania. Przekazujemy dane treningowe oraz liczbę epok (powtórzeń całego zbioru treningowego). Zakładamy, że `train_dataset` i `val_dataset` są wcześniej zdefiniowane (np. za pomocą `tf.keras.preprocessing.image_dataset_from_directory` lub innym sposobem). **Ważne:** Na tym etapie **trenuje się tylko nowo dodana warstwa Dense**, ponieważ wszystkie inne są zamrożone. To oznacza, że model uczy się ważyć i łączyć cechy już wykrywane przez sieć bazową tak, aby dopasować się do naszych klas. Przez 10 epok powinniśmy zaobserwować wzrost dokładności zarówno na treningu, jak i (miejmy nadzieję) na walidacji."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9cf1e3",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "\n",
    "\n",
    "Po tym wstępnym etapie model prawdopodobnie już osiągnie pewien przyzwoity poziom skuteczności w naszym zadaniu. Często jednak można go jeszcze poprawić poprzez **fine-tuning**, czyli lekkie dostrojenie części wag modelu bazowego."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad0507c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "\n",
    "\n",
    "### 4. Fine-tuning – dostrajanie części modelu bazowego\n",
    "\n",
    "![TensorFlow: Transfer Learning (Fine-Tuning) in Image Classification](https://daehnhardt.com/images/drawings/feature_extraction_vs_fine_tuning.png \"TensorFlow: Transfer Learning (Fine-Tuning) in Image Classification\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0133b951",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "\n",
    "\n",
    "Załóżmy, że po treningu samej nowej warstwy nasz model działa całkiem nieźle. Teraz spróbujemy nieco podnieść jego jakość poprzez dalsze treningi: odmrozimy *część* warstw modelu bazowego, aby dać im szansę dostosować się do danych naszego konkretnego zadania. Typowo, **nie odmrażamy całego modelu naraz**, lecz stopniowo – np. odmrażamy ostatni blok konwolucyjny. Sieci takie jak MobileNetV2 czy ResNet są podzielone na bloki (grupy warstw); często wystarczy odmrozić ostatni blok (kilka warstw) lub ostatnie N warstw."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429a9332",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "\n",
    "W MobileNetV2 możemy np. odmrozić ostatnich 20 warstw (to arbitralna liczba dla przykładu). Ważne jest, by **nie trenować zbyt wielu parametrów naraz**, jeśli danych jest mało, oraz by użyć **niższej szybkości uczenia**, żeby nie zniszczyć już wyuczonych parametrów.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704e0055",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5f8567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Ustalamy, do którego poziomu warstwy pozostawić zamrożone.\n",
    "# Np. odmrażamy ostatnich 20 warstw modelu bazowego:\n",
    "fine_tune_at = len(base_model.layers) - 20\n",
    "\n",
    "for layer in base_model.layers[:fine_tune_at]:\n",
    "    layer.trainable = False  # te warstwy pozostawiamy zamrożone\n",
    "for layer in base_model.layers[fine_tune_at:]:\n",
    "    layer.trainable = True   # te warstwy (ostatnie 20) ustawiamy jako trenowalne\n",
    "\n",
    "# Sprawdźmy, ile warstw jest teraz trenowalnych:\n",
    "trainable_count = sum(1 for layer in model.layers if layer.trainable)\n",
    "print(f\"Warstw trenowalnych: {trainable_count} / {len(model.layers)}\")\n",
    "\n",
    "# 9. Ponownie kompilujemy model, tym razem z mniejszym learning rate dla fine-tuningu.\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 10. Kontynuujemy trening (fine-tuning) - trenujemy zarówno nowe warstwy, jak i wybrane odmrożone warstwy bazowe.\n",
    "history_fine = model.fit(train_dataset,\n",
    "                         epochs=5,\n",
    "                         validation_data=val_dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00bd3d28",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "\n",
    "W powyższym kodzie:\n",
    "\n",
    "* Ustalamy indeks warstwy, od której zaczniemy odmrażać (`fine_tune_at`). Użyliśmy tutaj liczby 20 przykładowo – czyli pozostawiamy początkowe `len(base_model.layers) - 20` warstw zamrożonych, a ostatnie 20 warstw odmrażamy. Można też zamiast absolutnej liczby warstw posłużyć się nazwą warstwy: np. w MobileNetV2 znaleźć nazwę warstwy bloku, od którego chcemy trenować, i na jej podstawie rozdzielić.\n",
    "* Pętlą `for` przechodzimy przez warstwy modelu bazowego: wcześniej `base_model.trainable` zostało ustawione na False, więc musimy konkretnie włączyć trenowanie dla wybranych warstw. Po tym kroku część warstw ma `layer.trainable = True` (ostatni fragment sieci), reszta pozostaje False.\n",
    "* Sprawdzamy i wypisujemy, ile warstw jest trenowalnych spośród całości (w tym liczą się też nasze nowe warstwy). Powinniśmy zobaczyć, że wcześniej trenowalna była tylko ostatnia warstwa Dense (i ewentualnie warstwa global pooling, choć ona nie ma uczenia), a teraz dodatkowo doszły np. 20 warstw konwolucyjnych.\n",
    "* **Ponowna kompilacja:** Za każdym razem, gdy zmieniamy coś w parametrach trenowalnych modelu, powinniśmy skompilować go od nowa, by optymalizator mógł uwzględnić nowe parametry. Tutaj kluczowe jest ustawienie **mniejszego learning rate**. Dajemy `1e-5` (to 0.00001) dla optymalizatora Adam – jest to dużo mniejsza wartość niż domyślna (1e-3). Dzięki temu zmiany wag w trakcie fine-tuningu będą bardzo małe, co zapobiega drastycznemu zniekształceniu wcześniej nauczonych cech.\n",
    "* `model.fit` ponownie – kontynuujemy trening. Można wykonać kilka epok (np. 5-10) fine-tuningu. Zwykle obserwujemy, że na początku fine-tuningu metryka na walidacji może lekko spaść (model musi się *przestroić*), ale potem powinna poprawić się nieco powyżej wyniku osiągniętego przy zamrożonych warstwach. Trzeba uważać, by nie trenować zbyt długo, bo mając mało danych łatwo przeuczyć model, dopasowując zbytnio odmrożone warstwy do danych treningowych.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ec06b3",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "\n",
    "Po zakończeniu fine-tuningu mamy finalny model, który wykorzystuje **wiedzę przeniesioną** z modelu bazowego oraz jest częściowo dostrojony do naszego konkretnego zadania. Teraz taki model można używać do predykcji (np. `model.predict(new_images)`) lub ocenić na danych testowych."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90168938",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "\n",
    "\n",
    "### 5. Zastosowanie modelu – inferencja\n",
    "\n",
    "Na koniec, gdy model jest już wytrenowany (przynajmniej nowa warstwa, a opcjonalnie po fine-tuningu), możemy wykorzystać go do predykcji na nowych danych. Wykonuje się to tak samo jak dla każdego modelu Keras:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989c4e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Załóżmy, że mamy nowe obrazy do klasyfikacji w tablicy numpy new_images (np. o wymiarach [N, 224, 224, 3])\n",
    "# Upewnijmy się, że przeskalujemy je odpowiednio (MobileNetV2 wymaga skalowania do [-1,1]):\n",
    "new_images_preprocessed = tf.keras.applications.mobilenet_v2.preprocess_input(new_images)\n",
    "\n",
    "# Predykcja klasy dla nowych obrazów:\n",
    "predictions = model.predict(new_images_preprocessed)\n",
    "predicted_classes = predictions.argmax(axis=1)\n",
    "print(\"Przewidywane klasy:\", predicted_classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4ff7e7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "\n",
    "\n",
    "Tutaj `predictions` będzie macierzą kształtu `(N, 5)` z przewidywanymi prawdopodobieństwami dla każdej z 5 klas. Metodą `argmax` wybieramy indeks najwyższego prawdopodobieństwa, czyli przewidywaną klasę. Jeśli mamy zdefiniowaną listę nazw klas, możemy łatwo zamapować indeksy na nazwy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74527032",
   "metadata": {},
   "source": [
    "\n",
    "## Q\\&A – Pytania sprawdzające zrozumienie\n",
    "\n",
    "Poniżej znajduje się kilka pytań wraz z odpowiedziami, które pomogą utrwalić zdobytą wiedzę:\n",
    "\n",
    "**P1: Na czym polega uczenie transferowe (transfer learning) i dlaczego jest użyteczne?**\\\n",
    "&#x20;**Odpowiedź:** Transfer learning polega na wykorzystaniu wiedzy (wytrenowanych parametrów) modelu z jednego zadania do przyspieszenia uczenia modelu na innym, powiązanym zadaniu. Jest użyteczne, ponieważ pozwala trenować modele szybciej i przy mniejszej liczbie danych treningowych – model startuje z dobrą inicjalizacją (wiedza z zadania źródłowego), co często skutkuje wyższą dokładnością na zadaniu docelowym niż trenowanie od zera, zwłaszcza gdy dane są ograniczone.\n",
    "\n",
    "**P2: Czym jest** ***model pretrenowany*** **i jak się go wykorzystuje w transfer learningu?**\\\n",
    "&#x20;**Odpowiedź:** Model pretrenowany to model, który został już wcześniej wytrenowany na dużym zbiorze danych do jakiegoś zadania (np. klasyfikacji obrazów na ImageNet). Taki model posiada wagi odzwierciedlające wiedzę z tamtego zadania. W transfer learningu pobieramy taki model i wykorzystujemy go jako bazę dla nowego zadania – zwykle zachowujemy jego architekturę i większość wag, modyfikując jedynie ostatnie warstwy (lub dodając nowe warstwy), tak aby model dawał odpowiedzi w kontekście nowego zadania. W ten sposób korzystamy z wcześniej wytrenowanych cech, zamiast uczyć się wszystkiego od początku.\n",
    "\n",
    "**P3: Jaka jest różnica między podejściem** ***feature extraction*** **a** ***fine-tuning*** **w kontekście transfer learningu?**\\\n",
    "&#x20;**Odpowiedź:** *Feature extraction* (ekstrakcja cech) polega na zamrożeniu wag modelu pretrenowanego i użyciu go jedynie do wyciągania cech z danych – uczymy wówczas tylko nowo dodaną warstwę wyjściową, która na podstawie tych cech dokonuje klasyfikacji (lub innego zadania). Model bazowy działa wtedy jak stały ekstraktor cech. Z kolei *fine-tuning* (dostrajanie) to dalsze trenowanie części lub całości modelu bazowego już po wstępnym etapie ekstrakcji cech. Innymi słowy, przy fine-tuningu **odmrażamy** niektóre (lub wszystkie) warstwy modelu bazowego i kontynuujemy ich trenowanie (zazwyczaj z niską szybkością uczenia), aby delikatnie dostosować wcześniej nauczone wzorce do nowego zadania. Różnica więc polega na tym, że *feature extraction* nie modyfikuje wag pretrenowanego modelu (uczymy tylko nowe warstwy), a *fine-tuning* modyfikuje również część wag oryginalnego modelu.\n",
    "\n",
    "**P4: Dlaczego zaleca się zamrażać większość warstw modelu bazowego podczas trenowania nowej warstwy wyjściowej?**\\\n",
    "&#x20;**Odpowiedź:** Zamrażanie warstw zapobiega zmianom wcześniej wyuczonych parametrów modelu bazowego. Dzięki temu **nie nadpisujemy** (nie tracimy) wiedzy, którą model już posiada z zadania źródłowego. Kiedy danych do nowego zadania jest mało, próba trenowania wszystkich wag mogłaby prowadzić do silnego przeuczenia – model mógłby zacząć *zapamiętywać szum* zamiast uogólniać. Zamrażając większość warstw, ograniczamy liczbę parametrów, które muszą się nauczyć od nowa (uczą się głównie wagi nowej warstwy), co ułatwia trening i stabilizuje go. Dopiero gdy nowa warstwa nauczy się korzystać z istniejących cech, ewentualnie można **stopniowo** odmrażać kolejne warstwy i kontynuować trening (fine-tuning) – ale zawsze z ostrożnością (mały learning rate, monitorowanie wyników), by nie zniszczyć wcześniejszej wiedzy.\n",
    "\n",
    "**P5: Kiedy samo** ***feature extraction*** **może nie wystarczyć i warto zastosować** ***fine-tuning*****?**\\\n",
    "&#x20;**Odpowiedź:** Jeśli po dodaniu nowej warstwy i wytrenowaniu jej (przy zamrożonym modelu bazowym) wyniki na walidacji/testach są niezadowalające, a posiadamy przynajmniej umiarkowaną ilość danych, można rozważyć fine-tuning. Fine-tuning jest szczególnie przydatny, gdy:\n",
    "\n",
    "* Nowe zadanie jest dość **podobne** do zadania oryginalnego – wtedy możemy bezpiecznie dostroić wyższe warstwy, by poprawić wyniki.\n",
    "* Mamy jednak pewną ilość danych (choć nie tak dużo jak do trenowania od zera, to więcej niż kilka przykładów na klasę), aby umożliwić uczenie się dodatkowych wag bez natychmiastowego przeuczenia.\\\n",
    "  &#x20;Jeśli model bazowy osiągnął już pewien pułap i nie może poprawić się uczeniem tylko nowej głowy, dostrojenie kilku ostatnich warstw może pomóc wyciągnąć dodatkową poprawę skuteczności. Przykładowo, przy rozpoznawaniu kwiatów korzystając z modelu trenowanego na ImageNet – może okazać się, że kwiaty mają specyficzne wzorce, których kombincja wymaga lekkiej modyfikacji wag wyższych warstw. Fine-tuning pozwoli na to dostosowanie.\n",
    "\n",
    "**P6: Jakie ryzyka lub wyzwania wiążą się z użyciem transfer learningu?**\\\n",
    "&#x20;**Odpowiedź:** Mimo wielu zalet, transfer learning ma też pewne wyzwania:\n",
    "\n",
    "* Jeśli zadanie źródłowe i docelowe są **bardzo różne**, model pretrenowany może nie dawać pożądanych korzyści (jego cechy mogą być mało przydatne do nowego zadania). Np. model wytrenowany na zdjęciach naturalnych może słabo transferować do obrazów medycznych lub zdjęć satelitarnych, chyba że zastosujemy głębszy fine-tuning.\n",
    "* **Przeuczenie**: Jeśli nowy zbiór danych jest bardzo mały, istnieje ryzyko przeuczenia nawet podczas fine-tuningu kilku warstw. Model może zbytnio dopasować się do danych treningowych. Rozwiązaniem jest bardzo ostrożny fine-tuning lub pozostanie przy feature extraction, a także zastosowanie technik augmentacji danych.\n",
    "* **Niedouczenie**: Z drugiej strony, jeśli zbyt mało warstw dostroimy (albo użyjemy zbyt niskiego learning rate czy za krótko trenujemy), model może pozostać w stanie, który nie jest optymalnie dopasowany do nowego zadania – utknie z cechami, które nie są idealne. Dlatego fine-tuning wymaga pewnego eksperymentowania (ile warstw odmrażać, jaki learning rate, ile epok).\n",
    "* **Zgodność danych wejściowych**: Trzeba pamiętać, że dane wejściowe muszą być podane w formacie oczekiwanym przez model pretrenowany (np. rozmiar obrazu, skala pikseli, normalizacja). Np. modele z ImageNet zwykle oczekują obrazów 224x224 i konkretnych normalizacji. Niedopasowanie tych aspektów może skutkować słabym działaniem modelu.\n",
    "\n",
    "#\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c12339",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".VENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
