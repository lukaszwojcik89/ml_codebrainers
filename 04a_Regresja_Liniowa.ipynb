{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac3856b0",
   "metadata": {},
   "source": [
    "# **Regresja Liniowa w Uczeniu Maszynowym**\n",
    "\n",
    "![](https://datascientest.com/en/files/2021/01/Machine-learning-def-.png)\n",
    "\n",
    "_Bartek Bilski_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571d592a",
   "metadata": {},
   "source": [
    "## **Wstęp**\n",
    "\n",
    "Witaj na zajęciach dotyczących **regresji liniowej** – jednego z fundamentalnych algorytmów uczenia maszynowego. W ciągu tych zajęć poznasz podstawy regresji liniowej, nauczysz się implementować modele przy użyciu scikit-learn oraz zrozumiesz, jak regularyzacja może poprawić jakość modeli.\n",
    "\n",
    "Regresja liniowa to idealny punkt startowy do nauki machine learning, ponieważ jest intuicyjna matematycznie, a jednocześnie stanowi podstawę dla bardziej zaawansowanych technik."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d522841",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### **Struktura notebooka**\n",
    "\n",
    "Notebook zawiera objaśnienia teoretyczne oraz praktyczne przykłady w Pythonie. Po każdej sekcji znajdziesz **zadania do samodzielnego wykonania** oznaczone jako **Zadanie**. Zachęcam do aktywnego wykonywania tych ćwiczeń.\n",
    "\n",
    "### **Podstawowe Pojęcia Statystyczne – Wprowadzenie**\n",
    "\n",
    "- **Zmienna objaśniająca (feature)**: Atrybut opisujący dane wejściowe (np. metraż mieszkania).\n",
    "- **Zmienna docelowa (target)**: Wielkość, którą chcemy przewidzieć (np. cena mieszkania).\n",
    "- **Próbka i populacja**: Na podstawie próby (posiadanych danych) wnioskujemy o całej populacji.\n",
    "- **Miary położenia**: średnia, mediana.\n",
    "- **Miary zmienności**: wariancja, odchylenie standardowe.\n",
    "- **Rozkłady prawdopodobieństwa**: np. rozkład normalny.\n",
    "\n",
    "Statystyka pomaga nam lepiej zrozumieć dane i ich struktury zanim zbudujemy model ML.\n",
    "\n",
    "![](https://i.ibb.co/KVCdqr3/Screenshot-2024-12-10-112852.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85044f5",
   "metadata": {},
   "source": [
    "### **Typy zmiennych w analizie danych**\n",
    "\n",
    "W procesie eksploracji i modelowania danych niezwykle istotne jest zrozumienie typów zmiennych w zbiorze danych.\n",
    "\n",
    "**Główne rodzaje zmiennych:**\n",
    "\n",
    "1. **Numeryczne**\n",
    "   - **Ciągłe:** Mogą przyjmować dowolną wartość z pewnego przedziału (np. metraż, temperatura)\n",
    "   - **Dyskretne:** Przyjmują konkretne, zliczalne wartości (np. liczba pokoi)\n",
    "\n",
    "2. **Kategoryczne**\n",
    "   - Nie mają naturalnego porządku (np. nazwy miast, typ nieruchomości)\n",
    "   - Wymagają enkodowania do postaci numerycznej (One-Hot Encoding)\n",
    "\n",
    "3. **Porządkowe (ordinal)**\n",
    "   - Mają naturalny porządek (np. ocena jakości 1-5, poziom edukacji)\n",
    "   - Można kodować jako liczby zachowując hierarchię\n",
    "\n",
    "\n",
    "![](https://statsandr.com/blog/variable-types_files/variable-types-and-examples.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f59c4e1",
   "metadata": {},
   "source": [
    "## **Co to jest regresja?**\n",
    "\n",
    "**Regresja** to typ uczenia nadzorowanego, którego celem jest przewidywanie **wartości ciągłych** (numerycznych) na podstawie innych zmiennych. W przeciwieństwie do klasyfikacji, która przewiduje kategorie, regresja przewiduje konkretne liczby.\n",
    "\n",
    "**Przykłady zastosowań regresji:**\n",
    "- Przewidywanie cen nieruchomości na podstawie powierzchni, lokalizacji, wieku\n",
    "- Prognozowanie sprzedaży na podstawie nakładów na reklamę\n",
    "- Szacowanie temperatury na podstawie ciśnienia atmosferycznego\n",
    "\n",
    "**Popularne algorytmy regresji:**\n",
    "- Regresja liniowa (Linear Regression)\n",
    "- Drzewa regresyjne (Regression Trees) \n",
    "- Las losowy (Random Forest)\n",
    "- Sieci neuronowe (Neural Networks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d122e58",
   "metadata": {},
   "source": [
    "## **Teoria Regresji Liniowej**\n",
    "\n",
    "### **Czym jest regresja liniowa?**\n",
    "\n",
    "Regresja liniowa to metoda statystyczna używana do modelowania związku między zmienną zależną (docelową) a jedną lub więcej zmiennymi niezależnymi (cechami). Główne założenia:\n",
    "\n",
    "1. **Liniowość**: Związek między zmiennymi jest liniowy\n",
    "2. **Niezależność**: Obserwacje są niezależne od siebie\n",
    "3. **Homoscedastyczność**: Wariancja reszt jest stała\n",
    "4. **Normalność**: Reszty mają rozkład normalny\n",
    "\n",
    "### **Równanie regresji liniowej:**\n",
    "\n",
    "**Regresja prosta (jedna cecha):**\n",
    "$$ y = \\beta_0 + \\beta_1 x + \\epsilon $$\n",
    "\n",
    "**Regresja wielokrotna (wiele cech):**\n",
    "$$y = β₀ + β₁x₁ + β₂x₂ + ... + βₙxₙ + ε$$\n",
    "Gdzie:\n",
    "- $y$ - zmienna docelowa (np. cena)\n",
    "- $x_1,x_2,x_n$ - cechy (zmienne objaśniające)\n",
    "- $\\beta_0$ - wyraz wolny (przecięcie z osią Y, intercept)\n",
    "- $\\beta_1, \\beta_2, \\beta_n$ - współczynniki regresji (slopes)\n",
    "- $\\epsilon$ - składnik błędu\n",
    "\n",
    "**Interpretacja parametrów:**\n",
    "- $\\beta_0$: wartość $y$ gdy $x = 0$\n",
    "- $\\beta_1$: o ile zmienia się $y$ przy wzroście $x$ o 1 jednostkę\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7d0f8b",
   "metadata": {},
   "source": [
    "\n",
    "### **Jak działa algorytm?**\n",
    "#### **Metoda Najmniejszych Kwadratów (Ordinary Least Squares - OLS)**\n",
    "\n",
    "Aby znaleźć najlepszą linię regresji, minimalizujemy **sumę kwadratów błędów** (SSE):\n",
    "\n",
    "$$ \\text{SSE} = \\sum_{i=1}^{n}(y_i - \\hat{y}_i)^2 $$\n",
    "\n",
    "gdzie $\\hat{y}_i = \\beta_0 + \\beta_1 x_i$ to przewidywana wartość.\n",
    "\n",
    "**Rozwiązania analityczne dla regresji jednowymiarowej:**\n",
    "\n",
    "$$ \\hat{\\beta}_1 = \\frac{\\sum_{i=1}^{n}(x_i - \\bar{x})(y_i - \\bar{y})}{\\sum_{i=1}^{n}(x_i - \\bar{x})^2} $$\n",
    "\n",
    "$$ \\hat{\\beta}_0 = \\bar{y} - \\hat{\\beta}_1 \\bar{x} $$\n",
    "\n",
    "Metoda OLS gwarantuje znalezienie globalnego optimum dla regresji liniowej.\n",
    "\n",
    "![](https://vitalflux.com/wp-content/uploads/2022/02/ordinary-least-squares-method.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6591c36",
   "metadata": {},
   "source": [
    "## **Problem Overfittingu i Regularyzacja**\n",
    "\n",
    "### **Overfitting w regresji liniowej**\n",
    "\n",
    "Kiedy model ma zbyt wiele cech w stosunku do liczby obserwacji, może wystąpić **overfitting**:\n",
    "- Model \"zapamiętuje\" dane treningowe\n",
    "- Słabo generalizuje na nowe dane\n",
    "- Współczynniki mogą być bardzo duże i niestabilne\n",
    "\n",
    "### **Regularyzacja jako rozwiązanie**\n",
    "\n",
    "Regularyzacja dodaje \"karę\" za zbyt duże współczynniki, wymuszając prostsze modele:\n",
    "\n",
    "**Funkcja kosztu z regularyzacją:**\n",
    "$$ \\text{Koszt} = \\text{SSE} + \\lambda \\cdot \\text{Kara} $$\n",
    "\n",
    "gdzie $\\lambda$ (lambda) kontroluje siłę regularyzacji.\n",
    "\n",
    "### **Lasso (L1 Regularization)**\n",
    "\n",
    "**Idea:** Dodaje karę $$ \\lambda \\sum |\\beta_j| $$ do funkcji kosztu.\n",
    "\n",
    "**Efekty Lasso:**\n",
    "- **Selekcja cech:** Może wyzerować współczynniki nieistotnych cech\n",
    "- **Modele rzadkie:** Pozostają tylko najważniejsze cechy\n",
    "- **Łatwiejsza interpretacja:** Model używa mniej zmiennych\n",
    "\n",
    "**Kiedy używać Lasso:**\n",
    "\n",
    "✅ Gdy masz tysiące cech i chcesz przeprowadzić selekcję  \n",
    "✅ Gdy zależy Ci na interpretowalności modelu  \n",
    "✅ W wysokowymiarowych problemach (więcej cech niż obserwacji).\n",
    "### **Ridge (L2 Regularization)**\n",
    "\n",
    "**Idea:** Dodaje karę $\\lambda \\sum \\beta_j^2$ do funkcji kosztu.\n",
    "\n",
    "**Efekty Ridge:**\n",
    "- **Stabilizacja współczynników:** Wszystkie współczynniki stają się mniejsze\n",
    "- **Obsługa multikolinearności:** Lepiej radzi sobie ze skorelowanymi cechami\n",
    "- **Zachowanie wszystkich cech:** Nie zeruje współczynników\n",
    "\n",
    "**Kiedy używać Ridge:**\n",
    "\n",
    "✅ Gdy masz wiele podobnych/skorelowanych cech  \n",
    "✅ Gdy nie chcesz eliminować żadnych zmiennych  \n",
    "✅ Gdy chcesz stabilizować model bez utraty informacji\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### **Elastic Net**\n",
    "**Idea:** Dodaje karę $\\lambda \\sum \\beta_j^2$ + $ \\lambda \\sum |\\beta_j| $ do funkcji kosztu.\n",
    "\n",
    "**Efekty Elastic Net**\n",
    "- Kombinacja Ridge i Lasso\n",
    "- Balansuje między stabilnością a selekcją cech\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2dd53a3",
   "metadata": {},
   "source": [
    "## **Wczytanie i Eksploracja Danych - California Housing**\n",
    "\n",
    "Będziemy pracować ze zbiorem danych **California Housing**, który zawiera informacje o cenach domów w Kalifornii z 1990 roku. To klasyczny dataset do nauki regresji liniowej.\n",
    "\n",
    "### **Opis zbioru danych:**\n",
    "- **20,640 obserwacji** (bloków mieszkaniowych)\n",
    "- **8 cech numerycznych**\n",
    "- **Zmienna docelowa**: Mediana wartości domów (w $100k)\n",
    "\n",
    "### **Cechy w zbiorze:**\n",
    "1. **MedInc**: Mediana dochodu w bloku (w $10k)\n",
    "2. **HouseAge**: Mediana wieku domów w bloku\n",
    "3. **AveRooms**: Średnia liczba pokoi na dom\n",
    "4. **AveBedrms**: Średnia liczba sypialni na dom\n",
    "5. **Population**: Populacja bloku\n",
    "6. **AveOccup**: Średnia liczba mieszkańców na dom\n",
    "7. **Latitude**: Szerokość geograficzna\n",
    "8. **Longitude**: Długość geograficzna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238f000b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### =====================================\n",
    "### IMPORT BIBLIOTEK I KONFIGURACJA\n",
    "### =====================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "# Ustawienia wizualizacji\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['font.size'] = 12\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "print(\"✅ Wszystkie biblioteki zostały zaimportowane pomyślnie!\")\n",
    "print(\"🚀 Jesteśmy gotowi do pracy z regresją liniową!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303c8975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================\n",
    "# WCZYTANIE DANYCH CALIFORNIA HOUSING\n",
    "# =====================================\n",
    "\n",
    "print(\"📊 WCZYTYWANIE DANYCH CALIFORNIA HOUSING:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Wczytanie danych\n",
    "data = fetch_california_housing()\n",
    "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "df['MedHouseVal'] = data.target\n",
    "\n",
    "print(f\"✅ Dane wczytane pomyślnie!\")\n",
    "print(f\"📏 Rozmiar zbioru: {df.shape[0]} obserwacji, {df.shape[1]} kolumn\")\n",
    "print(f\"🎯 Zmienna docelowa: MedHouseVal (mediana wartości domów)\")\n",
    "\n",
    "# Podstawowe informacje\n",
    "print(\"\\n📋 PODSTAWOWE INFORMACJE O DANYCH:\")\n",
    "print(\"=\" * 50)\n",
    "print(df.info())\n",
    "\n",
    "print(\"\\n👀 PODGLĄD PIERWSZYCH 5 WIERSZY:\")\n",
    "print(\"=\" * 50)\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a2e82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📊 Statystyki opisowe\n",
    "print(\"\\n📈 STATYSTYKI OPISOWE:\")\n",
    "print(\"=\" * 50)\n",
    "display(df.describe().round(2))\n",
    "\n",
    "print(\"\\n💡 KLUCZOWE OBSERWACJE:\")\n",
    "print(\"✅ Wszystkie zmienne są numeryczne\")\n",
    "print(\"✅ Brak wartości NaN - dane są kompletne\")\n",
    "print(\"⚠️ Różne skale danych (MedInc: 0-15, Population: 3-35k)\")\n",
    "print(\"⚠️ Możliwe outliers (max AveRooms: 141!)\")\n",
    "print(\"🎯 Zmienna docelowa: MedHouseVal (0.15 - 5.0 * $100k)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3de43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔍 Sprawdzenie brakujących wartości\n",
    "print(\"🔍 SPRAWDZENIE KOMPLETNOŚCI DANYCH:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "missing_data = df.isnull().sum()\n",
    "print(\"Brakujące wartości na kolumnę:\")\n",
    "print(missing_data)\n",
    "\n",
    "if missing_data.sum() == 0:\n",
    "    print(\"\\n✅ Żadnych brakujących wartości - dane są kompletne!\")\n",
    "else:\n",
    "    print(f\"\\n⚠️ Znaleziono {missing_data.sum()} brakujących wartości\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af32dbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📊 Wizualizacja rozkładu zmiennej docelowej\n",
    "print(\"📊 ANALIZA ZMIENNEJ DOCELOWEJ (CENY DOMÓW):\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# Histogram\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.histplot(df['MedHouseVal'], kde=True, bins=50)\n",
    "plt.title(\"Rozkład cen domów\")\n",
    "plt.xlabel(\"Mediana wartości domów ($100k)\")\n",
    "plt.ylabel(\"Liczba obserwacji\")\n",
    "\n",
    "# Boxplot\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.boxplot(y=df['MedHouseVal'])\n",
    "plt.title(\"Rozkład cen - wykres pudełkowy\")\n",
    "plt.ylabel(\"Mediana wartości domów ($100k)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Sprawdzenie wartości maksymalnych\n",
    "max_value = df['MedHouseVal'].max()\n",
    "max_count = (df['MedHouseVal'] == max_value).sum()\n",
    "print(f\"\\n🔍 Analiza wartości maksymalnych:\")\n",
    "print(f\"Maksymalna wartość: ${max_value} * 100k = ${max_value * 100000}\")\n",
    "print(f\"Liczba obserwacji z maksymalną wartością: {max_count}\")\n",
    "if max_count > 100:\n",
    "    print(\"⚠️ Możliwe, że dane są 'ucapowane' (ograniczone od góry)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554c80dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📈 Analiza zależności między kluczowymi zmiennymi\n",
    "print(\"📈 ZALEŻNOŚCI MIĘDZY ZMIENNYMI:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Wybieramy najciekawsze zmienne do analizy\n",
    "key_vars = ['MedHouseVal', 'MedInc', 'AveRooms', 'HouseAge', 'Population']\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.pairplot(df[key_vars], diag_kind='hist', plot_kws={'alpha': 0.6})\n",
    "plt.suptitle('Zależności między kluczowymi zmiennymi', y=1.02)\n",
    "plt.show()\n",
    "\n",
    "print(\"💡 Na co zwrócić uwagę:\")\n",
    "print(\"- Czy widać liniowe zależności?\")\n",
    "print(\"- Które zmienne wydają się najsilniej skorelowane z ceną?\")\n",
    "print(\"- Czy są wartości odstające?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5718e9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔥 Mapa korelacji\n",
    "print(\"🔥 ANALIZA KORELACJI:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "correlation_matrix = df.corr()\n",
    "sns.heatmap(correlation_matrix, \n",
    "           annot=True, \n",
    "           cmap='RdBu_r', \n",
    "           center=0,\n",
    "           square=True,\n",
    "           linewidths=0.5,\n",
    "           cbar_kws={\"shrink\": .8})\n",
    "plt.title('Mapa korelacji - California Housing Dataset')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Analiza korelacji z zmienną docelową\n",
    "print(\"\\n📈 KORELACJE Z CENĄ DOMÓW:\")\n",
    "target_corr = correlation_matrix['MedHouseVal'].drop('MedHouseVal').abs().sort_values(ascending=False)\n",
    "for var, corr in target_corr.items():\n",
    "    strength = \"Silna\" if corr > 0.6 else \"Umiarkowana\" if corr > 0.3 else \"Słaba\"\n",
    "    print(f\"{var:12s}: {corr:+.3f} ({strength})\")\n",
    "\n",
    "print(f\"\\n🏆 Najsilniejszy predyktor: {target_corr.index[0]} (r={target_corr.iloc[0]:.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1073177f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🧹 Czyszczenie danych (opcjonalnie)\n",
    "print(\"🧹 CZYSZCZENIE DANYCH:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "max_value = df['MedHouseVal'].max()\n",
    "capped_count = (df['MedHouseVal'] == max_value).sum()\n",
    "\n",
    "print(f\"Obserwacje z maksymalną wartością ({max_value}): {capped_count}\")\n",
    "print(f\"Procent obserwacji: {(capped_count/len(df)*100):.1f}%\")\n",
    "\n",
    "if capped_count > 100:  # Jeśli więcej niż 100 obserwacji ma maksymalną wartość\n",
    "    print(f\"\\n📊 Rozważamy usunięcie {capped_count} obserwacji z 'ucapowanymi' wartościami\")\n",
    "    print(\"(Te wartości mogą być artefaktem sposobu zbierania danych)\")\n",
    "    \n",
    "    # Dla tego tutoriala zachowujemy wszystkie dane\n",
    "    print(\"🔧 Dla celów edukacyjnych zachowujemy wszystkie dane\")\n",
    "else:\n",
    "    print(\"\\n✅ Brak potrzeby usuwania danych\")\n",
    "\n",
    "# Wizualizacja głównej zależności\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(df['MedInc'], df['MedHouseVal'], alpha=0.5, s=20)\n",
    "plt.xlabel(\"Median Income (in $10k)\")\n",
    "plt.ylabel(\"Median House Value (in $100k)\")\n",
    "plt.title(\"Zależność między dochodem a ceną domów\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n💡 Obserwacja: Wyraźna pozytywna korelacja między dochodem a ceną!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a902e088",
   "metadata": {},
   "source": [
    "## **Przygotowanie Danych do Modelowania**\n",
    "\n",
    "Przed rozpoczęciem modelowania musimy:\n",
    "\n",
    "1. **Podzielić dane** na cechy (X) i zmienną docelową (y)\n",
    "2. **Rozdzielić zbiór** na treningowy i testowy\n",
    "3. **Przeanalizować skale** cech (ważne dla regularyzacji)\n",
    "4. **Przygotować pipeline** z preprocessingiem\n",
    "\n",
    "### **Dlaczego podział train/test jest ważny?**\n",
    "\n",
    "- **Zapobiega overfitting**: Model uczy się tylko na danych treningowych\n",
    "- **Ocena generalizacji**: Testujemy na \"niewidzianych\" danych\n",
    "- **Uczciwa ewaluacja**: Symuluje rzeczywiste warunki użycia modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e17c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================\n",
    "# PRZYGOTOWANIE DANYCH DO MODELOWANIA\n",
    "# =====================================\n",
    "\n",
    "print(\"🔧 PRZYGOTOWANIE DANYCH DO MODELOWANIA:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Podział na cechy (X) i zmienną docelową (y)\n",
    "X = df.drop('MedHouseVal', axis=1)\n",
    "y = df['MedHouseVal']\n",
    "\n",
    "print(f\"Kształt macierzy cech (X): {X.shape}\")\n",
    "print(f\"Kształt wektora etykiet (y): {y.shape}\")\n",
    "print(f\"\\nCechy w modelu: {list(X.columns)}\")\n",
    "\n",
    "# Podział na zbiory treningowy i testowy\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2,    # 20% danych na test\n",
    "    random_state=42   # Dla powtarzalności wyników\n",
    ")\n",
    "\n",
    "print(f\"\\n📊 PODZIAŁ DANYCH:\")\n",
    "print(f\"Zbiór treningowy: {X_train.shape[0]} obserwacji ({X_train.shape[0]/len(X)*100:.0f}%)\")\n",
    "print(f\"Zbiór testowy:    {X_test.shape[0]} obserwacji ({X_test.shape[0]/len(X)*100:.0f}%)\")\n",
    "print(\"✅ Podział zachowuje proporcje!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c17bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔍 Analiza skal cech\n",
    "print(\"🔍 ANALIZA SKAL CECH:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Statystyki skal\n",
    "scaling_analysis = pd.DataFrame({\n",
    "    'Cecha': X_train.columns,\n",
    "    'Średnia': X_train.mean(),\n",
    "    'Odch. std.': X_train.std(),\n",
    "    'Minimum': X_train.min(),\n",
    "    'Maksimum': X_train.max(),\n",
    "    'Zakres': X_train.max() - X_train.min()\n",
    "}).round(2)\n",
    "\n",
    "display(scaling_analysis)\n",
    "\n",
    "print(\"\\n💡 PROBLEM:\")\n",
    "print(\"- MedInc: skala 0-15 (dochody w dziesiątkach tysięcy)\")\n",
    "print(\"- Population: skala 3-35k (liczba mieszkańców)\")\n",
    "print(\"- AveRooms: skala 0-140 (pokoje na dom)\")\n",
    "print(\"\\n⚠️ Różne skale mogą zdominować model!\")\n",
    "print(\"🔧 Rozwiązanie: Skalowanie (StandardScaler)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2cf0b5",
   "metadata": {},
   "source": [
    "## **Pierwszy Model - Regresja Liniowa bez Preprocessingu**\n",
    "\n",
    "Zacznijmy od prostego modelu bez skalowania, żeby zobaczyć bazowe wyniki, a następnie porównamy je z modelem ze skalowaniem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e83ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================\n",
    "# PIERWSZY MODEL - BASIC LINEAR REGRESSION\n",
    "# =====================================\n",
    "\n",
    "print(\"🚀 PIERWSZY MODEL - REGRESJA LINIOWA (BEZ PREPROCESSINGU):\")\n",
    "print(\"=\" * 60)\n",
    "print(\"🎯 Cel: Uzyskanie wyników bazowych do porównania\")\n",
    "\n",
    "# Tworzenie i trenowanie modelu\n",
    "lin_reg_basic = LinearRegression()\n",
    "lin_reg_basic.fit(X_train, y_train)\n",
    "\n",
    "# Predykcje\n",
    "y_pred_basic = lin_reg_basic.predict(X_test)\n",
    "\n",
    "# Obliczenie metryk\n",
    "mse_basic = mean_squared_error(y_test, y_pred_basic)\n",
    "rmse_basic = np.sqrt(mse_basic)\n",
    "r2_basic = r2_score(y_test, y_pred_basic)\n",
    "mae_basic = mean_absolute_error(y_test, y_pred_basic)\n",
    "\n",
    "print(\"📊 WYNIKI MODELU BAZOWEGO:\")\n",
    "print(f\"MSE:  {mse_basic:.4f}\")\n",
    "print(f\"RMSE: ${rmse_basic*100:.0f}k (średni błąd predykcji)\")\n",
    "print(f\"R²:   {r2_basic:.4f} ({r2_basic*100:.1f}% wyjaśnionej zmienności)\")\n",
    "print(f\"MAE:  ${mae_basic*100:.0f}k (średni błąd bezwzględny)\")\n",
    "\n",
    "print(f\"\\n💡 INTERPRETACJA:\")\n",
    "print(f\"Model wyjaśnia {r2_basic*100:.1f}% zmienności cen domów\")\n",
    "print(f\"Średni błąd predykcji: ±${rmse_basic*100:.0f}k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31629770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📊 Wizualizacja wyników\n",
    "print(\"📊 WIZUALIZACJA WYNIKÓW:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Predykcje vs rzeczywiste wartości\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(y_test, y_pred_basic, alpha=0.6, s=30)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "plt.xlabel('Rzeczywiste ceny')\n",
    "plt.ylabel('Przewidywane ceny')\n",
    "plt.title('Predykcje vs Rzeczywiste wartości')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Histogram reszt\n",
    "plt.subplot(1, 2, 2)\n",
    "residuals = y_test - y_pred_basic\n",
    "plt.hist(residuals, bins=30, alpha=0.7, edgecolor='black')\n",
    "plt.xlabel('Reszty (błędy predykcji)')\n",
    "plt.ylabel('Liczba obserwacji')\n",
    "plt.title('Rozkład reszt')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"💡 Obserwacje z wykresów:\")\n",
    "print(\"- Punkty blisko linii y=x oznaczają dobre predykcje\")\n",
    "print(\"- Reszty powinny być normalnie rozłożone wokół zera\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa7aa36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔍 Analiza współczynników\n",
    "print(\"🔍 ANALIZA WSPÓŁCZYNNIKÓW REGRESJI:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Tworzenie DataFrame z współczynnikami\n",
    "coef_df = pd.DataFrame({\n",
    "    'Cecha': X.columns,\n",
    "    'Współczynnik': lin_reg_basic.coef_,\n",
    "    'Wartość_bezwzględna': np.abs(lin_reg_basic.coef_)\n",
    "})\n",
    "\n",
    "# Sortowanie według wartości bezwzględnej\n",
    "coef_df = coef_df.sort_values('Wartość_bezwzględna', ascending=False)\n",
    "\n",
    "print(\"📊 RANKING WAŻNOŚCI CECH:\")\n",
    "display(coef_df.round(4))\n",
    "\n",
    "print(f\"\\n🏠 WYRAZ WOLNY (Intercept): {lin_reg_basic.intercept_:.4f}\")\n",
    "\n",
    "print(\"\\n💡 INTERPRETACJA WSPÓŁCZYNNIKÓW:\")\n",
    "print(\"- Dodatni współczynnik = wzrost cechy zwiększa cenę\")\n",
    "print(\"- Ujemny współczynnik = wzrost cechy zmniejsza cenę\")\n",
    "print(\"- Większa wartość bezwzględna = silniejszy wpływ\")\n",
    "print(\"\\n⚠️ UWAGA: Współczynniki zależą od skali cech!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9044ed3",
   "metadata": {},
   "source": [
    "## **Model z Preprocessingiem - Skalowanie Danych**\n",
    "\n",
    "Teraz stworzymy model z odpowiednim skalowaniem danych. Wykorzystamy **Pipeline** - potężne narzędzie scikit-learn, które:\n",
    "\n",
    "1. **Automatyzuje** preprocessing i modelowanie\n",
    "2. **Zapobiega data leakage** (preprocessor uczony tylko na train)\n",
    "3. **Upraszcza kod** i zwiększa czytelność\n",
    "4. **Ułatwia wdrożenie** modelu w produkcji\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6d2c9d",
   "metadata": {},
   "source": [
    "**Popularne metody skalowania:**\n",
    "\n",
    "1. **StandardScaler (standaryzacja)**  \n",
    "   - Przekształca dane tak, by miały średnią 0 i odchylenie standardowe 1.  \n",
    "   - Wzór dla każdej cechy:  \n",
    "     $$ x_{scaled} = \\frac{x - \\bar{x}}{\\sigma} $$\n",
    "   \n",
    "2. **MinMaxScaler**  \n",
    "   - Przekształca dane do przedziału [0,1].  \n",
    "   - Wzór:  \n",
    "     $$ x_{scaled} = \\frac{x - x_{min}}{x_{max} - x_{min}} $$\n",
    "\n",
    "### **Wpływ skalowania na modele**\n",
    "\n",
    "**Algorytmy wrażliwe na skalę:**\n",
    "\n",
    "✅ Regresja z regularyzacją (Ridge, Lasso)  \n",
    "✅ SVM, KNN, K-means  \n",
    "✅ Sieci neuronowe  \n",
    "✅ PCA, LDA  \n",
    "\n",
    "**Algorytmy odporne na skalę:**\n",
    "\n",
    "❌ Drzewa decyzyjne  \n",
    "❌ Random Forest  \n",
    "❌ Naive Bayes  \n",
    "\n",
    "### **Zadanie **\n",
    "\n",
    "Zastanów się: dlaczego regularyzacja (Ridge/Lasso) jest wrażliwa na skalę cech? \n",
    "Wskazówka: przypomnij sobie wzory na kary L1 i L2!\n",
    "\n",
    "![](https://kharshit.github.io/img/scaling.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c4d6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================\n",
    "# MODEL Z PREPROCESSINGIEM - PIPELINE\n",
    "# =====================================\n",
    "\n",
    "print(\"🔧 TWORZENIE MODELU Z PREPROCESSINGIEM:\")\n",
    "print(\"=\" * 50)\n",
    "print(\"🎯 Pipeline: Skalowanie + Regresja Liniowa\")\n",
    "\n",
    "# Tworzenie pipeline\n",
    "lin_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),      # Krok 1: Skalowanie\n",
    "    ('linear_reg', LinearRegression()) # Krok 2: Regresja\n",
    "])\n",
    "\n",
    "print(\"✅ Pipeline utworzony!\")\n",
    "print(\"\\n📊 Kroki w pipeline:\")\n",
    "print(\"1. 'scaler': StandardScaler (mean=0, std=1)\")\n",
    "print(\"2. 'linear_reg': LinearRegression\")\n",
    "\n",
    "# Trenowanie pipeline\n",
    "print(\"\\n🏃‍♂️ Trenowanie modelu...\")\n",
    "lin_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predykcje\n",
    "y_pred_scaled = lin_pipeline.predict(X_test)\n",
    "\n",
    "# Metryki\n",
    "mse_scaled = mean_squared_error(y_test, y_pred_scaled)\n",
    "rmse_scaled = np.sqrt(mse_scaled)\n",
    "r2_scaled = r2_score(y_test, y_pred_scaled)\n",
    "mae_scaled = mean_absolute_error(y_test, y_pred_scaled)\n",
    "\n",
    "print(\"📊 WYNIKI MODELU Z SKALOWANIEM:\")\n",
    "print(f\"MSE:  {mse_scaled:.4f}\")\n",
    "print(f\"RMSE: ${rmse_scaled*100:.0f}k\")\n",
    "print(f\"R²:   {r2_scaled:.4f} ({r2_scaled*100:.1f}%)\")\n",
    "print(f\"MAE:  ${mae_scaled*100:.0f}k\")\n",
    "\n",
    "print(f\"\\n🔍 PORÓWNANIE Z MODELEM BAZOWYM:\")\n",
    "print(f\"R² improvement: {r2_scaled - r2_basic:+.4f}\")\n",
    "print(f\"RMSE change: ${(rmse_scaled - rmse_basic)*100:+.0f}k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950339b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📊 Porównanie modeli\n",
    "print(\"📊 PORÓWNANIE MODELI:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Metric': ['R²', 'RMSE ($k)', 'MAE ($k)'],\n",
    "    'Bez skalowania': [r2_basic, rmse_basic*100, mae_basic*100],\n",
    "    'Ze skalowaniem': [r2_scaled, rmse_scaled*100, mae_scaled*100]\n",
    "}).round(3)\n",
    "\n",
    "display(comparison_df)\n",
    "\n",
    "# Wizualizacja porównania\n",
    "plt.figure(figsize=(10, 6))\n",
    "metrics = ['R²', 'RMSE', 'MAE']\n",
    "basic_values = [r2_basic, rmse_basic, mae_basic]\n",
    "scaled_values = [r2_scaled, rmse_scaled, mae_scaled]\n",
    "\n",
    "x = np.arange(len(metrics))\n",
    "width = 0.35\n",
    "\n",
    "plt.bar(x - width/2, basic_values, width, label='Bez skalowania', alpha=0.8)\n",
    "plt.bar(x + width/2, scaled_values, width, label='Ze skalowaniem', alpha=0.8)\n",
    "\n",
    "plt.xlabel('Metryki')\n",
    "plt.ylabel('Wartość')\n",
    "plt.title('Porównanie modeli: z skalowaniem vs bez skalowania')\n",
    "plt.xticks(x, metrics)\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(\"💡 WNIOSEK:\")\n",
    "if abs(r2_scaled - r2_basic) < 0.001:\n",
    "    print(\"Skalowanie nie wpłynęło znacząco na Linear Regression\")\n",
    "    print(\"(To normalne - Linear Regression jest mało wrażliwa na skalę)\")\n",
    "    print(\"🔧 Skalowanie będzie ważne dla regularyzacji!\")\n",
    "else:\n",
    "    print(f\"Skalowanie {'poprawiło' if r2_scaled > r2_basic else 'pogorszyło'} wyniki\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc52087d",
   "metadata": {},
   "source": [
    "## **Regularyzacja - Ridge i Lasso Regression**\n",
    "\n",
    "Teraz przetestujemy modele z regularyzacją. Regularyzacja jest szczególnie przydatna gdy:\n",
    "\n",
    "1. **Mamy wiele cech** (zapobiega overfitting)\n",
    "2. **Cechy są skorelowane** (Ridge stabilizuje współczynniki)\n",
    "3. **Podejrzewamy nieistotne cechy** (Lasso może je wyeliminować)\n",
    "4. **Chcemy prostszy model** (Lasso redukuje liczbę cech)\n",
    "\n",
    "### **Parametr α (alpha):**\n",
    "- **α = 0**: Zwykła regresja liniowa\n",
    "- **α → ∞**: Wszystkie współczynniki → 0\n",
    "- **Optymalne α**: Znajdziemy przez cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae109191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================\n",
    "# REGULARYZACJA - RIDGE I LASSO\n",
    "# =====================================\n",
    "\n",
    "print(\"⚖️ REGULARYZACJA - RIDGE I LASSO REGRESSION:\")\n",
    "print(\"=\" * 60)\n",
    "print(\"🎯 Cel: Porównanie różnych wartości alpha\")\n",
    "\n",
    "# Różne wartości alpha do przetestowania\n",
    "alphas = [0.01, 0.1, 1, 10, 100]\n",
    "\n",
    "print(f\"🔧 Testowane wartości alpha: {alphas}\")\n",
    "print(\"📊 Dla każdego alpha trenujemy Ridge i Lasso\")\n",
    "\n",
    "# Przechowywanie wyników\n",
    "results = []\n",
    "\n",
    "for alpha in alphas:\n",
    "    print(f\"\\n🔄 Testowanie alpha = {alpha}...\")\n",
    "    \n",
    "    # Ridge Pipeline\n",
    "    ridge_pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('ridge', Ridge(alpha=alpha))\n",
    "    ])\n",
    "    ridge_pipeline.fit(X_train, y_train)\n",
    "    y_pred_ridge = ridge_pipeline.predict(X_test)\n",
    "    \n",
    "    # Lasso Pipeline\n",
    "    lasso_pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('lasso', Lasso(alpha=alpha, max_iter=10000))\n",
    "    ])\n",
    "    lasso_pipeline.fit(X_train, y_train)\n",
    "    y_pred_lasso = lasso_pipeline.predict(X_test)\n",
    "    \n",
    "    # Metryki\n",
    "    ridge_r2 = r2_score(y_test, y_pred_ridge)\n",
    "    lasso_r2 = r2_score(y_test, y_pred_lasso)\n",
    "    ridge_rmse = np.sqrt(mean_squared_error(y_test, y_pred_ridge))\n",
    "    lasso_rmse = np.sqrt(mean_squared_error(y_test, y_pred_lasso))\n",
    "    \n",
    "    results.append({\n",
    "        'alpha': alpha,\n",
    "        'Ridge_R2': ridge_r2,\n",
    "        'Lasso_R2': lasso_r2,\n",
    "        'Ridge_RMSE': ridge_rmse,\n",
    "        'Lasso_RMSE': lasso_rmse\n",
    "    })\n",
    "\n",
    "print(\"✅ Testowanie zakończone!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efac56ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📊 Analiza wyników regularyzacji\n",
    "print(\"📊 WYNIKI REGULARYZACJI:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "display(results_df.round(4))\n",
    "\n",
    "# Znajdź najlepsze alpha\n",
    "best_ridge_alpha = results_df.loc[results_df['Ridge_R2'].idxmax(), 'alpha']\n",
    "best_lasso_alpha = results_df.loc[results_df['Lasso_R2'].idxmax(), 'alpha']\n",
    "\n",
    "print(f\"\\n🏆 NAJLEPSZE WYNIKI:\")\n",
    "print(f\"Ridge - najlepsze α: {best_ridge_alpha} (R² = {results_df['Ridge_R2'].max():.4f})\")\n",
    "print(f\"Lasso - najlepsze α: {best_lasso_alpha} (R² = {results_df['Lasso_R2'].max():.4f})\")\n",
    "print(f\"Linear - R²: {r2_scaled:.4f}\")\n",
    "\n",
    "# Porównanie z modelem liniowym\n",
    "best_ridge_r2 = results_df['Ridge_R2'].max()\n",
    "best_lasso_r2 = results_df['Lasso_R2'].max()\n",
    "\n",
    "print(f\"\\n📈 PORÓWNANIE Z LINEAR REGRESSION:\")\n",
    "print(f\"Ridge improvement: {best_ridge_r2 - r2_scaled:+.4f}\")\n",
    "print(f\"Lasso improvement: {best_lasso_r2 - r2_scaled:+.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fee5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📈 Wizualizacja wpływu alpha\n",
    "print(\"📈 WIZUALIZACJA WPŁYWU ALPHA:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# R² vs alpha\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.semilogx(alphas, results_df['Ridge_R2'], 'o-', label='Ridge', linewidth=2, markersize=8)\n",
    "plt.semilogx(alphas, results_df['Lasso_R2'], 's-', label='Lasso', linewidth=2, markersize=8)\n",
    "plt.axhline(y=r2_scaled, color='red', linestyle='--', alpha=0.7, label='Linear Reg')\n",
    "plt.xlabel('Alpha (log scale)')\n",
    "plt.ylabel('R² Score')\n",
    "plt.title('R² vs Alpha')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# RMSE vs alpha\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.semilogx(alphas, results_df['Ridge_RMSE'], 'o-', label='Ridge', linewidth=2, markersize=8)\n",
    "plt.semilogx(alphas, results_df['Lasso_RMSE'], 's-', label='Lasso', linewidth=2, markersize=8)\n",
    "plt.axhline(y=rmse_scaled, color='red', linestyle='--', alpha=0.7, label='Linear Reg')\n",
    "plt.xlabel('Alpha (log scale)')\n",
    "plt.ylabel('RMSE')\n",
    "plt.title('RMSE vs Alpha')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"💡 INTERPRETACJA WYKRESÓW:\")\n",
    "print(\"1. Małe alpha → bliskie regresji liniowej\")\n",
    "print(\"2. Duże alpha → więcej regularyzacji\")\n",
    "print(\"3. Optimum to kompromis między underfitting a overfitting\")\n",
    "print(\"4. Ridge i Lasso mogą mieć różne optymalne alpha\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4682425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔍 Analiza współczynników z regularyzacją\n",
    "print(\"🔍 ANALIZA WSPÓŁCZYNNIKÓW Z REGULARYZACJĄ:\")\n",
    "print(\"=\" * 60)\n",
    "print(\"🎯 Porównanie jak regularyzacja wpływa na współczynniki\")\n",
    "\n",
    "# Trenujemy modele z najlepszymi alpha\n",
    "ridge_final = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('ridge', Ridge(alpha=best_ridge_alpha))\n",
    "])\n",
    "\n",
    "lasso_final = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('lasso', Lasso(alpha=best_lasso_alpha, max_iter=10000))\n",
    "])\n",
    "\n",
    "ridge_final.fit(X_train, y_train)\n",
    "lasso_final.fit(X_train, y_train)\n",
    "\n",
    "# Porównanie współczynników\n",
    "coef_comparison = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Linear': lin_pipeline.named_steps['linear_reg'].coef_,\n",
    "    'Ridge': ridge_final.named_steps['ridge'].coef_,\n",
    "    'Lasso': lasso_final.named_steps['lasso'].coef_,\n",
    "    'Lasso_Zero': np.abs(lasso_final.named_steps['lasso'].coef_) < 1e-6\n",
    "})\n",
    "\n",
    "print(\"📊 WSPÓŁCZYNNIKI WSZYSTKICH MODELI:\")\n",
    "display(coef_comparison.round(4))\n",
    "\n",
    "# Analiza selekcji cech przez Lasso\n",
    "zero_coefs = coef_comparison['Lasso_Zero'].sum()\n",
    "total_coefs = len(coef_comparison)\n",
    "\n",
    "print(f\"\\n🗑️ SELEKCJA CECH (LASSO α={best_lasso_alpha}):\")\n",
    "print(f\"Współczynniki wyzerowane: {zero_coefs}/{total_coefs} ({zero_coefs/total_coefs*100:.0f}%)\")\n",
    "\n",
    "if zero_coefs > 0:\n",
    "    removed_features = coef_comparison[coef_comparison['Lasso_Zero']]['Feature'].tolist()\n",
    "    print(\"\\n📋 CECHY USUNIĘTE PRZEZ LASSO:\")\n",
    "    for feature in removed_features:\n",
    "        print(f\"  - {feature}\")\n",
    "    \n",
    "    remaining_features = coef_comparison[~coef_comparison['Lasso_Zero']]['Feature'].tolist()\n",
    "    print(\"\\n✅ CECHY ZACHOWANE PRZEZ LASSO:\")\n",
    "    for feature in remaining_features:\n",
    "        coef_val = coef_comparison[coef_comparison['Feature'] == feature]['Lasso'].iloc[0]\n",
    "        print(f\"  - {feature}: {coef_val:.4f}\")\n",
    "else:\n",
    "    print(\"✅ LASSO zachował wszystkie cechy (alpha może być za małe)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e9736c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📊 Wizualizacja współczynników\n",
    "print(\"📊 WIZUALIZACJA WSPÓŁCZYNNIKÓW:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# 1. Porównanie współczynników\n",
    "ax1 = axes[0, 0]\n",
    "x_pos = np.arange(len(X.columns))\n",
    "width = 0.25\n",
    "\n",
    "ax1.bar(x_pos - width, coef_comparison['Linear'], width, label='Linear', alpha=0.8)\n",
    "ax1.bar(x_pos, coef_comparison['Ridge'], width, label='Ridge', alpha=0.8)\n",
    "ax1.bar(x_pos + width, coef_comparison['Lasso'], width, label='Lasso', alpha=0.8)\n",
    "\n",
    "ax1.set_xlabel('Cechy')\n",
    "ax1.set_ylabel('Wartość współczynnika')\n",
    "ax1.set_title('Porównanie współczynników')\n",
    "ax1.set_xticks(x_pos)\n",
    "ax1.set_xticklabels(X.columns, rotation=45, ha='right')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Wartości bezwzględne\n",
    "ax2 = axes[0, 1]\n",
    "ax2.bar(x_pos - width, np.abs(coef_comparison['Linear']), width, label='Linear', alpha=0.8)\n",
    "ax2.bar(x_pos, np.abs(coef_comparison['Ridge']), width, label='Ridge', alpha=0.8)\n",
    "ax2.bar(x_pos + width, np.abs(coef_comparison['Lasso']), width, label='Lasso', alpha=0.8)\n",
    "\n",
    "ax2.set_xlabel('Cechy')\n",
    "ax2.set_ylabel('|Współczynnik|')\n",
    "ax2.set_title('Wartości bezwzględne współczynników')\n",
    "ax2.set_xticks(x_pos)\n",
    "ax2.set_xticklabels(X.columns, rotation=45, ha='right')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Ridge vs Lasso scatter\n",
    "ax3 = axes[1, 0]\n",
    "ax3.scatter(coef_comparison['Ridge'], coef_comparison['Lasso'], alpha=0.7, s=80)\n",
    "for i, feature in enumerate(X.columns):\n",
    "    ax3.annotate(feature, \n",
    "                (coef_comparison['Ridge'].iloc[i], coef_comparison['Lasso'].iloc[i]),\n",
    "                xytext=(5, 5), textcoords='offset points', fontsize=8)\n",
    "\n",
    "# Linia x=y\n",
    "min_val = min(coef_comparison['Ridge'].min(), coef_comparison['Lasso'].min())\n",
    "max_val = max(coef_comparison['Ridge'].max(), coef_comparison['Lasso'].max())\n",
    "ax3.plot([min_val, max_val], [min_val, max_val], 'r--', alpha=0.5)\n",
    "\n",
    "ax3.set_xlabel('Ridge współczynniki')\n",
    "ax3.set_ylabel('Lasso współczynniki')\n",
    "ax3.set_title('Ridge vs Lasso')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Porównanie metryk\n",
    "ax4 = axes[1, 1]\n",
    "models = ['Linear', 'Ridge\\n(α=' + str(best_ridge_alpha) + ')', 'Lasso\\n(α=' + str(best_lasso_alpha) + ')']\n",
    "r2_scores = [r2_scaled, best_ridge_r2, best_lasso_r2]\n",
    "\n",
    "bars = ax4.bar(models, r2_scores, color=['skyblue', 'lightgreen', 'lightcoral'], alpha=0.8)\n",
    "ax4.set_ylabel('R² Score')\n",
    "ax4.set_title('Porównanie jakości modeli')\n",
    "ax4.set_ylim(0, 1)\n",
    "\n",
    "# Dodanie wartości na słupkach\n",
    "for bar, score in zip(bars, r2_scores):\n",
    "    height = bar.get_height()\n",
    "    ax4.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "             f'{score:.4f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"💡 WNIOSKI Z WIZUALIZACJI:\")\n",
    "print(\"1. Ridge zmniejsza wszystkie współczynniki proporcjonalnie\")\n",
    "print(\"2. Lasso może eliminować cechy (zerowe współczynniki)\")\n",
    "print(\"3. Regularyzacja stabilizuje model i zapobiega overfittingu\")\n",
    "print(\"4. Wybór między Ridge/Lasso zależy od problemu i danych\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0658e0b",
   "metadata": {},
   "source": [
    "## **Zadania Praktyczne - Samodzielna Praca**\n",
    "\n",
    "### **Zadanie 1: Eksperyment z cechami geograficznymi**\n",
    "California Housing zawiera współrzędne geograficzne (Latitude, Longitude). Sprawdź:\n",
    "1. Jak usunięcie lub dodanie tych cech wpływa na model?\n",
    "2. Czy można stworzyć nową cechę \"distance from center\" (np. odległość od San Francisco)?\n",
    "3. Porównaj wyniki z obecnym modelem\n",
    "\n",
    "### **Zadanie 2: Analiza reszt (residuals)**\n",
    "Dla najlepszego modelu:\n",
    "1. Oblicz reszty: `residuals = y_true - y_pred`\n",
    "2. Sprawdź czy reszty mają rozkład normalny (histogram + QQ-plot)\n",
    "3. Narysuj reszty vs przewidywane wartości\n",
    "4. Zidentyfikuj outliers - które domy są najgorzej przewidziane?\n",
    "\n",
    "### **Zadanie 3: Feature Engineering**\n",
    "Stwórz nowe cechy:\n",
    "1. **Rooms per household**: `AveRooms / AveOccup`\n",
    "2. **Income per room**: `MedInc / AveRooms`  \n",
    "3. **Population density**: `Population / (HouseAge + 1)`\n",
    "4. Przetestuj czy nowe cechy poprawiają R²\n",
    "\n",
    "### **Zadanie 4: Cross-Validation i Grid Search**\n",
    "```python\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Znajdź optymalne alpha używając Grid Search\n",
    "param_grid = {'lasso__alpha': [0.001, 0.01, 0.1, 1, 10]}\n",
    "grid_search = GridSearchCV(lasso_pipeline, param_grid, cv=5, scoring='r2')\n",
    "grid_search.fit(X_train, y_train)\n",
    "```\n",
    "\n",
    "### **Zadanie 5: Model Interpretability**\n",
    "1. Ranking cech - które są najważniejsze dla przewidywania ceny?\n",
    "2. Analiza business impact - co oznaczają współczynniki w praktyce?\n",
    "3. Jak zmiana każdej cechy o 1 jednostkę wpływa na cenę domu?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61ffbee",
   "metadata": {},
   "source": [
    "## **Podsumowanie i Najlepsze Praktyki**\n",
    "\n",
    "### **🏆 Co osiągnęliśmy:**\n",
    "\n",
    "1. **📊 Eksploracja danych**: Poznaliśmy California Housing dataset\n",
    "2. **🔧 Preprocessing**: Nauczyliśmy się skalowania i pipeline'ów\n",
    "3. **📈 Modelowanie**: Zaimplementowaliśmy Linear, Ridge, i Lasso regression\n",
    "4. **⚖️ Regularyzacja**: Zrozumieliśmy wpływ parametru alpha\n",
    "5. **🔍 Interpretacja**: Przeanalizowaliśmy współczynniki i ich znaczenie\n",
    "\n",
    "\n",
    "\n",
    "### **💡 Kluczowe wnioski:**\n",
    "\n",
    "**O California Housing:**\n",
    "- **MedInc** (dochód) to najsilniejszy predyktor ceny\n",
    "- Model wyjaśnia ~60% zmienności cen domów\n",
    "- Regularyzacja nie poprawiła znacząco wyników (dane są już dobrze przygotowane)\n",
    "\n",
    "**O regresji liniowej:**\n",
    "- ✅ Prosta i interpretowalana\n",
    "- ✅ Dobra jako model bazowy  \n",
    "- ⚠️ Zakłada liniowe zależności\n",
    "- ⚠️ Wymaga odpowiedniego preprocessingu\n",
    "\n",
    "**O regularyzacji:**\n",
    "- **Ridge**: Stabilizuje współczynniki, dobry dla skorelowanych cech\n",
    "- **Lasso**: Automatyczna selekcja cech, tworzy rzadkie modele\n",
    "- **Alpha**: Kontroluje siłę regularyzacji (większe = więcej ograniczeń)\n",
    "\n",
    "### **🔧 Najlepsze praktyki:**\n",
    "\n",
    "1. **Zawsze skaluj dane** przy regularyzacji\n",
    "2. **Używaj Pipeline** dla czystego kodu\n",
    "3. **Dziel dane** na train/test przed preprocessingiem\n",
    "4. **Waliduj cross-validation** dla lepszej oceny\n",
    "5. **Interpretuj współczynniki** w kontekście biznesowym\n",
    "6. **Sprawdzaj założenia** regresji liniowej\n",
    "\n",
    "### **🚀 Co dalej:**\n",
    "\n",
    "1. **Polynomial Features** - nieliniowe zależności\n",
    "2. **Ensemble Methods** - Random Forest, Gradient Boosting\n",
    "3. **Feature Selection** - automatyczna selekcja cech\n",
    "4. **Hyperparameter Tuning** - Grid Search, Random Search\n",
    "5. **Advanced Validation** - nested CV, time series splits\n",
    "\n",
    "---\n",
    "\n",
    "**💡 Pamiętaj**: \n",
    "> \"All models are wrong, but some are useful\" - George Box\n",
    "\n",
    "Regresja liniowa może nie być idealna, ale jest **użyteczna**, **interpretowalana** i stanowi **solidną podstawę** do nauki bardziej zaawansowanych technik ML.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719c8291",
   "metadata": {},
   "source": [
    "## **📚 Dalsze Materiały i Zasoby**\n",
    "\n",
    "### **🔗 Przydatne linki:**\n",
    "\n",
    "**Dokumentacja:**\n",
    "- [Scikit-learn Linear Models](https://scikit-learn.org/stable/modules/linear_model.html)\n",
    "- [Pandas Documentation](https://pandas.pydata.org/docs/)\n",
    "- [Matplotlib Tutorials](https://matplotlib.org/stable/tutorials/index.html)\n",
    "\n",
    "**Kursy online:**\n",
    "- [Andrew Ng - Machine Learning Course](https://www.coursera.org/learn/machine-learning)\n",
    "- [Fast.ai - Practical Deep Learning](https://www.fast.ai/)\n",
    "- [Elements of Statistical Learning (książka)](https://hastie.su.domains/ElemStatLearn/)\n",
    "\n",
    "**Praktyczne zasoby:**\n",
    "- [Kaggle Learn](https://www.kaggle.com/learn) - darmowe kursy ML\n",
    "- [Google Colab](https://colab.research.google.com/) - darmowe GPU do eksperymentów\n",
    "- [Papers with Code](https://paperswithcode.com/) - najnowsze badania\n",
    "\n",
    "### **📈 Datasety do ćwiczeń:**\n",
    "\n",
    "1. **Boston Housing** - klasyczny dataset regresji\n",
    "2. **Wine Quality** - regression + classification  \n",
    "3. **Bike Sharing** - analiza szeregów czasowych\n",
    "4. **Student Performance** - edukacyjny dataset\n",
    "5. **Real Estate** - ceny nieruchomości\n",
    "\n",
    "### **🔧 Narzędzia do zaawansowanej analizy:**\n",
    "\n",
    "- **Seaborn** - zaawansowane wizualizacje\n",
    "- **Plotly** - interaktywne wykresy\n",
    "- **SHAP** - interpretowalny ML\n",
    "- **MLflow** - tracking eksperymentów  \n",
    "- **Streamlit** - szybkie web apps\n",
    "\n",
    "---\n",
    "\n",
    "**🚀 Powodzenia w dalszej nauce Machine Learning!**\n",
    "\n",
    "Pamiętaj: najlepszy sposób nauki to praktyka. Eksperymentuj z różnymi algorytmami, dataset'ami i podejściami. Każdy projekt uczy czegoś nowego!\n",
    "\n",
    "**Happy Coding! 🐍💻**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
