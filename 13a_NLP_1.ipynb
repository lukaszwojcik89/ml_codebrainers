{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4b561d6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Podstawy NLP â€“ analiza sentymentu z uÅ¼yciem podstawowych modeli ML&#x20;\n",
    "\n",
    "&#x20;![Natural Language Processing With Python's NLTK Package â€“ Real Python](https://files.realpython.com/media/NLP-for-Beginners-Pythons-Natural-Language-Toolkit-NLTK_Watermarked.16a787c1e9c6.jpg \"Natural Language Processing With Python's NLTK Package â€“ Real Python\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4453c755",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " \n",
    "## Cele edukacyjne\n",
    "\n",
    "* **Zrozumienie czym jest NLP (Przetwarzanie JÄ™zyka Naturalnego)** â€“ poznasz definicjÄ™ NLP i przykÅ‚ady jego zastosowaÅ„.\n",
    "* **Wprowadzenie do analizy sentymentu** â€“ dowiesz siÄ™, na czym polega analiza sentymentu (opinie pozytywne vs negatywne) i gdzie siÄ™ jÄ… wykorzystuje.\n",
    "* **Przygotowanie Å›rodowiska pracy** â€“ zainstalujesz i zaimportujesz podstawowe narzÄ™dzia potrzebne do pracy z danymi tekstowymi (biblioteki Python takie jak *pandas*, *scikit-learn*, *nltk* itp.).\n",
    "* **Eksploracja zbioru danych** â€“ nauczysz siÄ™ wczytaÄ‡ zbiÃ³r danych z recenzjami (np. **IMDB**), podejrzeÄ‡ jego zawartoÅ›Ä‡ oraz przeprowadziÄ‡ wstÄ™pnÄ… analizÄ™: sprawdziÄ‡ liczbÄ™ prÃ³bek, przykÅ‚adowe dane i rozkÅ‚ad klas (pozytywne/negatywne opinie).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c7c837",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " \n",
    "## Wprowadzenie â€“ Czym jest NLP?\n",
    "\n",
    "![1.00](https://cdn.prod.website-files.com/5ec6a20095cdf182f108f666/5f22908f09f2341721cd8901_AI%20poster.png \"NLP and text mining: A natural fit for business growth\")\n",
    "\n",
    "**Przetwarzanie JÄ™zyka Naturalnego (ang. Natural Language Processing, NLP)** to dziedzina informatyki i sztucznej inteligencji, ktÃ³rej celem jest umoÅ¼liwienie komputerom zrozumienia i przetwarzania jÄ™zyka naturalnego â€“ takiego, jakim posÅ‚ugujÄ… siÄ™ ludzie. Innymi sÅ‚owy, NLP to tworzenie systemÃ³w, ktÃ³re potrafiÄ… analizowaÄ‡, interpretowaÄ‡, a nawet generowaÄ‡ tekst lub mowÄ™ w jÄ™zyku np. polskim czy angielskim."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb94fb68",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " PrzykÅ‚adowe zastosowania NLP na co dzieÅ„:\n",
    "\n",
    "* **TÅ‚umaczenie maszynowe** â€“ np. tÅ‚umacz Google przekÅ‚adajÄ…cy tekst z jednego jÄ™zyka na inny.\n",
    "* **Asystenci gÅ‚osowi** â€“ Siri, Alexa czy Asystent Google rozumiejÄ… polecenia gÅ‚osowe uÅ¼ytkownika.\n",
    "* **Analiza sentymentu** â€“ automatyczne okreÅ›lanie, czy dany tekst (np. recenzja produktu, tweet) wyraÅ¼a pozytywnÄ…, negatywnÄ… czy neutralnÄ… opiniÄ™.\n",
    "* **Chatboty i systemy dialogowe** â€“ programy rozmawiajÄ…ce z uÅ¼ytkownikiem w jÄ™zyku naturalnym.\n",
    "* **Wyszukiwanie informacji** â€“ wyszukiwarki internetowe interpretujÄ…ce pytania zadane peÅ‚nym zdaniem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76319448",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " \n",
    "\n",
    "Skupimy siÄ™ na **analizie sentymentu**, czyli na jednym z popularnych zadaÅ„ NLP. Analiza sentymentu polega na automatycznym okreÅ›laniu emocjonalnego wydÅºwiÄ™ku tekstu. NajczÄ™Å›ciej sprowadza siÄ™ to do stwierdzenia, czy tekst jest **pozytywny** czy **negatywny** (czasem wyrÃ³Å¼nia siÄ™ teÅ¼ trzeciÄ… kategoriÄ™: neutralny). DziÄ™ki takim modelom moÅ¼na np. analizowaÄ‡ opinie klientÃ³w o produkcie, reakcje na kampaniÄ™ marketingowÄ… albo nastroje wypowiedzi w mediach spoÅ‚ecznoÅ›ciowych."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af7d5ad",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " \n",
    "\n",
    "\n",
    "**Dlaczego to jest waÅ¼ne?** WyobraÅº sobie firmÄ™, ktÃ³ra wypuÅ›ciÅ‚a nowy produkt â€“ codziennie pojawiajÄ… siÄ™ setki recenzji i komentarzy w internecie. Przeczytanie ich wszystkich przez czÅ‚owieka jest trudne, ale algorytm analizy sentymentu moÅ¼e w kilka chwil podsumowaÄ‡, ilu klientÃ³w jest zadowolonych, a ilu nie. Automatyczna analiza opinii pozwala firmom szybko reagowaÄ‡ na negatywne gÅ‚osy, a naukowcom badaÄ‡ spoÅ‚eczne reakcje na rÃ³Å¼ne wydarzenia."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3487b1dc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " ## Analiza sentymentu â€“ podejÅ›cia\n",
    "\n",
    "![1.00](https://www.researchgate.net/publication/336988754/figure/fig2/AS:928001474711553@1598264201745/Sentiment-analysis-methods.png \"Sentiment analysis methods | Download Scientific Diagram\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b0ddce",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " \n",
    "\n",
    "\n",
    "IstniejÄ… rÃ³Å¼ne podejÅ›cia do analizy sentymentu:\n",
    "\n",
    "* **Metody oparte na sÅ‚ownikach (rule-based)** â€“ Najprostsze podejÅ›cia korzystajÄ… ze zdefiniowanych list sÅ‚Ã³w o zabarwieniu pozytywnym lub negatywnym (tzw. *slowniki sentymentu*). Tekst oceniany jest na podstawie zliczania pozytywnych i negatywnych sÅ‚Ã³w. Np. jeÅ›li zdanie zawiera sÅ‚owa \"Å›wietny, wspaniaÅ‚y\" moÅ¼e zostaÄ‡ ocenione jako pozytywne. To podejÅ›cie jest intuicyjne, ale bywa zawodne â€“ nie uwzglÄ™dnia kontekstu (np. zdanie \"to nie byÅ‚ Å›wietny film\" zawiera sÅ‚owo *Å›wietny*, ale caÅ‚oÅ›Ä‡ jest negatywna przez *nie*).\n",
    "* **Metody oparte na uczeniu maszynowym (machine learning)** â€“ Model **uczy siÄ™** na przykÅ‚adach tekstÃ³w oznaczonych jako pozytywne/negatywne. Taki model sam dobiera cechy jÄ™zykowe (np. czÄ™stoÅ›Ä‡ wystÄ™powania okreÅ›lonych sÅ‚Ã³w) pozwalajÄ…ce przewidywaÄ‡ sentyment nowego tekstu. W tej kategorii mieszczÄ… siÄ™ klasyczne algorytmy jak Naive Bayes czy Regresja Logistyczna.\n",
    "* **Metody gÅ‚Ä™bokiego uczenia (deep learning)** â€“ WspÃ³Å‚czeÅ›nie najlepsze wyniki czÄ™sto osiÄ…ga siÄ™ modelami opartymi o sieci neuronowe (np. model BERT). SÄ… one jednak bardziej zÅ‚oÅ¼one i wymagajÄ… duÅ¼ych zasobÃ³w oraz danych.&#x20;\n",
    "\n",
    "Przejdziemy przez caÅ‚y proces tworzenia prostego systemu analizy sentymentu opartego na uczeniu maszynowym. Zaczniemy od przygotowania danych, nastÄ™pnie przeksztaÅ‚cimy teksty na cechy numeryczne, a na koÅ„cu zbudujemy model potrafiÄ…cy klasyfikowaÄ‡ nowe teksty jako pozytywne lub negatywne."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53055a76",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " \n",
    "## Przygotowanie Å›rodowiska pracy\n",
    "\n",
    "![1.00](https://media.geeksforgeeks.org/wp-content/uploads/20240402170207/NLP-Libraries-in-Python-copy.webp \"NLP Libraries in Python - GeeksforGeeks\")\n",
    "\n",
    "Zacznijmy od przygotowania Å›rodowiska. Upewnij siÄ™, Å¼e masz zainstalowane potrzebne biblioteki. W niniejszym kursie bÄ™dziemy korzystaÄ‡ [m.in](http://m.in). z:\n",
    "\n",
    "* **pandas** â€“ do wczytywania i manipulacji zbiorami danych (szczegÃ³lnie przydatne do eksploracji).\n",
    "* **datasets (HuggingFace)** â€“ do pobrania przykÅ‚adowych otwartych zbiorÃ³w danych do analizy sentymentu.\n",
    "* **nltk (Natural Language Toolkit)** â€“ do podstawowych operacji NLP (tokenizacja, stop words itp.).\n",
    "* **scikit-learn** â€“ do wektorowych reprezentacji tekstu (CountVectorizer/TF-IDF) oraz implementacji klasycznych algorytmÃ³w ML (np. Naive Bayes, Logistic Regression)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d68ea60",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " \n",
    "\n",
    "> &#x20;Zbiory, ktÃ³rych uÅ¼yjemy, sÄ… publicznie dostÄ™pne do celÃ³w edukacyjnych:\n",
    ">\n",
    "> * **IMDB Reviews** â€“ 50Â 000 recenzji filmÃ³w w jÄ™zyku angielskim (pozytywne i negatywne) opublikowanych pierwotnie na IMDb.\n",
    ">\n",
    ">   [huggingface.co](https://huggingface.co/datasets/clarin-pl/polemo2-official#:~:text=Data%20splits)\n",
    "> * **Polski zbiÃ³r recenzji (PolEmo 2.0)** â€“ ok. 8Â 216 recenzji w jÄ™zyku polskim (np. opinie o hotelach, produktach, usÅ‚ugach) z podziaÅ‚em na opinie pozytywne, negatywne oraz neutralne/niejednoznaczne.\n",
    ">\n",
    ">   [huggingface.co](https://huggingface.co/datasets/clarin-pl/polemo2-official#:~:text=Class%20train%20dev%20test%20minus,1439)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e23eb4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " Zainstalujmy i zaimportujmy potrzebne biblioteki:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4978b5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas scikit-learn nltk datasets --quiet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee85e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "\n",
    "# Pobranie sÅ‚ownika stop words dla jÄ™zyka angielskiego (potrzebne w kolejnych etapach)\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97519e5c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " \n",
    "Po uruchomieniu powyÅ¼szej komÃ³rki, biblioteki zostanÄ… zainstalowane (jeÅ›li jeszcze ich nie masz), a NLTK pobierze listÄ™ stop words oraz punktuator do tokenizacji zdaÅ„. MoÅ¼emy teraz wczytaÄ‡ dane."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ff8c73",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " ## Wczytanie i eksploracja zbioru danych IMDB\n",
    "\n",
    "&#x20;                              ![IMDb\\_Logo\\_Rectangle\\_Gold.\\_CB443386186\\_.png](https://m.media-amazon.com/images/G/01/IMDb/brand/guidelines/imdb/IMDb_Logo_Rectangle_Gold._CB443386186_.png \"IMDb_Logo_Rectangle_Gold._CB443386186_.png\")\n",
    "\n",
    "Zaczniemy od zbioru danych **IMDb** z recenzjami filmÃ³w.&#x20;\n",
    "\n",
    "KorzystajÄ…c z biblioteki ğŸ¤— *datasets*, moÅ¼emy Å‚atwo pobraÄ‡ ten zbiÃ³r. Wystarczy uÅ¼yÄ‡ `load_dataset(\"imdb\")`, a dane zostanÄ… automatycznie pobrane. ZbiÃ³r IMDb zawiera 50Â 000 recenzji: 25Â 000 przeznaczonych do trenowania modeli i 25Â 000 do testowania, po poÅ‚owie **pozytywnych** i **negatywnych**.\n",
    "\n",
    "Wczytajmy dane i zobaczmy podstawowe informacje:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4d1ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# imdb_data=pd.read_csv('datasets/IMDB.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed51d065",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Wczytanie zbioru IMDb. ZostanÄ… utworzone podzbiory: 'train' i 'test'\n",
    "imdb_data =load_dataset(\"imdb\", verification_mode='no_checks')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28daeae",
   "metadata": {},
   "source": [
    "\n",
    "Po wykonaniu powyÅ¼szego polecenia, powinniÅ›my mieÄ‡ dostÄ™p do danych. SprawdÅºmy ile przykÅ‚adÃ³w jest w zbiorze treningowym i testowym:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a3ebce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rozmiary zbioru treningowego i testowego\n",
    "print(\"Liczba recenzji w train:\", len(imdb_data['train']))\n",
    "print(\"Liczba recenzji w test:\", len(imdb_data['test']))\n",
    "\n",
    "# DostÄ™pne kolumny w danych\n",
    "print(\"Kolumny:\", imdb_data['train'].column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4087b0dd",
   "metadata": {},
   "source": [
    "&#x20;MoÅ¼emy potwierdziÄ‡, jak sÄ… zakodowane etykiety:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12dc0992",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# SprawdÅºmy kilka pierwszych etykiet i ich znaczenie\n",
    "label_values = set(imdb_data['train']['label'])\n",
    "print(\"Unikalne etykiety w zbiorze:\", label_values)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a32031",
   "metadata": {},
   "source": [
    "&#x20;Z dokumentacji wiadomo, Å¼e w tym zbiorze:\n",
    "\n",
    "* **0** oznacza recenzjÄ™ negatywnÄ…,\n",
    "* **1** oznacza recenzjÄ™ pozytywnÄ….\n",
    "\n",
    "Teraz przyjrzyjmy siÄ™ przykÅ‚adowym danym. WyÅ›wietlimy przykÅ‚adowÄ… recenzjÄ™ i jej etykietÄ™"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119a146f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pobranie pierwszego przykÅ‚adu ze zbioru treningowego\n",
    "first_review = imdb_data['train'][0]\n",
    "print(\"Etykieta:\", first_review['label'])\n",
    "print(\"TreÅ›Ä‡ recenzji:\")\n",
    "print(first_review['text'][:500], \"...\")  # wypisz pierwsze 500 znakÃ³w"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800ca1e9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " \n",
    "**Pytanie:** PatrzÄ…c na powyÅ¼szÄ… recenzjÄ™, czy potrafisz na pierwszy rzut oka stwierdziÄ‡, czy jest pozytywna czy negatywna? ZwrÃ³Ä‡ uwagÄ™ na sÅ‚owa kluczowe, ktÃ³re mogÄ… zdradzaÄ‡ sentyment autora.\n",
    "\n",
    "SprÃ³bujmy jeszcze lepiej zrozumieÄ‡ dane:\n",
    "\n",
    "* Jak dÅ‚ugie sÄ… recenzje? Czy sÄ… to zdania, akapity, a moÅ¼e caÅ‚e eseje?\n",
    "* Czy recenzje zawierajÄ… duÅ¼o znakÃ³w interpunkcyjnych, wielkich liter, liczb itp.?\n",
    "* W jakim stylu sÄ… pisane (formalny/nieformalny, slang)?\n",
    "\n",
    "Te obserwacje przydadzÄ… nam siÄ™ przy planowaniu **przetwarzania tekstu**&#x20;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9dc8ee",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "\n",
    "### RozkÅ‚ad klas w zbiorze IMDb\n",
    "\n",
    "Zanim przejdziemy dalej, sprawdÅºmy, czy zbiÃ³r jest zrÃ³wnowaÅ¼ony. Tzn. czy mamy mniej wiÄ™cej tyle samo recenzji pozytywnych i negatywnych. Zrobimy szybkie zliczenie:\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22769770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Konwersja zbioru treningowego do pandas DataFrame dla Å‚atwej eksploracji\n",
    "df_train = pd.DataFrame(imdb_data['train'])\n",
    "df_test = pd.DataFrame(imdb_data['test'])\n",
    "\n",
    "# Zliczenie etykiet pozytywnych vs negatywnych\n",
    "print(df_train['label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84839a3b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Wynik powinien pokazaÄ‡ zbliÅ¼onÄ… liczbÄ™ `0` i `1`w zbiorze treningowym. Oznacza to, Å¼e klasy sÄ… zbalansowane â€“ to dobra informacja, bo model uczony na takich danych nie bÄ™dzie faworyzowaÅ‚ jednej klasy tylko dlatego, Å¼e jest jej wiÄ™cej.\n",
    "\n",
    "Analogicznie moÅ¼emy sprawdziÄ‡ zbiÃ³r testowy: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d32e86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_test['label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2f8831",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " ### Eksploracja danych â€“ przykÅ‚ady recenzji\n",
    "\n",
    "Przeczytajmy kilka losowych recenzji, aby zorientowaÄ‡ siÄ™ w zawartoÅ›ci. MoÅ¼emy wylosowaÄ‡ po jednej recenzji oznaczonej jako pozytywna i negatywna:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a47ac52",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Losowy pozytywny i losowy negatywny przykÅ‚ad z treningu\n",
    "positive_example = df_train[df_train['label'] == 1].sample(1)\n",
    "negative_example = df_train[df_train['label'] == 0].sample(1)\n",
    "\n",
    "print(\"PrzykÅ‚adowa pozytywna recenzja:\\n\", positive_example['text'].values[0][:300], \"...\\n\")\n",
    "print(\"PrzykÅ‚adowa negatywna recenzja:\\n\", negative_example['text'].values[0][:300], \"...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955e4944",
   "metadata": {},
   "source": [
    "ZwrÃ³Ä‡ uwagÄ™ na sÅ‚ownictwo w obu recenzjach. CzÄ™sto w pozytywnych opiniach pojawiajÄ… siÄ™ sÅ‚owa typu *\"great\", \"excellent\", \"amazing\"*, a w negatywnych *\"boring\", \"bad\", \"terrible\"*. OczywiÅ›cie nie jest to reguÅ‚a bezwyjÄ…tkowa â€“ model ML powinien siÄ™ tych zaleÅ¼noÅ›ci nauczyÄ‡ automatycznie.\n",
    "\n",
    "### Podstawowa statystyka: dÅ‚ugoÅ›Ä‡ recenzji\n",
    "\n",
    "SprawdÅºmy jeszcze Å›redniÄ… dÅ‚ugoÅ›Ä‡ recenzji w zbiorze IMDb. MoÅ¼emy policzyÄ‡ liczbÄ™ znakÃ³w lub sÅ‚Ã³w w kaÅ¼dej recenzji i znaleÅºÄ‡ Å›redniÄ… oraz medianÄ™. To da nam obraz, z jak dÅ‚ugim tekstem bÄ™dziemy pracowaÄ‡ (waÅ¼ne np. dla wydajnoÅ›ci przetwarzania)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4432a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oblicz dÅ‚ugoÅ›Ä‡ recenzji (w znakach) dla kilku przykÅ‚adÃ³w i Å›redniÄ… dla zbioru treningowego\n",
    "df_train['length_chars'] = df_train['text'].apply(len)\n",
    "print(\"PrzykÅ‚adowe dÅ‚ugoÅ›ci recenzji (w znakach):\", df_train['length_chars'].head().tolist())\n",
    "print(\"Åšrednia dÅ‚ugoÅ›Ä‡ recenzji:\", df_train['length_chars'].mean())\n",
    "print(\"Mediana dÅ‚ugoÅ›ci recenzji:\", df_train['length_chars'].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d652a43f",
   "metadata": {},
   "source": [
    "\n",
    "**Ä†wiczenie:** Zamiast liczby znakÃ³w, sprÃ³buj policzyÄ‡ **liczbÄ™ sÅ‚Ã³w** w recenzjach i ponownie policzyÄ‡ Å›redniÄ… oraz medianÄ™. WskazÃ³wka: MoÅ¼esz wykorzystaÄ‡ metodÄ™ `.split()` dzielÄ…cÄ… tekst po spacjach, aby przybliÅ¼onÄ… liczbÄ™ sÅ‚Ã³w (choÄ‡ nie jest to idealna metoda, o lepszej tokenizacji bÄ™dziemy mÃ³wiÄ‡ pÃ³Åºniej).\n",
    "\n",
    "*(UzupeÅ‚nij kod poniÅ¼ej, aby policzyÄ‡ Å›redniÄ… i medianÄ™ dÅ‚ugoÅ›ci recenzji w sÅ‚owach.)*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbba232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Oblicz dÅ‚ugoÅ›Ä‡ recenzji w sÅ‚owach dla zbioru treningowego i podaj Å›redniÄ… oraz medianÄ™.\n",
    "# PodpowiedÅº: dla kaÅ¼dego text w df_train['text'] wykonaj text.split() i policz len() listy wynikowej.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9155af6",
   "metadata": {},
   "source": [
    "Zazwyczaj recenzje filmowe IMDb sÄ… doÅ›Ä‡ obszerne (kilka zdaÅ„ do kilku akapitÃ³w). DÅ‚ugoÅ›Ä‡ tekstu moÅ¼e wpÅ‚ywaÄ‡ na wybÃ³r metod przetwarzania â€“ np. bardzo dÅ‚ugie dokumenty mogÄ… wymagaÄ‡ przyciÄ™cia lub podzielenia, ale w naszym przypadku raczej nie bÄ™dzie takiej potrzeby."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb20aa82",
   "metadata": {},
   "source": [
    "### Podsumowanie eksploracji\n",
    "\n",
    "Do tej pory:\n",
    "\n",
    "* ZaÅ‚adowaliÅ›my zbiÃ³r danych **IMDb** zawierajÄ…cy recenzje filmÃ³w oznaczone jako pozytywne lub negatywne.\n",
    "* PotwierdziliÅ›my rozmiar zbioru i rÃ³wnowagÄ™ klas.\n",
    "* ObejrzeliÅ›my przykÅ‚adowe recenzje â€“ widaÄ‡ rÃ³Å¼norodnoÅ›Ä‡ jÄ™zyka, obecnoÅ›Ä‡ emocjonalnych sÅ‚Ã³w, a czasem sarkazmu czy negacji.\n",
    "* PoliczyliÅ›my podstawowe statystyki (dÅ‚ugoÅ›Ä‡ recenzji), co daÅ‚o nam wyobraÅ¼enie o danych."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62dce291",
   "metadata": {},
   "source": [
    "## Quiz â€“ sprawdÅº swojÄ… wiedzÄ™\n",
    "\n",
    "1. **Co oznacza skrÃ³t NLP?**\n",
    "2. **WymieÅ„ dwa przykÅ‚ady zastosowaÅ„ NLP (innych niÅ¼ analiza sentymentu).**\n",
    "3. **Jakie znasz podstawowe podejÅ›cia do analizy sentymentu? KtÃ³re z nich bÄ™dziemy stosowaÄ‡ w tym kursie?**\n",
    "4. **Dlaczego przy analizie zbioru danych waÅ¼ne jest sprawdzenie rozkÅ‚adu klas (np. liczby opinii pozytywnych vs negatywnych)?**\n",
    "\n",
    "*ZastanÃ³w siÄ™ nad odpowiedziami. Odpowiedzi moÅ¼esz zapisaÄ‡ poniÅ¼ej we wÅ‚asnych sÅ‚owach.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c612a8b",
   "metadata": {},
   "source": [
    "**Twoje odpowiedzi:**\n",
    "\n",
    "* 1: ...\n",
    "* 2: ...\n",
    "* 3: ...\n",
    "* 4: ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e221a467",
   "metadata": {},
   "source": [
    "## Notatki wÅ‚asne\n",
    "\n",
    "*(PoniÅ¼ej moÅ¼esz zapisaÄ‡ wÅ‚asne notatki, spostrzeÅ¼enia lub podsumowanie. Ta sekcja jest dla Ciebie : ) .)*\n",
    "\n",
    "**Notatki:**\n",
    "\n",
    "* ...\n",
    "* ...\n",
    "* ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df828d1c",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Przetwarzanie tekstu â€“ czyszczenie, tokenizacja, stop words, lematyzacja/stemming. Reprezentacja: Bag-of-Words i TF-IDF\n",
    "\n",
    "## Cele edukacyjne\n",
    "\n",
    "* **Dowiesz siÄ™, dlaczego i jak czyÅ›ciÄ‡ dane tekstowe** â€“ usuwanie zbÄ™dnych znakÃ³w, standaryzacja (np. wielkoÅ›ci liter), podstawowe techniki przygotowania surowego tekstu.\n",
    "* **Nauczysz siÄ™ tokenizacji** â€“ podziaÅ‚u tekstu na tokeny (najczÄ™Å›ciej sÅ‚owa) jako pierwszy krok przeksztaÅ‚cania tekstu.\n",
    "* **Poznasz pojÄ™cie** ***stop words*** â€“ zrozumiesz, czym sÄ… tzw. \"sÅ‚owa nieniosÄ…ce treÅ›ci\" i jak je usuwaÄ‡, by nie zaciemniaÅ‚y analizy.\n",
    "* **Stemming i lematyzacja** â€“ dowiesz siÄ™, jak sprowadzaÄ‡ wyrazy do ich podstawowej formy (np. \"koty\" -> \"kot\") i po co to robimy.\n",
    "* **Reprezentacja Bag-of-Words (BoW)** â€“ zrozumiesz, jak tekst moÅ¼na zamieniÄ‡ na wektor liczbowy poprzez zliczanie wystÄ…pieÅ„ sÅ‚Ã³w.\n",
    "* **Reprezentacja TF-IDF** â€“ poznasz ulepszenie Bag-of-Words waÅ¼one czÄ™stoÅ›ciÄ… w dokumentach (TF-IDF) i zobaczysz, czemu jest przydatne w modelowaniu."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da7d592",
   "metadata": {},
   "source": [
    "Mamy zbiÃ³r recenzji filmowych (IMDb) z odpowiadajÄ…cymi im etykietami sentymentu. Jednak **surowy tekst** w takiej postaci nie jest bezpoÅ›rednio uÅ¼yteczny dla algorytmu uczenia maszynowego. Musimy go najpierw przeksztaÅ‚ciÄ‡.\n",
    "\n",
    "Typowy **pipeline** (proces) w zadaniach NLP wyglÄ…da nastÄ™pujÄ…co:\n",
    "\n",
    "1. **Czyszczenie danych tekstowych** â€“ usuniÄ™cie lub standaryzacja elementÃ³w, ktÃ³re mogÄ… przeszkadzaÄ‡ w analizie (np. HTML, znaki specjalne, liczby, emotikony, itp.), sprowadzenie tekstu do jednolitej formy.\n",
    "2. **Tokenizacja** â€“ rozbicie tekstu na mniejsze jednostki, najczÄ™Å›ciej sÅ‚owa (tokeny). Czasem stosuje siÄ™ teÅ¼ tokenizacjÄ™ na znaki, sylaby lub grupy wyrazÃ³w (n-gramy), ale tutaj skupimy siÄ™ na sÅ‚owach.\n",
    "3. **Usuwanie stop words** â€“ usuniÄ™cie z tokenÃ³w tzw. sÅ‚Ã³w pospolitych, ktÃ³re nie niosÄ… istotnego znaczenia dla zadania (np. \"i\", \"Å¼e\", \"to\"). DziÄ™ki temu redukujemy szum w danych.\n",
    "4. **Stemming / Lematyzacja** â€“ sprowadzenie odmienionych form wyrazÃ³w do ich rdzenia lub podstawowej formy sÅ‚ownikowej (np. \"pies\", \"psa\", \"psom\" -> \"pies\"). UmoÅ¼liwia to traktowanie wariantÃ³w tego samego sÅ‚owa jednakowo.\n",
    "5. **Tworzenie cech (feature extraction)** â€“ zamiana listy tokenÃ³w na cechy liczbowe, na ktÃ³rych moÅ¼e pracowaÄ‡ model. W klasycznym ujÄ™ciu bÄ™dzie to Bag-of-Words lub TF-IDF, ktÃ³re zaraz omÃ³wimy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e52ab8",
   "metadata": {},
   "source": [
    "##  Czyszczenie tekstu (text cleaning)\n",
    "\n",
    "Surowe dane tekstowe mogÄ… zawieraÄ‡ elementy, ktÃ³re utrudniajÄ… analizÄ™ lub nie wnoszÄ… nic istotnego. PrzykÅ‚ady:\n",
    "\n",
    "* Znaki interpunkcyjne (.,!?), ktÃ³re zwykle nie wpÅ‚ywajÄ… na sentyment (choÄ‡ np. wielokropek czy wykrzyknienia mogÄ… wzmacniaÄ‡ emocje, ale na poczÄ…tek je pominiemy).\n",
    "* Cyfry/liczby, daty â€“ raczej nie przydatne w zadaniu sentymentu.\n",
    "* HTML czy znaki specjalne (np. `&nbsp;`, `<br>` w tekÅ›cie recenzji webowych).\n",
    "* Wielkie litery na poczÄ…tku zdaÅ„ â€“ moÅ¼emy ujednoliciÄ‡ tekst do maÅ‚ych liter, Å¼eby \"Film\" i \"film\" nie byÅ‚y traktowane jako rÃ³Å¼ne tokeny.\n",
    "* Tzw. **szum** (ang. noise): ciÄ…gi znakÃ³w niebÄ™dÄ…ce sÅ‚owami, np. emotikony, hashtagi, adresy URL. (W recenzjach filmowych moÅ¼e nie byÄ‡ takich rzeczy, ale np. w tweetach czÄ™sto wystÄ™pujÄ…)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770a5576",
   "metadata": {},
   "source": [
    "\n",
    "**Nasze podejÅ›cie:** Na potrzeby naszego modelu zrealizujemy prostÄ… strategiÄ™ czyszczenia:\n",
    "\n",
    "* Zamienimy tekst na same **maÅ‚e litery**.\n",
    "* Usuniemy **znaki niealfanumeryczne** (wszystko poza literami i cyframi) lub zastÄ…pimy je spacjÄ…. To pozwoli pozbyÄ‡ siÄ™ interpunkcji.\n",
    "* Opcjonalnie: moÅ¼emy usunÄ…Ä‡ cyfry, ale w recenzjach filmÃ³w liczby (np. \"10/10\", \"1998\") mogÄ… wystÄ™powaÄ‡. Raczej nie sÄ… kluczowe dla sentymentu, wiÄ™c moÅ¼emy je usunÄ…Ä‡, Å¼eby uproÅ›ciÄ‡ sÅ‚ownik."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78cf7293",
   "metadata": {},
   "source": [
    "PowyÅ¼sze moÅ¼emy zrealizowaÄ‡ np. za pomocÄ… wyraÅ¼eÅ„ regularnych (biblioteka `re` w Pythonie) lub metod Å‚aÅ„cuchowych Pythona.\n",
    "\n",
    "StwÃ³rzmy funkcjÄ™ `clean_text()`, ktÃ³ra przyjmie ciÄ…g znakÃ³w (recenzjÄ™) i zwrÃ³ci wyczyszczony tekst:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8c76cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text: str) -> str:\n",
    "    # 1. Zamiana na maÅ‚e litery\n",
    "    text = text.lower()\n",
    "    # 2. UsuniÄ™cie znacznikÃ³w HTML (jeÅ›li sÄ…) poprzez usuniÄ™cie ciÄ…gÃ³w w < >\n",
    "    text = re.sub(r'<.*?>', ' ', text)\n",
    "    # 3. UsuniÄ™cie znakÃ³w nie-alfanumerycznych (pozostaw litery i cyfry, resztÄ™ zastÄ…p spacjÄ…)\n",
    "    text = re.sub(r'[^a-z0-9Ä…Ä‡Ä™Å‚Å„Ã³Å›ÅºÅ¼ ]+', ' ', text)  # dodatkowo polskie znaki, Å¼eby ich nie usuwaÄ‡ w polskich tekstach\n",
    "    # 4. UsuniÄ™cie nadmiarowych spacji (jeÅ›li wskutek powyÅ¼szych operacji pojawiÅ‚y siÄ™ wielokrotne spacje)\n",
    "    text = re.sub(r'\\\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "# Test funkcji clean_text na sztucznym przykÅ‚adzie\n",
    "raw_example = \"To jest <b>przykÅ‚adowy</b> TEKST!!! Zawiera %^ rÃ³Å¼ne dziwne znaki... oraz liczby 12345.\"\n",
    "print(\"Przed czyszczeniem: \", raw_example)\n",
    "print(\"Po czyszczeniu:    \", clean_text(raw_example))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01516eff",
   "metadata": {},
   "source": [
    "\n",
    "Po uruchomieniu testu powyÅ¼ej powinniÅ›my zobaczyÄ‡, Å¼e:\n",
    "\n",
    "* Wszystkie litery sÄ… maÅ‚e.\n",
    "* HTML (`<b>...</b>`) zniknÄ…Å‚.\n",
    "* Symbol `%^` i wielokrotne wykrzykniki zostaÅ‚y usuniÄ™te.\n",
    "* Liczby zostaÅ‚y zachowane (w powyÅ¼szym kodzie zachowujemy cyfry `0-9` â€“ moÅ¼na je usunÄ…Ä‡ zmieniajÄ…c wyraÅ¼enie regularne, ale na razie niech zostanÄ…).\n",
    "* CiÄ…gi spacji zostaÅ‚y zredukowane do pojedynczej spacji.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7b9630",
   "metadata": {},
   "source": [
    "**Uwaga:** Nasza funkcja `clean_text` jest doÅ›Ä‡ prosta. W praktyce czyszczenie moÅ¼na rozszerzaÄ‡:\n",
    "\n",
    "* MoÅ¼na by usunÄ…Ä‡ *stop words* juÅ¼ na etapie czyszczenia (my zrobimy to pÃ³Åºniej).\n",
    "* MoÅ¼na by zamieniaÄ‡ emotikony na sÅ‚owa oznaczajÄ…ce emocje (np. \":)\" -> \"emotikon\\_usmiech\").\n",
    "* MoÅ¼na by uÅ¼yÄ‡ biblioteki dedykowanej do czyszczenia tekstu (np. `beautifulsoup` do HTML, czy `emoji` do obsÅ‚ugi emotikon).\n",
    "* Dla jÄ™zyka polskiego: moÅ¼na pokusiÄ‡ siÄ™ o zamianÄ™ polskich liter diakrytycznych na ich podstawowe formy (Ä…->a, Ä‡->c, itd.), ale wtedy tracimy trochÄ™ informacji (lepiej tego nie robiÄ‡, by np. \"los\" i \"Å‚oÅ›\" nie staÅ‚y siÄ™ tym samym sÅ‚owem).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9952db62",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Na potrzeby naszego przykÅ‚Å‚adu obecna funkcja wystarczy.\n",
    "\n",
    "Teraz zastosujmy czyszczenie do naszych danych. WeÅºmy kilka surowych recenzji z IMDb i je wyczyÅ›Ä‡my, Å¼eby zobaczyÄ‡ rÃ³Å¼nicÄ™:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44a93f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_texts = df_train['text'].iloc[:2]\n",
    "for i, text in enumerate(sample_texts):\n",
    "    print(f\"Oryginalna recenzja {i+1} (skrÃ³cona):\\n{text[:100]}...\\n\")\n",
    "    print(f\"Po czyszczeniu:\\n{clean_text(text)[:100]}...\\n{'-'*40}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78cbc90",
   "metadata": {},
   "source": [
    "ZwrÃ³Ä‡ uwagÄ™, Å¼e tekst po czyszczeniu nadal wyglÄ…da jak zdania, ale nie ma w nim wielkich liter ani specjalnych znakÃ³w.\n",
    "\n",
    "**Ä†wiczenie:** ZastanÃ³w siÄ™, dlaczego usuwanie interpunkcji moÅ¼e czasem spowodowaÄ‡ utratÄ™ informacji. Czy potrafisz wymyÅ›liÄ‡ sytuacjÄ™, w ktÃ³rej interpunkcja albo emotikon niosÅ‚yby informacjÄ™ o sentymencie? (PodpowiedÅº: Wykrzyknienia lub pytajniki mogÄ… wzmacniaÄ‡ wydÅºwiÄ™k, np. \"Film byÅ‚ Å›wietny!!!\" vs \"Film byÅ‚ Å›wietny\"). W naszej prostej metodzie pomijamy ten aspekt â€“ moÅ¼esz zapisaÄ‡ swojÄ… odpowiedÅº/rozwaÅ¼ania poniÅ¼ej:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e694dc",
   "metadata": {},
   "source": [
    "\n",
    "**Twoje przemyÅ›lenia:** *(Czy interpunkcja moÅ¼e nieÅ›Ä‡ informacjÄ™ sentymentu?)*\n",
    "\n",
    "... (tu wpisz wÅ‚asne uwagi) ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bfb07dd",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Tokenizacja â€“ podziaÅ‚ tekstu na tokeny (sÅ‚owa)\n",
    "\n",
    "&#x20;                                           ![Tokenization â€” A complete guide. Natural Language Processing â€” NLP Fromâ€¦ |  by Utkarsh Kant | Medium](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSw-6MjlECiyaOc7aq2EDJJJbfowX2DDrhw3g\\&s \"Tokenization â€” A complete guide. Natural Language Processing â€” NLP Fromâ€¦ |  by Utkarsh Kant | Medium\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e415df72",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "MajÄ…c wyczyszczony tekst, nastÄ™pnym krokiem jest **tokenizacja**, czyli rozbicie ciÄ…gu znakÃ³w na listÄ™ tokenÃ³w. NajczÄ™Å›ciej jako token przyjmujemy sÅ‚owo (ciÄ…g liter miÄ™dzy spacjami), ale w praktyce definicja tokenu zaleÅ¼y od zadania:\n",
    "\n",
    "* W analize sentymentu zwykle tokenami sÄ… sÅ‚owa lub emotikony, czasem pary wyrazÃ³w (bigramy) teÅ¼ traktuje siÄ™ jako cechy.\n",
    "* W innych zastosowaniach tokenem moÅ¼e byÄ‡ pojedynczy znak (np. w modelach opartych o litery) lub caÅ‚e frazy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868fc689",
   "metadata": {},
   "source": [
    "\n",
    "My skupimy siÄ™ na tokenizacji sÅ‚Ã³w. W jÄ™zyku angielskim sprawa jest doÅ›Ä‡ prosta â€“ moÅ¼na w wiÄ™kszoÅ›ci przypadkÃ³w podzieliÄ‡ tekst na spacjach i znakach interpunkcyjnych. W jÄ™zyku polskim podobnie. Problemy pojawiajÄ… siÄ™ w jÄ™zykach takich jak chiÅ„ski (gdzie nie ma spacji miÄ™dzy wyrazami), ale tym nie bÄ™dziemy siÄ™ zajmowaÄ‡.\n",
    "\n",
    "Skorzystamy z narzÄ™dzi NLTK do tokenizacji zdaÅ„ w jÄ™z. angielskim. NLTK posiada funkcjÄ™ `word_tokenize`, ale wymaga ona pobrania modelu tokenizatora (co zrobiliÅ›my wyÅ¼ej `nltk.download('punkt')`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b762c29",
   "metadata": {},
   "source": [
    "Przetestujmy tokenizacjÄ™ na jednym zdaniu:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769c0397",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "test_sentence = \"Film byÅ‚ niesamowity, bardzo mi siÄ™ podobaÅ‚!\"\n",
    "tokens = word_tokenize(clean_text(test_sentence))\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66cf955",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "ZwrÃ³Ä‡ uwagÄ™: tokenizacja NLTK:\n",
    "\n",
    "* Podzieli zdanie na pojedyncze sÅ‚owa.\n",
    "* DomyÅ›lnie rozdzieli teÅ¼ znaki interpunkcyjne jako oddzielne tokeny, ale poniewaÅ¼ wyczyÅ›ciliÅ›my tekst z interpunkcji wczeÅ›niej, w tokenach bÄ™dÄ… tylko sÅ‚owa.\n",
    "\n",
    "W powyÅ¼szym przypadku (po czyszczeniu) zdanie `\"film byÅ‚ niesamowity bardzo mi siÄ™ podobaÅ‚\"` powinno daÄ‡ listÄ™ tokenÃ³w podobnÄ… do `[\"film\", \"byÅ‚\", \"niesamowity\", \"bardzo\", \"mi\", \"siÄ™\", \"podobaÅ‚\"]`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4494bfa8",
   "metadata": {},
   "source": [
    "**Uwaga:** WidaÄ‡ tu, Å¼e tokenizacja \"po naszemu\" zachowaÅ‚a formy odmienione (\"byÅ‚\", \"podobaÅ‚\"). PÃ³Åºniej zajmiemy siÄ™ sprowadzaniem do podstawowej formy, ale najpierw omÃ³wimy **stop words**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f18418e",
   "metadata": {},
   "source": [
    "### Tokenizacja caÅ‚ego zbioru\n",
    "\n",
    "Tokenizowanie kaÅ¼dej recenzji z osobna i przechowywanie list sÅ‚Ã³w jest moÅ¼liwe, ale niekonieczne w naszym pipeline'ie. Biblioteki takie jak scikit-learn majÄ… swoje wewnÄ™trzne tokenizatory (np. `CountVectorizer` potrafi sam podzieliÄ‡ tekst wedÅ‚ug wybranego wzorca, domyÅ›lnie po spacjach i podstawowej interpunkcji).\n",
    "\n",
    "**W tym notatniku** jednak wykonamy pewne kroki rÄ™cznie, by dobrze zrozumieÄ‡ proces. Na koniec pokaÅ¼emy, jak Vectorizer robi to automatycznie.\n",
    "\n",
    "Na razie zrÃ³bmy tak: weÅºmy kilka recenzji i zastosujmy peÅ‚en proces czyszczenie + tokenizacja, aby zobaczyÄ‡, jak nasze dane bÄ™dÄ… wyglÄ…daÅ‚y po tych operacjach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccbce426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PrzeksztaÅ‚cenie kilku przykÅ‚adowych recenzji na listy tokenÃ³w\n",
    "for text in df_train['text'].iloc[:3]:\n",
    "    cleaned = clean_text(text)\n",
    "    tokens = word_tokenize(cleaned)\n",
    "    print(\"Oryginalny tekst (skrÃ³cony):\", text[:60], \"...\")\n",
    "    print(\"Po tokenizacji:\", tokens[:10], \"...\\n\")  # wypisz pierwsze 10 tokenÃ³w dla zwiÄ™zÅ‚oÅ›ci\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909d381c",
   "metadata": {},
   "source": [
    "Wyniki pokazujÄ… nam, Å¼e tekst zostaÅ‚ rozbity na poszczegÃ³lne sÅ‚owa. WidaÄ‡ teÅ¼, Å¼e mogÄ… pojawiÄ‡ siÄ™ **stop words**, np. \"the\", \"was\", \"it\" w angielskim czy \"to\", \"siÄ™\" w polskim â€“ o tym za moment.\n",
    "\n",
    "**Zadanie:** ZastanÃ³w siÄ™, czy tokenizacja powinna byÄ‡ wykonywana przed czyszczeniem, czy po. W naszej kolejnoÅ›ci najpierw czyÅ›cimy (np. usuwamy interpunkcjÄ™), potem tokenizujemy. Co by siÄ™ staÅ‚o, gdybyÅ›my odwrÃ³cili kolejnoÅ›Ä‡? *(SprÃ³buj odpowiedzieÄ‡ w myÅ›lach lub zapisz poniÅ¼ej.)*\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7577a4d8",
   "metadata": {},
   "source": [
    "**OdpowiedÅº:**&#x20; \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd5ea13",
   "metadata": {},
   "source": [
    "## Stop words â€“ sÅ‚owa nieistotne\n",
    "\n",
    "&#x20;                           ![Stop Word Removal Techniques for NLP Models | Ifioque.com](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTWbjOhgpy4QOORgglw7DXzQb0FMSjIlwAqsQ\\&s \"Stop Word Removal Techniques for NLP Models | Ifioque.com\")\n",
    "\n",
    "**Stop words** to *czÄ™sto wystÄ™pujÄ…ce sÅ‚owa, ktÃ³re niosÄ… maÅ‚o treÅ›ciowych informacji*. W jÄ™zyku polskim sÄ… to np. \"i\", \"oraz\", \"ale\", \"to\", \"siÄ™\", \"w\", \"na\". W angielskim: \"and\", \"the\", \"but\", \"to\", \"in\", \"on\", itp. Te wyrazy gÅ‚Ã³wnie peÅ‚niÄ… funkcje gramatyczne. W kontekÅ›cie analizy sentymentu zazwyczaj nie wskazujÄ… na pozytywnÄ… czy negatywnÄ… opiniÄ™.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60bce33f",
   "metadata": {},
   "source": [
    "\n",
    "**Dlaczego je usuwaÄ‡?**\n",
    "\n",
    "PoniewaÅ¼ pojawiajÄ… siÄ™ w niemal kaÅ¼dym dokumencie, mogÄ… zdominowaÄ‡ statystyki i sprawiÄ‡, Å¼e wektorowa reprezentacja tekstu ma bardzo duÅ¼o cech, ktÃ³re nic nie wnoszÄ… (np. liczbÄ™ wystÄ…pieÅ„ \"the\" czy \"i\"). UsuwajÄ…c je, zmniejszamy wymiar danych i skupiamy siÄ™ na sÅ‚owach kluczowych (rzeczownikach, przymiotnikach, czasownikach zwiÄ…zanych z opiniÄ…).\n",
    "\n",
    "Scikit-learn i NLTK udostÄ™pniajÄ… gotowe listy stop words dla rÃ³Å¼nych jÄ™zykÃ³w. Skorzystamy z listy angielskiej z NLTK, a dla polskiego stworzymy krÃ³tkÄ… listÄ™ samodzielnie (NLTK nie ma gotowej listy dla polskiego)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4185f1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Lista angielskich stop words z NLTK\n",
    "stop_words_eng = set(stopwords.words('english'))\n",
    "print(\"Liczba stop words (angielski):\", len(stop_words_eng))\n",
    "print(\"PrzykÅ‚adowe stop words:\", list(stop_words_eng)[:10])\n",
    "\n",
    "# Definiujemy rÄ™cznie krÃ³tkÄ… listÄ™ polskich stop words (istniejÄ… biblioteki z gotowymi listami, np. stopwordsiso)\n",
    "stop_words_pl = {\"i\", \"w\", \"na\", \"siÄ™\", \"nie\", \"Å¼e\", \"to\", \"jest\", \"tam\", \"tu\", \"o\", \"a\", \"ale\", \"oraz\", \"jak\", \"tak\"}\n",
    "print(\"PrzykÅ‚adowe stop words (polski):\", list(stop_words_pl)[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76b9c02",
   "metadata": {},
   "source": [
    "Lista angielska ma zapewne ok. 200 sÅ‚Ã³w. Nasza polska jest bardzo skrÃ³cona dla ilustracji â€“ prawdziwa lista powinna byÄ‡ dÅ‚uÅ¼sza.\n",
    "\n",
    "Teraz, aby usunÄ…Ä‡ stop words z tokenÃ³w, moÅ¼emy po prostu przefiltrowaÄ‡ listÄ™ tokenÃ³w i wyrzuciÄ‡ z niej te, ktÃ³re znajdujÄ… siÄ™ na liÅ›cie stop words.\n",
    "\n",
    "Przetestujmy to na krÃ³tkim tekÅ›cie mieszanym:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760607b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = [\"to\", \"jest\", \"bardzo\", \"fajny\", \"film\"]\n",
    "tokens_filtered = [t for t in tokens if t not in stop_words_pl]\n",
    "print(\"Przed usuniÄ™ciem stop words:\", tokens)\n",
    "print(\"Po usuniÄ™ciu stop words:\", tokens_filtered)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb471782",
   "metadata": {},
   "source": [
    "\n",
    "W powyÅ¼szym przykÅ‚adzie token \"to\" i \"jest\" powinny zostaÄ‡ usuniÄ™te jako stop words, pozostawiajÄ…c \"bardzo\", \"fajny\", \"film\". OczywiÅ›cie \"bardzo\" to teÅ¼ czÄ™ste sÅ‚owo (przysÅ‚Ã³wek), ktÃ³re moÅ¼na by dodaÄ‡ do stop words, ale naszej krÃ³tkiej listy tam nie ma.\n",
    "\n",
    "Teraz zastosujmy usuwanie stop words w naszym pipeline. PoÅ‚Ä…czmy dotychczasowe kroki: **czyszczenie -> tokenizacja -> usuniÄ™cie stop words** dla przykÅ‚adowej recenzji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50ac64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = df_train['text'].iloc[0]  # pierwsza recenzja\n",
    "cleaned = clean_text(sample_text)\n",
    "tokens = word_tokenize(cleaned)\n",
    "tokens_no_stop = [t for t in tokens if t not in stop_words_eng]\n",
    "print(\"Oryginalny tekst:\", sample_text[:60], \"...\")\n",
    "print(\"Po czyszczeniu:\", cleaned[:60], \"...\")\n",
    "print(\"Tokeny (kilka pierwszych):\", tokens[:10])\n",
    "print(\"Tokeny po usuniÄ™ciu stop words (kilka pierwszych):\", tokens_no_stop[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e63ba8b",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Zaobserwuj, ile tokenÃ³w odpadÅ‚o jako stop words. W jÄ™zyku angielskim prawdopodobnie wiele \"the\", \"and\", \"of\" itp. zostaÅ‚o usuniÄ™tych. PozostaÅ‚y bardziej znaczÄ…ce sÅ‚owa.\n",
    "\n",
    "**Nota:** W bibliotekach takich jak `CountVectorizer` moÅ¼na ustawiÄ‡ parametr `stop_words='english'`, by automatycznie usuwaÄ‡ angielskie stop words podczas wektoryzacji, co czÄ™sto siÄ™ robi. My jednak przechodzimy krok po kroku manualnie, by zrozumieÄ‡ mechanizm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66fb6b0c",
   "metadata": {},
   "source": [
    "\n",
    "**Ä†wiczenie:** UsuÅ„ stop words ze zdania: *\"To byÅ‚ naprawdÄ™ Å›wietny film, ktÃ³ry bardzo mi siÄ™ podobaÅ‚.\"* Najpierw wyczyÅ›Ä‡ to zdanie funkcjÄ… `clean_text`, potem stokenizuj i przefiltruj uÅ¼ywajÄ…c zarÃ³wno listy polskich stop words (dla sÅ‚Ã³w \"to\", \"mi\", \"siÄ™\" etc.) jak i angielskich (to akurat polskie zdanie, wiÄ™c uÅ¼yj polskiej listy). Zapisz wynikowe tokeny.\n",
    "\n",
    "*(MoÅ¼esz wykonaÄ‡ to Ä‡wiczenie w poniÅ¼szej komÃ³rce kodu.)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51900e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: WyczyÅ›Ä‡ zdanie, tokenizuj i usuÅ„ stop words (PL) dla podanego przykÅ‚adowego zdania.\n",
    "test_sentence = \"To byÅ‚ naprawdÄ™ Å›wietny film, ktÃ³ry bardzo mi siÄ™ podobaÅ‚.\"\n",
    "# Tu wpisz kolejne kroki: clean_text, word_tokenize, filter stop_words_pl\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90cc806",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Stemming i lematyzacja\n",
    "\n",
    "![1.00](https://cdn.botpenguin.com/assets/website/Stemming_IR_346db34f6c.webp \"Stemming in NLP: Key Concepts and Fundamentals Explained\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92cee819",
   "metadata": {},
   "source": [
    "\n",
    "Kolejnym krokiem, ktÃ³ry **opcjonalnie** moÅ¼na zastosowaÄ‡, jest sprowadzenie tokenÃ³w do ich podstawowej formy. SÄ… dwie gÅ‚Ã³wne techniki:\n",
    "\n",
    "* **Stemming** â€“ ucina koÅ„cÃ³wki wyrazÃ³w wedÅ‚ug pewnych reguÅ‚, by sprowadziÄ‡ je do rdzenia (niekoniecznie poprawnego sÅ‚owa). Np. stemming w jÄ™z. angielskim: *\"playing\", \"played\", \"plays\"* -> *\"play\"*. W polskim: *\"kot\", \"koty\", \"kota\", \"kotem\"* -> moÅ¼e daÄ‡ *\"kot\"* (w zaleÅ¼noÅ›ci od algorytmu).\n",
    "* **Lematyzacja** â€“ wykorzystuje sÅ‚owniki i reguÅ‚y jÄ™zyka, by znaleÅºÄ‡ **lemma** czyli formÄ™ podstawowÄ…. Np. *\"went\"* -> *\"go\"*, *\"mice\"* -> *\"mouse\"*. W polskim *\"poszÅ‚am\"* -> *\"pÃ³jÅ›Ä‡\"*, *\"jabÅ‚ek\"* -> *\"jabÅ‚ko\"*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d58e60",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Stemming jest prostszy (nie wymaga znajomoÅ›ci jÄ™zyka), ale czasem obcina za duÅ¼o lub tworzy sztuczne formy. Lematyzacja jest dokÅ‚adniejsza, ale wymaga wiÄ™cej zasobÃ³w (sÅ‚owniki morfologiczne lub modele).\n",
    "\n",
    "W naszym projekcie zastosujemy **stemming** dla jÄ™zyka angielskiego jako przykÅ‚ad. Dla polskiego peÅ‚na lematyzacja wymagaÅ‚aby np. biblioteki *spaCy* z modelem pl lub *Morfeusz* â€“ to doÅ›Ä‡ ciÄ™Å¼kie jak na nasze potrzeby, wiÄ™c ograniczymy siÄ™ do Å›wiadomoÅ›ci, Å¼e takie narzÄ™dzia istniejÄ…. (Polskie teksty i tak przetworzymy w wersji bez lematyzacji, co teÅ¼ zadziaÅ‚a, tylko sÅ‚ownik cech bÄ™dzie wiÄ™kszy, bo np. \"film\" i \"filmu\" bÄ™dÄ… osobno).\n",
    "\n",
    "Skorzystamy z NLTK `PorterStemmer` lub `SnowballStemmer` dla angielskiego. SnowballStemmer jest uniwersalny i wspiera kilka jÄ™zykÃ³w (niestety polskiego brak). UÅ¼yjmy PorterStemmer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8b8822",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "words = [\"playing\", \"plays\", \"played\", \"player\", \"playingly\"]\n",
    "stemmed = [stemmer.stem(w) for w in words]\n",
    "print(\"SÅ‚owa oryginalne:  \", words)\n",
    "print(\"Po stemmingu:     \", stemmed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4bd948",
   "metadata": {},
   "source": [
    "Zobaczmy wynik:\n",
    "\n",
    "* \"playing\", \"plays\", \"played\" powinny wszystkie daÄ‡ \"play\".\n",
    "* \"player\" moÅ¼e daÄ‡ \"player\"&#x20;\n",
    "* \"playingly\" (niezbyt uÅ¼ywane sÅ‚owo) pewnie zostanie okrojone do \"playingli\" lub \"play\" â€“ tu widaÄ‡, Å¼e stemmer czasem robi dziwne rzeczy gdy sÅ‚owo jest nietypowe.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3602a8ce",
   "metadata": {},
   "source": [
    "Teraz `WordNetLemmatizer` wymaga znajomoÅ›ci czÄ™Å›ci mowy, inaczej lematyzuje do rzeczownika domyÅ›lnie:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e7b7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "words2 = [\"playing\", \"played\", \"cats\", \"better\"]\n",
    "lemmas = [lemmatizer.lemmatize(w) for w in words2]\n",
    "lemmas_verbs = [lemmatizer.lemmatize(w, pos='v') for w in words2]\n",
    "print(\"OryginaÅ‚y: \", words2)\n",
    "print(\"Lematy domyÅ›lne (rzeczowniki):\", lemmas)\n",
    "print(\"Lematy jako czasowniki:\", lemmas_verbs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3fec37",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Dla powyÅ¼szego:\n",
    "\n",
    "* DomyÅ›lnie: \"playing\" -> \"playing\" (bo traktuje jako rzeczownik, nie zmienia), \"played\" -> \"played\", \"cats\" -> \"cat\", \"better\" -> \"better\".\n",
    "* Jako czasowniki: \"playing\" -> \"play\", \"played\" -> \"play\", reszta bez zmian (\"better\" jako czasownik - \"better\" zostanie)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10632375",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Lematyzacja wiÄ™c wymaga pipeline'u, ktÃ³ry najpierw oznacza czÄ™Å›ci mowy (POS tagging) â€“ to wykracza poza nasz zakres. **W praktyce** w prostych modelach czÄ™sto wystarcza stemming zamiast peÅ‚nej lematyzacji, choÄ‡ jest mniej precyzyjny.\n",
    "\n",
    "&#x20;Zdecydujmy, Å¼e dla angielskich danych zastosujemy stemming, a dla polskich â€“ nie bÄ™dziemy robiÄ‡ stemmingu (brak narzÄ™dzia out-of-the-box w NLTK). Bez obaw â€“ modele i tak sobie poradzÄ…, tylko sÅ‚Ã³w bÄ™dzie trochÄ™ wiÄ™cej.\n",
    "\n",
    "Zaimplementujmy prostÄ… funkcjÄ™, ktÃ³ra wykona peÅ‚ne przetworzenie pojedynczego tekstu: **czyszczenie -> tokenizacja -> usuniÄ™cie stopwords -> stemming (dla angielskiego)**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9029ec1",
   "metadata": {},
   "source": [
    "\n",
    "W wyniku powinniÅ›my otrzymaÄ‡ listÄ™ tokenÃ³w, np. `[\"movi\", \"absolut\", \"wonder\", \"love\", \"act\", \"plot\"]`. ZauwaÅ¼, Å¼e po stemmingu powstajÄ… czasem niepeÅ‚ne sÅ‚owa (\"wonder\" zamiast \"wonderful\", \"movi\" zamiast \"movie\", \"love\" zamiast \"loved\"). Mimo to dla algorytmu liczÄ…cego frekwencje sÅ‚Ã³w, te formy bÄ™dÄ… konsistentne w caÅ‚ym korpusie.\n",
    "\n",
    "PodobnÄ… funkcjÄ™ moglibyÅ›my napisaÄ‡ dla polskiego, ale ograniczymy siÄ™ do czyszczenia, tokenizacji i usuniÄ™cia stopwords (bez stemmingu):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a98f206",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text_pl(text: str) -> list:\n",
    "    text_clean = clean_text(text)\n",
    "    tokens = word_tokenize(text_clean)\n",
    "    tokens = [t for t in tokens if t not in stop_words_pl]  # uÅ¼yjemy naszej ograniczonej listy polskiej\n",
    "    # Brak stemmingu/lematyzacji dla PL\n",
    "    return tokens\n",
    "\n",
    "print(preprocess_text_pl(\"Ten film byÅ‚ niesamowity, naprawdÄ™ mi siÄ™ podobaÅ‚!\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a547fc",
   "metadata": {},
   "source": [
    "\n",
    "To powinno zwrÃ³ciÄ‡ np. `[\"ten\", \"film\", \"byÅ‚\", \"niesamowity\", \"naprawdÄ™\", \"podobaÅ‚\"]` minus ewentualne stop words jeÅ›li pasujÄ… do listy (np. \"mi\", \"siÄ™\" powinny zostaÄ‡ usuniÄ™te).\n",
    "\n",
    "**Ä†wiczenie:** PomyÅ›l, jakie wyzwania wiÄ…Å¼Ä… siÄ™ z lematyzacjÄ… polskiego tekstu w porÃ³wnaniu do angielskiego. (PodpowiedÅº: Odmiana przez przypadki, rodzaje gramatyczne, zÅ‚oÅ¼ona gramatyka). Dlaczego proste \"ucinanie\" koÅ„cÃ³wek (stemming) moÅ¼e byÄ‡ trudne dla polskiego?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270adc12",
   "metadata": {},
   "source": [
    "\n",
    "*(Wpisz swoje przemyÅ›lenia poniÅ¼ej.)*\n",
    "\n",
    "**Twoje przemyÅ›lenia:**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f7d720",
   "metadata": {},
   "source": [
    "## Reprezentacja tekstu: Bag-of-Words\n",
    "![NLP: Bag of Words. The Bag of Words (BoW) model is aâ€¦ | by Rahul S | Medium](https://miro.medium.com/v2/resize:fit:661/0*cf1wq8eIix-Z2qIf.png \"NLP: Bag of Words. The Bag of Words (BoW) model is aâ€¦ | by Rahul S | Medium\")\n",
    "\n",
    "\n",
    "Mamy przygotowane i przetworzone tokeny â€“ czas zamieniÄ‡ je na **cechy liczbowe**. Klasyczne podejÅ›cie to **Bag-of-Words (torba sÅ‚Ã³w)**. W modelu tym:\n",
    "\n",
    "* Tworzymy **sÅ‚ownik wszystkich unikalnych tokenÃ³w** w naszym korpusie treningowym.\n",
    "* KaÅ¼demu tokenowi przypisujemy indeks kolumny.\n",
    "* Reprezentujemy kaÅ¼dy dokument (recenzjÄ™) jako wektor dÅ‚ugoÅ›ci = liczbie sÅ‚Ã³w w sÅ‚owniku. W tym wektorze w pozycji odpowiadajÄ…cej danemu sÅ‚owu wpisujemy np. liczbÄ™ wystÄ…pieÅ„ tego sÅ‚owa w dokumencie (lub 0, jeÅ›li nie wystÄ™puje)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2eb8177",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "### Tworzenie Bag-of-Words (BoW) w Pythonie\n",
    "\n",
    "\n",
    "MoÅ¼na to zrobiÄ‡ rÄ™cznie, ale wygodniej skorzystaÄ‡ z `CountVectorizer` z scikit-learn, ktÃ³ry:\n",
    "\n",
    "* Zbuduje sÅ‚ownik sÅ‚Ã³w (faza `fit`).\n",
    "* Zamieni listy tekstÃ³w na macierz czÄ™stoÅ›ci sÅ‚Ã³w (faza `transform`).\n",
    "\n",
    "PoniewaÅ¼ `CountVectorizer` sam wewnÄ™trznie dokonuje pewnej tokenizacji, moÅ¼emy mu po prostu podaÄ‡ surowe (ale wyczyszczone) teksty, a on resztÄ™ zrobi. Jednak, jeÅ›li chcemy mieÄ‡ wpÅ‚yw na tok preprocesingu (np. uÅ¼yÄ‡ naszego stemmera, itp.), moÅ¼emy teÅ¼ przekazaÄ‡ wektorizerowi juÅ¼ przetworzone tokeny zÅ‚Ä…czone znÃ³w w stringi.\n",
    "\n",
    "Aby nie komplikowaÄ‡, najpierw pokaÅ¼emy prosty uÅ¼ycie `CountVectorizer` *bez* wÅ‚asnego preprocessingu (on sam zrobi podstawowÄ… tokenizacjÄ™ i moÅ¼e usunÄ…Ä‡ stop words jeÅ›li chcemy). Potem porÃ³wnamy z naszym wÅ‚asnym przygotowaniem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266b7255",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# WeÅºmy prÃ³bkÄ™ 5 recenzji ze zbioru treningowego\n",
    "sample_texts = df_train['text'].iloc[:5].tolist()\n",
    "\n",
    "vectorizer = CountVectorizer(stop_words='english', max_features=20)\n",
    "# stop_words='english' spowoduje usuniÄ™cie angielskich stopwords automatycznie\n",
    "# max_features=20 ograniczy sÅ‚ownik do 20 najczÄ™Å›ciej wystÄ™pujÄ…cych sÅ‚Ã³w (tylko dla demonstracji)\n",
    "\n",
    "X_sample = vectorizer.fit_transform(sample_texts)\n",
    "print(\"Rozmiar macierzy cech:\", X_sample.shape)\n",
    "print(\"SÅ‚owa w sÅ‚owniku:\", vectorizer.get_feature_names_out())\n",
    "print(\"Macierz BoW (pierwsze 5 dokumentÃ³w, w formacie gÄ™stym):\\\\n\", X_sample.toarray())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b71b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(X_sample.toarray(),columns=vectorizer.get_feature_names_out(),index=[text[:100] for text in sample_texts])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a21fff",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Wynik:\n",
    "\n",
    "* Rozmiar macierzy cech to (5 dokumentÃ³w, 20 cech).\n",
    "* Wypisane sÅ‚owa w sÅ‚owniku to 20 najpopularniejszych sÅ‚Ã³w w tych 5 recenzjach (dajÄ…ce poglÄ…d, co siÄ™ czÄ™sto powtarza).\n",
    "* Macierz to piÄ™Ä‡ wektorÃ³w po 20 liczb. Np. jeÅ›li sÅ‚owo \"movie\" jest pierwsze w sÅ‚owniku, to pierwsza kolumna zawiera zliczenia sÅ‚owa \"movie\" w kaÅ¼dym z 5 dokumentÃ³w."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e9f2bc",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Warto zauwaÅ¼yÄ‡, Å¼e wiÄ™kszoÅ›Ä‡ wartoÅ›ci w tej macierzy to zapewne zera (bo kaÅ¼de zdanie zawiera tylko kilka z moÅ¼liwych sÅ‚Ã³w). Taka macierz Bag-of-Words jest **rzadka (sparse)**. `CountVectorizer` zwraca jÄ… jako sparse matrix (oszczÄ™dnie przechowywanÄ…). WywoÅ‚anie `.toarray()` konwertuje jÄ… do peÅ‚nej tablicy â€“ robiÄ…c to dla caÅ‚ego zbioru 25k dokumentÃ³w i tysiÄ™cy cech byÅ‚oby bardzo pamiÄ™cioÅ¼erne, dlatego unikamy tego na duÅ¼ych danych."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52483361",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "### Bag-of-Words na caÅ‚ym zbiorze IMDb\n",
    "\n",
    "Teraz zrÃ³bmy wektoryzacjÄ™ dla caÅ‚ego naszego zbioru treningowego (25k recenzji). SÅ‚ownik bÄ™dzie spory â€“ moÅ¼na ograniczyÄ‡ do np. 10k najczÄ™stszych sÅ‚Ã³w (`max_features=10000`), co czasem pomaga modelom i wydajnoÅ›ci. Tutaj zrÃ³bmy np. 5000 dla demonstracji, by nie byÅ‚o za ciÄ™Å¼ko."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12e1659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wektorowanie caÅ‚ego zbioru treningowego IMDb\n",
    "vectorizer_full = CountVectorizer(stop_words='english', max_features=5000)\n",
    "X_train_bow = vectorizer_full.fit_transform(df_train['text'])  # uÅ¼ywamy oryginalnych tekstÃ³w, a vectorizer sam wyczyÅ›ci/tokenizuje prosto\n",
    "\n",
    "print(\"Liczba cech (sÅ‚Ã³w) w sÅ‚owniku:\", len(vectorizer_full.get_feature_names_out()))\n",
    "print(\"PrzykÅ‚adowe sÅ‚owa:\", vectorizer_full.get_feature_names_out()[:10])\n",
    "print(\"Macierz BoW - rozmiar:\", X_train_bow.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046b7f6c",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Ta operacja moÅ¼e chwilÄ™ potrwaÄ‡ (przetwarza 25k dokumentÃ³w, buduje sÅ‚ownik 5000 sÅ‚Ã³w). Po wykonaniu:\n",
    "\n",
    "* Zobaczymy potwierdzenie, Å¼e cech jest 5000 (nasze ograniczenie).\n",
    "* Pierwsze 10 sÅ‚Ã³w (zapewne najbardziej popularnych): zwykle w recenzjach filmowych to mogÄ… byÄ‡ sÅ‚owa typu \"film\", \"movie\", \"one\", \"like\", \"good\", \"bad\" itp. (choÄ‡ uwaga: `stop_words='english'` usunÄ™Å‚o \"the\", \"and\" itd., wiÄ™c ich nie bÄ™dzie).\n",
    "* Rozmiar macierzy: (25000, 5000)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b665c70",
   "metadata": {},
   "source": [
    "\n",
    "Teraz moÅ¼emy rÃ³wnieÅ¼ przeksztaÅ‚ciÄ‡ zbiÃ³r testowy do takiej samej reprezentacji (uÅ¼ywajÄ…c `transform` na juÅ¼ wytrenowanym vectorizerze â€“ **nie fitujemy ponownie na teÅ›cie!**, aby sÅ‚ownik pozostaÅ‚ staÅ‚y):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9401bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_bow = vectorizer_full.transform(df_test['text'])\n",
    "print(\"Rozmiar macierzy BoW dla testu:\", X_test_bow.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b609ad",
   "metadata": {},
   "source": [
    "MajÄ…c `X_train_bow` i `X_test_bow`, a takÅ¼e odpowiadajÄ…ce im etykiety `y_train` i `y_test` (ktÃ³re mamy w `df_train['label']` itd.), jesteÅ›my gotowi do trenowania modeli (co zrobimy w notatniku 3).\n",
    "\n",
    "Jednak zanim przejdziemy do modeli, warto poznaÄ‡ jeszcze jednÄ… reprezentacjÄ™, ktÃ³ra czÄ™sto daje lepsze wyniki niÅ¼ goÅ‚e BoW: **TF-IDF**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c162db49",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "## Reprezentacja TF-IDF\n",
    "\n",
    "![TF-IDF Defined - KDnuggets](https://www.kdnuggets.com/wp-content/uploads/arya-tf-idf-defined-0-1024x573.png \"TF-IDF Defined - KDnuggets\")\n",
    "\n",
    "TF-IDF (Term Frequencyâ€“Inverse Document Frequency) to modyfikacja Bag-of-Words, ktÃ³ra oprÃ³cz czÄ™stoÅ›ci sÅ‚owa w dokumencie (TF) uwzglÄ™dnia takÅ¼e **uniwersalnoÅ›Ä‡** sÅ‚owa w caÅ‚ym korpusie (DF â€“ document frequency).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013f6e98",
   "metadata": {},
   "source": [
    "Intuicja:\n",
    "\n",
    "* JeÅ›li sÅ‚owo pojawia siÄ™ w **wielu dokumentach**, to jego zdolnoÅ›Ä‡ do rozrÃ³Å¼niania dokumentÃ³w jest maÅ‚a (np. sÅ‚owo \"film\" pojawi siÄ™ prawie we wszystkich recenzjach filmu â€“ nie mÃ³wi czy recenzja jest pozytywna czy negatywna).\n",
    "* TF-IDF obniÅ¼a wagÄ™ takich sÅ‚Ã³w poprzez mnoÅ¼enie TF przez IDF (inverse document frequency), ktÃ³re jest niÅ¼sze dla sÅ‚Ã³w wystÄ™pujÄ…cych w wielu dokumentach."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcef59aa",
   "metadata": {},
   "source": [
    "WzÃ³r (nie musisz go pamiÄ™taÄ‡ na pamiÄ™Ä‡, ale warto znaÄ‡ ogÃ³lny ksztaÅ‚t):\n",
    "\n",
    "$$\n",
    "tf\\text{-}idf(t,d) = tf(t,d) \\times \\log \\frac{N}{df(t)}\n",
    "$$\n",
    "\n",
    "gdzie:\n",
    "\n",
    "- $tf(t, d)$ â€“ liczba wystÄ…pieÅ„ sÅ‚owa $t$ w dokumencie $d$ (czasem uÅ¼ywa siÄ™ czÄ™stotliwoÅ›ci wzglÄ™dnej),\n",
    "- $df(t)$ â€“ liczba dokumentÃ³w, w ktÃ³rych sÅ‚owo $t$ wystÄ™puje,\n",
    "- $N$ â€“ liczba dokumentÃ³w w korpusie.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6380b591",
   "metadata": {},
   "source": [
    "Logarytm sprawia, Å¼e wpÅ‚yw \\$df\\$ jest znoszony w skali log (im rzadsze sÅ‚owo, tym wiÄ™ksze \\$\\log(N/df)\\$).\n",
    "\n",
    "W praktyce nie liczymy tego rÄ™cznie â€“ znÃ³w posÅ‚uÅ¼y nam narzÄ™dzie z scikit-learn: `TfidfVectorizer`, uÅ¼ywany podobnie do CountVectorizer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1525a548",
   "metadata": {},
   "source": [
    "SprÃ³bujmy na maÅ‚ym przykÅ‚adzie porÃ³wnaÄ‡ BoW vs TF-IDF:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24926d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "sample_texts = [\n",
    "    \"I love this movie movie movie\",\n",
    "    \"This movie was bad and boring\",\n",
    "    \"What a great movie!\"\n",
    "]\n",
    "vect_count = CountVectorizer(stop_words='english')\n",
    "vect_tfidf = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "X_count = vect_count.fit_transform(sample_texts).toarray()\n",
    "X_tfidf = vect_tfidf.fit_transform(sample_texts).toarray()\n",
    "\n",
    "print(\"SÅ‚ownik:\", vect_count.get_feature_names_out())\n",
    "print(\"BoW zliczenia:\\n\", X_count)\n",
    "print(\"TF-IDF wartoÅ›ci:\\n\", np.round(X_tfidf, 2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8e2b23",
   "metadata": {},
   "source": [
    "\n",
    "PorÃ³wnujÄ…c:\n",
    "\n",
    "* W BoW macierzy zobaczymy czyste liczby (np. sÅ‚owo \"movie\" moÅ¼e mieÄ‡ liczbÄ™ 3 w pierwszym zdaniu).\n",
    "* W TF-IDF macierzy zobaczymy wartoÅ›ci uÅ‚amkowe. SÅ‚owo \"movie\" w pierwszym dokumencie dostanie doÅ›Ä‡ wysokÄ… wartoÅ›Ä‡ TF-IDF (bo TF=3, ale teÅ¼ wystÄ™puje w wszystkich 3 dokumentach, wiÄ™c IDF trochÄ™ to obniÅ¼y). W drugim i trzecim dokumencie \"movie\" ma TF=1, ale w trzecim dokumencie to jedyne sÅ‚owo prawie, wiÄ™c tam TF-IDF moÅ¼e byÄ‡ najwyÅ¼sze.\n",
    "\n",
    "WidaÄ‡ teÅ¼, Å¼e sÅ‚owo, ktÃ³re jest unikalne dla jednego dokumentu dostanie wyÅ¼szÄ… wagÄ™ niÅ¼ sÅ‚owo, ktÃ³re pojawia siÄ™ wszÄ™dzie."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b773fa0",
   "metadata": {},
   "source": [
    "\n",
    "### TF-IDF na naszych danych\n",
    "\n",
    "Zastosujmy TfidfVectorizer podobnie jak CountVectorizer wczeÅ›niej, na peÅ‚nym zbiorze treningowym IMDb:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26be649f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(df_train['text'])\n",
    "X_test_tfidf = tfidf_vectorizer.transform(df_test['text'])\n",
    "\n",
    "print(\"Macierz TF-IDF - rozmiar:\", X_train_tfidf.shape)\n",
    "print(\"PrzykÅ‚adowe cechy:\", tfidf_vectorizer.get_feature_names_out()[:10])\n",
    "print(\"WartoÅ›ci TF-IDF (fragment dla 1. dokumentu):\", X_train_tfidf[0, :10].toarray())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef483951",
   "metadata": {},
   "source": [
    "\n",
    "Macierz TF-IDF bÄ™dzie tego samego wymiaru (25000, 5000). RÃ³Å¼ni siÄ™ tylko wartoÅ›ciami wewnÄ…trz.\n",
    "\n",
    "**WaÅ¼ne:** TF-IDF rÃ³wnieÅ¼ zwraca macierz rzadkÄ…. Nie przeksztaÅ‚camy jej do peÅ‚nej tablicy jeÅ›li nie musimy.\n",
    "\n",
    "Z punktu widzenia modeli uczenia, TF-IDF to po prostu inny zestaw cech. Wiele algorytmÃ³w (w tym Naive Bayes, regresja logistyczna) czÄ™sto dziaÅ‚a lepiej z TF-IDF niÅ¼ czystym BoW, ale to zaleÅ¼y od danych. MoÅ¼na teÅ¼ prÃ³bowaÄ‡ uÅ¼ywaÄ‡ obu na raz lub dodatkowych pomysÅ‚Ã³w (np. cecha czy w tekscie wystÄ…piÅ‚ wykrzyknik, dÅ‚ugoÅ›Ä‡ tekstu itp., ale nie bÄ™dziemy tego tutaj robiÄ‡)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bbfa208",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Podsumowanie przetwarzania tekstu\n",
    "\n",
    "PrzeszliÅ›my przez kluczowe etapy przygotowania danych tekstowych:\n",
    "\n",
    "* WyczyÅ›ciliÅ›my tekst (lowercase, usuniÄ™cie znakÃ³w specjalnych).\n",
    "* PodzieliliÅ›my na tokeny (sÅ‚owa).\n",
    "* UsunÄ™liÅ›my stop words, ktÃ³re najczÄ™Å›ciej nie wnoszÄ… informacji.\n",
    "* (Opcjonalnie) ZastosowaliÅ›my stemming/lematyzacjÄ™, by ujednoliciÄ‡ formy wyrazÃ³w.\n",
    "* ZamieniliÅ›my przetworzone teksty na reprezentacje numeryczne:\n",
    "\n",
    "  * Bag-of-Words (wystÄ…pienia sÅ‚Ã³w),\n",
    "  * TF-IDF (waÅ¼one wystÄ…pienia sÅ‚Ã³w)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55cdbc6",
   "metadata": {},
   "source": [
    "\n",
    "Mamy teraz gotowe cechy, na podstawie ktÃ³rych moÅ¼emy trenowaÄ‡ model uczÄ…cy siÄ™ odrÃ³Å¼niaÄ‡ opinie pozytywne od negatywnych.\n",
    "\n",
    "Teraz zajmiemy siÄ™ trenowaniem modeli: uÅ¼yjemy **Naiwnego Bayesa** i **Regresji Logistycznej**, a nastÄ™pnie ocenimy ich skutecznoÅ›Ä‡ na zbiorze testowym.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a34873",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Pytania:**\n",
    "* Dlaczego usuwamy stop words i jaki to ma wpÅ‚yw na wielkoÅ›Ä‡ sÅ‚ownika cech.\n",
    "* Czym rÃ³Å¼ni siÄ™ stemming od lematyzacji (i czemu nie zawsze jest Å‚atwo lematyzowaÄ‡).\n",
    "* Jak w wektorze BoW/TF-IDF reprezentowane sÄ… dokumenty (co znaczÄ… poszczegÃ³lne wartoÅ›ci).\n",
    "* Co oznacza skrÃ³t TF-IDF na intuicyjnym poziomie."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a788bd1",
   "metadata": {},
   "source": [
    "## Quiz â€“ utrwalenie pojÄ™Ä‡\n",
    "\n",
    "1. **Dlaczego warto sprowadzaÄ‡ tekst do maÅ‚ych liter przed analizÄ…?**\n",
    "2. **Podaj trzy przykÅ‚ady** ***stop words*** **w jÄ™zyku polskim.**\n",
    "3. **Co to jest stemming?** (wyjaÅ›nij wÅ‚asnymi sÅ‚owami)\n",
    "4. **W modelu Bag-of-Words, czy kolejnoÅ›Ä‡ sÅ‚Ã³w w dokumencie ma znaczenie?**\n",
    "5. **ZaÅ‚Ã³Å¼my, Å¼e sÅ‚owo wystÄ™puje we wszystkich dokumentach w korpusie. JakÄ… mniej wiÄ™cej wartoÅ›Ä‡ TF-IDF to sÅ‚owo otrzyma?** (wysokÄ… czy niskÄ… i dlaczego?)\n",
    "\n",
    "**Twoje odpowiedzi:**\n",
    "\n",
    "1. ...\n",
    "2. ...\n",
    "3. ...\n",
    "4. ...\n",
    "5. ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c721c67",
   "metadata": {},
   "source": [
    "## Ä†wiczenia praktyczne\n",
    "\n",
    "* **Ä†wiczenie 1:** Zaimportuj drugi zbiÃ³r danych (polskojÄ™zyczny, np. recenzje z PolEmo 2.0) podobnie jak zrobiliÅ›my to dla IMDb. Wczytaj dane i sprawdÅº ich rozmiar oraz przykÅ‚adowe wpisy. *(WskazÃ³wka: uÅ¼yj* *`load_dataset(\"clarin-pl/polemo2-official\")`* *analogicznie do IMDb. Zobacz* *`dataset['train']`* *i* *`dataset['test']`.)*\n",
    "* **Ä†wiczenie 2:** Zastosuj funkcje przetwarzajÄ…ce tekst do kilku polskich recenzji. ZwrÃ³Ä‡ uwagÄ™ na rÃ³Å¼nice: czy nasza funkcja `clean_text` z polskimi znakami dziaÅ‚a poprawnie? Czy lista `stop_words_pl` powinna zostaÄ‡ rozszerzona o dodatkowe sÅ‚owa, ktÃ³re widzisz w danych? Zanotuj kilka obserwacji.\n",
    "* **Ä†wiczenie 3:** Wektoruj polskie recenzje za pomocÄ… `CountVectorizer` (jeÅ›li dane sÄ… duÅ¼e, moÅ¼esz ustawiÄ‡ `max_features` na kilka tysiÄ™cy). PorÃ³wnaj najczÄ™stsze sÅ‚owa w polskim zbiorze z tymi z angielskiego IMDb â€“ czy sÄ… to gÅ‚Ã³wnie stop words, czy pojawiajÄ… siÄ™ konkretne sÅ‚owa zwiÄ…zane z ocenÄ… (np. \"dobry\", \"Å›wietny\", \"nudny\")? Co to mÃ³wi o danych?\n",
    "\n",
    "*(MoÅ¼esz wykorzystaÄ‡ poniÅ¼sze komÃ³rki na powyÅ¼sze Ä‡wiczenia.)*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a647ec8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TODO: Ä†wiczenie 1 â€“ wczytaj polski zbiÃ³r danych i przeanalizuj podstawowe informacje (wielkoÅ›Ä‡, przykÅ‚ady).\n",
    "\n",
    "\n",
    "# TODO: Ä†wiczenie 2 â€“ zastosuj preprocess_text_pl do kilku polskich recenzji i przeanalizuj wyniki.\n",
    "\n",
    "\n",
    "# TODO: Ä†wiczenie 3 â€“ CountVectorizer na polskich danych, analiza najczÄ™stszych sÅ‚Ã³w.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6060b8d",
   "metadata": {},
   "source": [
    "\n",
    "## Notatki wÅ‚asne\n",
    "\n",
    "*(Zanotuj tutaj swoje wÅ‚asne podsumowanie, rzeczy do zapamiÄ™tania, pytania.)*\n",
    "\n",
    "* ...\n",
    "* ...\n",
    "* ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b569a8a0",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Trenowanie modelu klasyfikacji sentymentu â€“ Naive Bayes i Logistic Regression\n",
    "\n",
    "## Cele edukacyjne\n",
    "\n",
    "* **Przygotowanie danych do modelowania** â€“ przypomnisz sobie uzyskane wektory cech (BoW/TF-IDF) i etykiety, ewentualnie dokonasz drobnego przygotowania (podziaÅ‚ na train/test, filtrowanie klas jeÅ›li potrzebne).\n",
    "* **Poznasz algorytm Naiwnego Bayesa (Multinomial Naive Bayes)** â€“ zrozumiesz w intuicyjny sposÃ³b, jak wykorzystuje prawdopodobieÅ„stwa sÅ‚Ã³w do klasyfikacji tekstu.\n",
    "* **Poznasz algorytm Regresji Logistycznej** â€“ dowiesz siÄ™, Å¼e to model liniowy potrafiÄ…cy przewidywaÄ‡ prawdopodobieÅ„stwo klasy, i jest czÄ™sto uÅ¼ywany w zadaniach NLP.\n",
    "* **Nauczysz siÄ™ trenowaÄ‡ modele ML w scikit-learn** â€“ utworzysz model, dopasujesz go do danych treningowych, dokonasz predykcji na danych testowych.\n",
    "* **Ocena modelu** â€“ dowiesz siÄ™, jak oceniÄ‡ skutecznoÅ›Ä‡ modelu: miara dokÅ‚adnoÅ›ci (accuracy), macierz pomyÅ‚ek; porÃ³wnasz wyniki modeli.\n",
    "* **Ä†wiczenia i eksperymenty** â€“ samodzielnie sprawdzisz wpÅ‚yw pewnych zmian (np. inny typ reprezentacji cech, tuning parametrÃ³w) na dziaÅ‚anie modeli, przetestujesz model na nowych przykÅ‚adach tekstu."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda210b2",
   "metadata": {},
   "source": [
    "## Przygotowanie danych\n",
    "\n",
    "Mamy juÅ¼ zebrane cechy tekstowe ze zbioru recenzji IMDb (w jÄ™zyku angielskim). Przypomnijmy:\n",
    "\n",
    "* ZbiÃ³r **treningowy**: 25Â 000 recenzji, z ktÃ³rych kaÅ¼da jest reprezentowana jako wektor cech (np. 5000-cechowy wektor TF-IDF lub BoW) i ma etykietÄ™ 0 lub 1 (negatywna/pozytywna).\n",
    "* ZbiÃ³r **testowy**: 25Â 000 recenzji, rÃ³wnieÅ¼ przekonwertowanych do tej samej przestrzeni cech, posÅ‚uÅ¼y nam do niezaleÅ¼nej oceny modeli.\n",
    "\n",
    "Przypiszmy `y_train` i `y_test`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba3866d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_train['label'].to_numpy()\n",
    "y_test = df_test['label'].to_numpy()\n",
    "\n",
    "print(\"PrzykÅ‚adowe etykiety treningowe:\", y_train[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6f0c59",
   "metadata": {},
   "source": [
    "Upewnijmy siÄ™, Å¼e rozmiary siÄ™ zgadzajÄ… z macierzami cech:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d00d23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Rozmiar X_train, y_train:\", X_train_tfidf.shape, y_train.shape)\n",
    "print(\"Rozmiar X_test, y_test:\", X_test_tfidf.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1927214",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "JeÅ›li wszystko jest w porzÄ…dku, moÅ¼emy przejÅ›Ä‡ do trenowania modeli.\n",
    "\n",
    "> Uwaga (dotyczÄ…ca drugiego zbioru danych): JeÅ›li chcesz rÃ³wnolegle przeÄ‡wiczyÄ‡ uÅ¼ycie polskiego zbioru recenzji, moÅ¼esz powtÃ³rzyÄ‡ proces przetwarzania i wektoryzacji rÃ³wnieÅ¼ dla niego. Dla przejrzystoÅ›ci, w dalszej czÄ™Å›ci notatnika skupimy siÄ™ na danych IMDb (angielskich), ale w sekcji Ä‡wiczeÅ„ zachÄ™cam do sprawdzenia modeli takÅ¼e na polskich danych. Dodatkowo, jeÅ›li polski zbiÃ³r ma wiÄ™cej niÅ¼ dwie kategorie (np. PolEmo 2.0 ma 4 kategorie: pozytywne, negatywne, neutralne, mieszane), moÅ¼na rozwaÅ¼yÄ‡ filtracjÄ™ do dwÃ³ch gÅ‚Ã³wnych (pozytywne vs negatywne) dla porÃ³wnywalnoÅ›ci â€“ o czym jeszcze wspomnimy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369d40e8",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Multinomial Naive Bayes â€“ intuicja dziaÅ‚ania\n",
    "\n",
    "\n",
    "\n",
    "**Naiwny klasyfikator Bayesowski** to rodzina prostych modeli probabilistycznych. \"Naiwny\" â€“ bo zakÅ‚ada niezaleÅ¼noÅ›Ä‡ cech od siebie, co w przypadku sÅ‚Ã³w w zdaniu jest zaÅ‚oÅ¼eniem uproszczonym (sÅ‚owa w zdaniu oczywiÅ›cie nie sÄ… w peÅ‚ni niezaleÅ¼ne). Mimo tego zaÅ‚oÅ¼enia, model czÄ™sto sprawdza siÄ™ zaskakujÄ…co dobrze.\n",
    "\n",
    "Wariant **Multinomial Naive Bayes** jest dostosowany do cech bÄ™dÄ…cych zliczeniami (jak sÅ‚owa). Intuicja:\n",
    "\n",
    "* Dla kaÅ¼dej klasy (pozytywne/negatywne) obliczamy prawdopodobieÅ„stwa wystÄ…pienia danego sÅ‚owa w tej klasie na podstawie danych treningowych.\n",
    "* Aby obliczyÄ‡ prawdopodobieÅ„stwo, Å¼e nowy dokument jest np. pozytywny, model mnoÅ¼y (aproksymuje) prawdopodobieÅ„stwa wszystkich sÅ‚Ã³w w dokumencie pod warunkiem klasy pozytywnej oraz *prior* klasy (np. czÄ™stoÅ›Ä‡ pozytywnych w treningu).\n",
    "* MÃ³wiÄ…c proÅ›ciej: NB sprawdza, do ktÃ³rej klasy dokument \"bardziej pasuje\" pod wzglÄ™dem uÅ¼ytych sÅ‚Ã³w.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06a73e9",
   "metadata": {},
   "source": [
    "\n",
    "![Multinomial Naive Bayes Explained: Function, Advantages & Disadvantages,  Applications](https://ik.imagekit.io/upgrad1/abroad-images/imageCompo/images/Picture2SWG591.png?pr-true \"Multinomial Naive Bayes Explained: Function, Advantages & Disadvantages,  Applications\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69774dd7",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "PrzykÅ‚ad uproszczony: JeÅ›li sÅ‚owo \"great\" jest 10 razy czÄ™stsze w pozytywnych recenzjach niÅ¼ w negatywnych, a sÅ‚owo \"boring\" jest czÄ™stsze w negatywnych, to:\n",
    "\n",
    "* Dokument zawierajÄ…cy \"great\" bÄ™dzie miaÅ‚ wyÅ¼sze prawdopodobieÅ„stwo bycia pozytywnym (pomnoÅ¼y siÄ™ wysoki warunek dla \"great|positive\").\n",
    "* Dokument z \"boring\" â€“ wyÅ¼sze prawdopodobieÅ„stwo bycia negatywnym.\n",
    "\n",
    "OczywiÅ›cie model weÅºmie pod uwagÄ™ **wszystkie sÅ‚owa** i zbalansuje te wskazÃ³wki.\n",
    "\n",
    "Nie zagÅ‚Ä™biamy siÄ™ tu w wzory Bayesa (choÄ‡ sÄ… Å‚adne): waÅ¼ne Å¼e NB sprowadza siÄ™ do bardzo szybkiego zliczania i porÃ³wnywania czÄ™stoÅ›ci sÅ‚Ã³w.\n",
    "\n",
    "Scikit-learn udostÄ™pnia implementacjÄ™ `MultinomialNB` w module `naive_bayes`. BÄ™dziemy go uÅ¼ywaÄ‡.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c78a4d",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Trenowanie modelu Naive Bayes\n",
    "\n",
    "ZaÅ‚Ã³Å¼my, Å¼e bÄ™dziemy uÅ¼ywaÄ‡ reprezentacji **TF-IDF** jako cech (moÅ¼na teÅ¼ sprÃ³bowaÄ‡ BoW â€“ NB czÄ™sto dobrze radzi sobie z czystymi zliczeniami).\n",
    "\n",
    "StwÃ³rzmy i wytrenujmy model NB na zbiorze treningowym:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5004d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Inicjalizacja modelu NB\n",
    "nb_model = MultinomialNB()\n",
    "# Trenowanie modelu (dopasowanie do danych treningowych)\n",
    "nb_model.fit(X_train_tfidf, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92cf03a",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Model siÄ™ trenuje bardzo szybko (NB jest wydajny nawet na duÅ¼e zbiory).\n",
    "\n",
    "Teraz dokonamy predykcji na zbiorze testowym i obliczymy **dokÅ‚adnoÅ›Ä‡ (accuracy)**, czyli odsetek poprawnie zaklasyfikowanych recenzji.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7c1428",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Predykcja na danych testowych\n",
    "y_pred_nb = nb_model.predict(X_test_tfidf)\n",
    "# Obliczenie accuracy\n",
    "acc_nb = accuracy_score(y_test, y_pred_nb)\n",
    "print(f\"DokÅ‚adnoÅ›Ä‡ (accuracy) Naive Bayes: {acc_nb:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50bd09f2",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Czy to dobrze? BiorÄ…c pod uwagÄ™, Å¼e losowe strzelanie daÅ‚oby 50%, a ludzie w sumie siÄ™ z grubsza zgadzajÄ… w ocenach filmÃ³w moÅ¼e w \\~90% (sÄ… kontrowersyjne filmy), wynik \\~85% jest caÅ‚kiem niezÅ‚y dla tak prostego modelu. OczywiÅ›cie da siÄ™ lepiej, sprÃ³bujemy to poprawiÄ‡ logisticznÄ….\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa35b400",
   "metadata": {},
   "source": [
    "\n",
    "### Analiza wynikÃ³w i macierz pomyÅ‚ek\n",
    "\n",
    "Sam accuracy to nie wszystko. Warto zobaczyÄ‡ **macierz pomyÅ‚ek (confusion matrix)**, by wiedzieÄ‡, gdzie model siÄ™ myliÅ‚ najczÄ™Å›ciej â€“ czy czÄ™Å›ciej bierze pozytywne za negatywne czy odwrotnie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83006f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Oblicz macierz pomyÅ‚ek\n",
    "cm = confusion_matrix(y_test, y_pred_nb)\n",
    "print(\"Macierz pomyÅ‚ek (NB):\\n\", cm)\n",
    "\n",
    "# ZakÅ‚adamy, Å¼e klasy sÄ… oznaczone jako unikalne wartoÅ›ci z y_test\n",
    "classes = np.unique(y_test)\n",
    "\n",
    "# Wizualizacja macierzy pomyÅ‚ek jako heatmap z uÅ¼yciem seaborn\n",
    "plt.figure(figsize=(6, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=classes, yticklabels=classes)\n",
    "plt.title(\"Macierz pomyÅ‚ek (NB)\")\n",
    "plt.xlabel(\"Predykcja\")\n",
    "plt.ylabel(\"Rzeczywista wartoÅ›Ä‡\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43b197d",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Interpretacja macierzy pomyÅ‚ek:\n",
    "\n",
    "* Element \\[0,0]: liczba **negatywnych** recenzji poprawnie zaklasyfikowanych jako negatywne (True Negatives).\n",
    "* Element \\[1,1]: liczba **pozytywnych** recenzji poprawnie zaklasyfikowanych jako pozytywne (True Positives).\n",
    "* Element \\[0,1]: liczba negatywnych recenzji bÅ‚Ä™dnie zaklasyfikowanych jako pozytywne (False Positives).\n",
    "* Element \\[1,0]: liczba pozytywnych recenzji bÅ‚Ä™dnie zaklasyfikowanych jako negatywne (False Negatives)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6d6a85",
   "metadata": {},
   "source": [
    "\n",
    "Idealny model miaÅ‚by tylko przekÄ…tnÄ… niezerowÄ…. U nas pewnie pomyÅ‚ki bÄ™dÄ… w obu kategoriach. MoÅ¼na policzyÄ‡ np. *precision* i *recall* kaÅ¼dej klasy, ale nie zagÅ‚Ä™biajmy siÄ™ â€“ przy symetrycznych kosztach bÅ‚Ä™du i zbalansowanych klasach accuracy wystarczy.\n",
    "\n",
    "**Pytanie:** JeÅ›li zobaczysz, Å¼e np. \\[0,1] (FN) jest wiÄ™ksze od \\[1,0] (FP), co to oznacza? (Np. model czÄ™Å›ciej myli siÄ™ myÅ›lÄ…c, Å¼e negatywna recenzja jest pozytywna, niÅ¼ odwrotnie). Z czego to moÅ¼e wynikaÄ‡? *(To pytanie otwarte, pomyÅ›l - moÅ¼e model ma \"tendencjÄ™\" do przewidywania jednej klasy? MoÅ¼na by to powiÄ…zaÄ‡ np. z proporcjami klas w treningu lub specyfikÄ… danych).*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8ae27c",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Regresja logistyczna â€“ intuicja\n",
    "\n",
    "![Linear Regression vs Logistic Regression - Tpoint Tech](https://d2jdgazzki9vjm.cloudfront.net/tutorial/machine-learning/images/linear-regression-vs-logistic-regression.png \"Linear Regression vs Logistic Regression - Tpoint Tech\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb97bcf3",
   "metadata": {},
   "source": [
    "\n",
    "**Regresja logistyczna** to rÃ³wnieÅ¼ model liniowy, ale zamiast zakÅ‚adaÄ‡ rozkÅ‚ady jak NB, bezpoÅ›rednio uczy siÄ™ funkcji ğ‘“(cechy) â†’ prawdopodobieÅ„stwo klasy.\n",
    "\n",
    "Wersja binarna (dwie klasy) regresji logistycznej:\n",
    "\n",
    "* Model przypisuje kaÅ¼demu sÅ‚owu (cecha) pewnÄ… **waga** â€“ liczba dodatnia lub ujemna.\n",
    "* Suma (waÅ¼ona) wszystkich cech w dokumencie daje wynik, ktÃ³ry przeksztaÅ‚camy funkcjÄ… sigmoid w zakres \\[0,1] â€“ to jest przewidywane prawdopodobieÅ„stwo klasy pozytywnej.\n",
    "* JeÅ›li to prawdopodobieÅ„stwo > 0.5 (zazwyczaj), model klasyfikuje jako pozytywny, inaczej negatywny."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef19af19",
   "metadata": {},
   "source": [
    "\n",
    "Te wagi sÄ… optymalizowane na zbiorze treningowym tak, by maksymalizowaÄ‡ poprawnoÅ›Ä‡. Np. model moÅ¼e nauczyÄ‡ siÄ™ wagi +2 dla sÅ‚owa \"great\" (sprzyja pozytywnej) i wagi -3 dla \"boring\" (sprzyja negatywnej), itd., oraz pewnego progu bazowego.\n",
    "\n",
    "Regresja logistyczna nie zakÅ‚ada niezaleÅ¼noÅ›ci cech â€“ w zasadzie kaÅ¼da cecha ma wÅ‚asnÄ… wagÄ™, wiÄ™c moÅ¼e trochÄ™ lepiej wykorzystaÄ‡ sytuacje, gdy pewne sÅ‚owa wystÄ™pujÄ… razem (chociaÅ¼ to wciÄ…Å¼ model liniowy, wiÄ™c nie modeluje *interakcji* miÄ™dzy sÅ‚owami bezpoÅ›rednio, ale moÅ¼e Å‚Ä…czyÄ‡ wagi).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030e3951",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "Trenowanie regresji logist. polega na iteracyjnym dostrajaniu wag (z uÅ¼yciem np. algorytmu gradientowego). To moÅ¼e zajÄ…Ä‡ nieco wiÄ™cej czasu niÅ¼ NB, zwÅ‚aszcza na 25k dokumentach i 5000 cech. Warto wiÄ™c:\n",
    "\n",
    "* ByÄ‡ moÅ¼e ograniczyÄ‡ liczbÄ™ iteracji (parametr `max_iter`).\n",
    "* Ewentualnie uÅ¼yÄ‡ tylko czÄ™Å›ci cech (ale my juÅ¼ ograniczyliÅ›my do 5000).\n",
    "* MonitorowaÄ‡, czy model siÄ™ zbiega (czasami ostrzega o braku zbieÅ¼noÅ›ci â€“ wtedy zwiÄ™kszamy `max_iter`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37b71e0",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Trenowanie modelu logistycznego\n",
    "\n",
    "Skorzystamy z `LogisticRegression` z scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750b18ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_model = LogisticRegression(max_iter=200)\n",
    "log_model.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220acaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_model.n_iter_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859c5133",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "JeÅ›li pojawi siÄ™ ostrzeÅ¼enie o konwergencji, moÅ¼na zwiÄ™kszyÄ‡ `max_iter` np. do 300 czy 500. 200 zazwyczaj wystarcza dla tego rozmiaru problemu, ale zaleÅ¼y od parametrÃ³w domyÅ›lnych.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f48c775",
   "metadata": {},
   "source": [
    "Po wytrenowaniu, wykonajmy predykcjÄ™ i policzmy accuracy:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd03b1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_log = log_model.predict(X_test_tfidf)\n",
    "acc_log = accuracy_score(y_test, y_pred_log)\n",
    "print(f\"DokÅ‚adnoÅ›Ä‡ (accuracy) Logistic Regression: {acc_log:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d5d063",
   "metadata": {},
   "source": [
    "SprawdÅºmy macierz pomyÅ‚ek dla LR:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a468c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_log = confusion_matrix(y_test, y_pred_log)\n",
    "print(\"Macierz pomyÅ‚ek (LR):\\n\", cm_log)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb16b7e5",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "PorÃ³wnaj z macierzÄ… NB â€“ czy ktÃ³ryÅ› model popeÅ‚nia wyraÅºnie mniej bÅ‚Ä™dÃ³w okreÅ›lonego typu?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c55a12",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Analiza i porÃ³wnanie modeli\n",
    "\n",
    "Teraz mamy wyniki dwÃ³ch modeli:\n",
    "\n",
    "* **Naive Bayes**\n",
    "* **Logistic Regression**\n",
    "\n",
    "MoÅ¼emy je bezpoÅ›rednio porÃ³wnaÄ‡ â€“ LR wyszedÅ‚ nieco lepszy. CzÄ™sto tak bywa, bo LR moÅ¼e bardziej dostosowaÄ‡ siÄ™ do danych kosztem dÅ‚uÅ¼szego treningu. NB jest jednak prosty i bywa lepszy przy mniejszych danych.\n",
    "\n",
    "Ciekawe moÅ¼e byÄ‡ teÅ¼ sprawdzenie kilku **przykÅ‚adowych predykcji** â€“ weÅºmy parÄ™ recenzji z testu i zobaczmy, co modele przewidziaÅ‚y, a jaka jest prawda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762aff7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WeÅºmy kilka losowych indeksÃ³w\n",
    "indices = [0, 1, 2, 100, 101, 20000]  # przykÅ‚adowe indeksy (moÅ¼esz zmieniÄ‡ lub losowaÄ‡)\n",
    "for i in indices:\n",
    "    text = df_test['text'].iloc[i]\n",
    "    true_label = y_test[i]\n",
    "    pred_nb = y_pred_nb[i]\n",
    "    pred_log = y_pred_log[i]\n",
    "    print(f\"Recenzja: {text[:200]}...\")  # skracamy dla czytelnoÅ›ci\n",
    "    print(f\"   Prawdziwa etykieta: {true_label} | NB przewidziaÅ‚: {pred_nb} | LR przewidziaÅ‚a: {pred_log} \\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c12cf16",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Przejrzyj te wyniki:\n",
    "\n",
    "* Zobacz, gdzie model siÄ™ pomyliÅ‚ (true\\_label != przewidywanie). Przeczytaj fragment recenzji â€“ czy zawiera jakieÅ› sÅ‚owa, ktÃ³re mogÅ‚y zmyliÄ‡ model? Np. recenzja negatywna moÅ¼e zawieraÄ‡ zdanie \"It was a good attempt but overall boring\" â€“ zawiera sÅ‚owo \"good\", ktÃ³re NB mÃ³gÅ‚ przeceniÄ‡.\n",
    "* Czy sÄ… rÃ³Å¼nice miÄ™dzy NB a LR? MoÅ¼e ktÃ³ryÅ› poprawnie, a drugi Åºle w pewnych przypadkach.\n",
    "\n",
    "To daje pewnÄ… intuicjÄ™, co modele \"myÅ›lÄ…\". PamiÄ™taj, Å¼e oba modele sÄ… doÅ›Ä‡ *\"gÅ‚upie\"* w tym sensie, Å¼e patrzÄ… tylko na worek sÅ‚Ã³w. Nie rozumiejÄ… ironii, negacji w kontekÅ›cie (poza sÅ‚owem \"not\" jeÅ›li je uwzglÄ™dnimy, NB i LR wiedzÄ… Å¼e \"not\" czÄ™sto sygnalizuje negatyw, ale zdanie \"not bad\" to pozytywne znaczenie, a model moÅ¼e uznaÄ‡ \"not\" i \"bad\" oba za sygnaÅ‚y negatywu niezaleÅ¼nie)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54501287",
   "metadata": {},
   "source": [
    "## Zastosowanie modelu do nowych przykÅ‚adÃ³w\n",
    "\n",
    "Na koniec zobaczmy, jak uÅ¼yÄ‡ wytrenowanych modeli do oceny nowych tekstÃ³w spoza naszego zbioru.\n",
    "\n",
    "Napiszmy funkcjÄ™ pomocniczÄ…, ktÃ³ra weÅºmie tekst (np. recenzjÄ™), przetworzy go tak samo jak dane treningowe i wydrukuje przewidywany sentyment.\n",
    "\n",
    "PoniewaÅ¼ nasz `tfidf_vectorizer` byÅ‚ trenowany na danych angielskich IMDb, najlepiej podawaÄ‡ mu teksty angielskie o podobnej tematyce (recenzje filmÃ³w). Dla testu moÅ¼emy sprÃ³bowaÄ‡ rÃ³wnieÅ¼ z polskim tekstem â€“ zobaczymy, Å¼e raczej nie zadziaÅ‚a sensownie, bo sÅ‚Ã³w nie bÄ™dzie w sÅ‚owniku.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88e290d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(text: str):\n",
    "    # PrzeksztaÅ‚cenie tekstu za pomocÄ… tego samego wektoryzatora TF-IDF\n",
    "    text_vector = tfidf_vectorizer.transform([text])\n",
    "    # Predykcja NB i LR\n",
    "    pred_nb = nb_model.predict(text_vector)[0]\n",
    "    pred_log = log_model.predict(text_vector)[0]\n",
    "    # PrawdopodobieÅ„stwo pozytywnej klasy wg LR (nb ma swoje, ale trudno je porÃ³wnywaÄ‡ bezkontekstowo)\n",
    "    prob_log = log_model.predict_proba(text_vector)[0,1]\n",
    "    # WyÅ›wietlenie wyniku\n",
    "    sentiment_nb = \"pozytywna\" if pred_nb == 1 else \"negatywna\"\n",
    "    sentiment_log = \"pozytywna\" if pred_log == 1 else \"negatywna\"\n",
    "    print(f\"Tekst: {text}\")\n",
    "    print(f\"   NB: {sentiment_nb}, LR: {sentiment_log} (P(positive)={prob_log:.2f})\")\n",
    "\n",
    "# Przetestujmy na kilku zdaniach:\n",
    "predict_sentiment(\"This movie was absolutely fantastic! I loved it.\")\n",
    "predict_sentiment(\"Boring film. Waste of time... I do not recommend.\")\n",
    "predict_sentiment(\"It had some good moments, but overall it was disappointing.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00968aab",
   "metadata": {},
   "source": [
    "SprÃ³buj wymyÅ›liÄ‡ wÅ‚asne krÃ³tkie recenzje i zobacz, co wyjdzie:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b895a127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: zmieÅ„ teksty poniÅ¼ej na wÅ‚asne i sprawdÅº wyniki\n",
    "predict_sentiment(\"The story was not bad, but not great either.\")\n",
    "predict_sentiment(\"One of the best movies I've ever seen!!!\")\n",
    "predict_sentiment(\"It was a movie. The actors spoke and there was music.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5d75b5",
   "metadata": {},
   "source": [
    "JeÅ›li sprÃ³bujesz z polskim tekstem:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d48b728",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_sentiment(\"Ten film byÅ‚ naprawdÄ™ Å›wietny! ChÄ™tnie obejrzÄ™ go ponownie.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f428952a",
   "metadata": {},
   "source": [
    "\n",
    "prawdopodobnie model nie rozpozna sÅ‚Ã³w (\"film\" moÅ¼e akurat jest teÅ¼ w angielskim, ale \"Å›wietny\" na pewno nie) â€“ wiÄ™kszoÅ›Ä‡ cech wyjdzie 0, wiÄ™c model moÅ¼e daÄ‡ przewidywanie bazujÄ…ce na biasie (prawdopodobnie uzna np. negatywny, bo nie znalazÅ‚ pozytywnych sÅ‚Ã³w znanych mu). To pokazuje, Å¼e model dziaÅ‚a tylko w zakresie jÄ™zyka i sÅ‚ownictwa, na ktÃ³rym zostaÅ‚ nauczony.\n",
    "\n",
    "**Wniosek:** Nasz model angielski nie zrozumie polskiego zdania i vice versa. Dlatego budujÄ…c systemy na rÃ³Å¼ne rynki jÄ™zykowe, trzeba trenowaÄ‡ osobne modele lub wielojÄ™zyczne podejÅ›cia (to bardziej skomplikowane).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30c9c58",
   "metadata": {},
   "source": [
    "\n",
    "## Ä†wiczenia i pomysÅ‚y do samodzielnego sprawdzenia\n",
    "\n",
    "MoÅ¼esz teraz poeksperymentowaÄ‡, aby lepiej poznaÄ‡ temat:\n",
    "\n",
    "1. **Bag-of-Words vs TF-IDF:** SprÃ³buj wytrenowaÄ‡ modele NB i LR na surowych cechach BoW (np. uÅ¼yj `X_train_bow` zamiast `X_train_tfidf`). PorÃ³wnaj wyniki. Czy TF-IDF poprawiÅ‚o wynik? KtÃ³ry model bardziej zyskaÅ‚ na TF-IDF?\n",
    "2. **Zmiana liczby cech:** Wektor TF-IDF, ktÃ³ry zbudowaliÅ›my, miaÅ‚ ograniczenie do 5000 cech. SprÃ³buj zwiÄ™kszyÄ‡ do 10Â 000 lub uÅ¼yÄ‡ peÅ‚nego sÅ‚ownika (usunÄ…Ä‡ `max_features` w `TfidfVectorizer`). Uwaga: wiÄ™cej cech moÅ¼e wydÅ‚uÅ¼yÄ‡ trening. SprawdÅº, czy accuracy roÅ›nie, maleje czy pozostaje podobne.\n",
    "3. **Dodanie n-gramÃ³w:** DotÄ…d uÅ¼ywaliÅ›my pojedynczych sÅ‚Ã³w jako cechy. `TfidfVectorizer` pozwala uwzglÄ™dniÄ‡ n-gramy (sekwekcje sÅ‚Ã³w). Ustaw `ngram_range=(1,2)` aby dodaÄ‡ bigramy (pary sÅ‚Ã³w). Wytrenowanie modelu z bigramami moÅ¼e wychwyciÄ‡ np. frazy \"not good\" jako osobnÄ… cechÄ™. SprawdÅº, czy to poprawi wyniki.\n",
    "4. **Inny algorytm:** SprÃ³buj innego modelu klasyfikacji, np. SVM (`sklearn.svm.LinearSVC`) lub drzewo decyzyjne (`sklearn.tree.DecisionTreeClassifier`). PorÃ³wnaj ich skutecznoÅ›Ä‡ i czas trenowania z NB i LR.\n",
    "5. **Klasy wielokrotne:** JeÅ¼eli masz drugi zbiÃ³r danych z wiÄ™cej niÅ¼ dwiema klasami (np. **PolEmo 2.0**: plus, minus, zero, amb), sprÃ³buj zbudowaÄ‡ model 4-klasowy na nim. NB i LR potrafiÄ… obsÅ‚uÅ¼yÄ‡ multi-klasy (LR domyÅ›lnie uÅ¼ywa strategii one-vs-rest). SprawdÅº confusion matrix â€“ czy model gÅ‚Ã³wnie myli neutralne z negatywnymi, itp.? (WiÄ™cej klas to trudniejsze zadanie!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f3110a",
   "metadata": {},
   "source": [
    "\n",
    "**Wykonaj przynajmniej czÄ™Å›Ä‡ z powyÅ¼szych i zanotuj wnioski.** PamiÄ™taj, Å¼e eksperymenty mogÄ… trochÄ™ potrwaÄ‡ (szczegÃ³lnie SVM lub duÅ¼a liczba cech).\n",
    "\n",
    "*(MoÅ¼esz wykorzystaÄ‡ poniÅ¼sze komÃ³rki do eksperymentÃ³w.)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f618e652",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TODO: Eksperyment 1 - PorÃ³wnanie NB/LR na BoW vs TF-IDF\n",
    "\n",
    "# TODO: Eksperyment 2 - ZwiÄ™kszenie liczby cech\n",
    "\n",
    "# TODO: Eksperyment 3 - Dodanie bigramÃ³w do cech\n",
    "\n",
    "# TODO: Eksperyment 4 - WyprÃ³bowanie innego algorytmu (np. SVM)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160428f4",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "## Podsumowanie\n",
    "\n",
    "NauczyliÅ›my siÄ™ trenowaÄ‡ modele klasyczne do analizy sentymentu:\n",
    "\n",
    "* **Multinomial Naive Bayes** â€“ szybki, oparty na prawdopodobieÅ„stwach sÅ‚Ã³w, caÅ‚kiem skuteczny przy niezbyt duÅ¼ej liczbie danych.\n",
    "* **Regresja Logistyczna** â€“ model liniowy uczÄ…cy siÄ™ wag cech, zazwyczaj dajÄ…cy wysokÄ… skutecznoÅ›Ä‡ kosztem dÅ‚uÅ¼szego treningu.\n",
    "\n",
    "Oba modele uzyskaÅ‚y dokÅ‚adnoÅ›Ä‡ w okolicach 85-90% na naszym zbiorze testowym IMDb, co jest przyzwoitym wynikiem. W praktyce moÅ¼na by sprÃ³bowaÄ‡ poprawiÄ‡ go:\n",
    "\n",
    "* DodajÄ…c wiÄ™cej danych treningowych (nasze 25k to juÅ¼ sporo, ale zawsze moÅ¼na mieÄ‡ wiÄ™cej).\n",
    "* StosujÄ…c bardziej zÅ‚oÅ¼one modele (np. ensemble modeli lub sieci neuronowe).\n",
    "* UdoskonalajÄ…c cechy (np. uwzglÄ™dniajÄ…c bigramy, lepsze przetwarzanie negacji, itp.).\n",
    "\n",
    "Kluczowe wnioski:\n",
    "\n",
    "* **Pipeline NLP**: surowy tekst â†’ przetwarzanie (clean, tokenizacja, stopwords, etc.) â†’ wektor cech â†’ model ML â†’ przewidywanie.\n",
    "* Model trzeba dobraÄ‡ do problemu i danych. Naiwny Bayes sprawdzi siÄ™, gdy cechy sÄ… doÅ›Ä‡ niezaleÅ¼ne, regresja logistyczna poradzi sobie z korelacjami lepiej.\n",
    "* Ocena modelu powinna byÄ‡ przeprowadzona na **oddzielnym zbiorze testowym**, by mieÄ‡ pewnoÅ›Ä‡, Å¼e model generalizuje, a nie tylko nauczyÅ‚ siÄ™ na pamiÄ™Ä‡ danych treningowych.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810c79b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872165da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e75c92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d89915",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fdf699",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c47d8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181df77f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": ".VENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
