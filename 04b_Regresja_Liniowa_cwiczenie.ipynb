{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41b04b76",
   "metadata": {},
   "source": [
    "# üìä ƒÜwiczenia: Regresja Liniowa\n",
    "\n",
    "**Cel:** Praktyczne zastosowanie algorytm√≥w regresji liniowej na rzeczywistych danych\n",
    "\n",
    "**Dataset:** Student Performance Dataset - zawiera informacje o wynikach uczni√≥w wraz z r√≥≈ºnymi czynnikami, kt√≥re mogƒÖ wp≈Çywaƒá na ich osiƒÖgniƒôcia akademickie.\n",
    "\n",
    "## üéØ Cel biznesowy\n",
    "Jako analityk danych w instytucji edukacyjnej, Twoim zadaniem jest zbudowanie modelu, kt√≥ry bƒôdzie przewidywa≈Ç wyniki uczni√≥w na podstawie r√≥≈ºnych czynnik√≥w. Pomo≈ºe to w:\n",
    "- Identyfikacji uczni√≥w zagro≈ºonych s≈Çabymi wynikami\n",
    "- Optymalizacji program√≥w wsparcia\n",
    "- Zrozumieniu kluczowych czynnik√≥w wp≈ÇywajƒÖcych na sukces akademicki\n",
    "\n",
    "---\n",
    "\n",
    "**Instrukcja:** Uzupe≈Çnij kod w miejscach oznaczonych `# TODO:`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e55c1a6",
   "metadata": {},
   "source": [
    "## üìã Spis tre≈õci\n",
    "\n",
    "1. [Wczytanie i eksploracja danych](#1-wczytanie-i-eksploracja-danych)\n",
    "2. [Przygotowanie danych](#2-przygotowanie-danych)\n",
    "3. [Regresja liniowa - podstawy](#3-regresja-liniowa---podstawy)\n",
    "4. [Regresja wielokrotna](#4-regresja-wielokrotna)\n",
    "5. [Regularyzacja (Ridge & Lasso)](#5-regularyzacja-ridge--lasso)\n",
    "6. [Ewaluacja modeli](#6-ewaluacja-modeli)\n",
    "7. [Walidacja krzy≈ºowa](#7-walidacja-krzy≈ºowa)\n",
    "8. [Analiza wynik√≥w](#8-analiza-wynik√≥w)\n",
    "9. [Zadania dodatkowe](#9-zadania-dodatkowe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a512b0ae",
   "metadata": {},
   "source": [
    "## 1. Wczytanie i eksploracja danych\n",
    "\n",
    "### Zadanie 1.1: Import bibliotek i wczytanie danych\n",
    "Zaimportuj niezbƒôdne biblioteki i wczytaj dataset Student_Performance.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce60ee0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Zaimportuj niezbƒôdne biblioteki\n",
    "# Potrzebujesz: pandas, numpy, matplotlib, seaborn, sklearn\n",
    "\n",
    "\n",
    "# TODO: Wczytaj dataset Student_Performance.csv z folderu datasets/\n",
    "df = None\n",
    "\n",
    "# TODO: Wy≈õwietl podstawowe informacje o datasecie\n",
    "# - pierwsze 5 wierszy\n",
    "# - kszta≈Çt datasetu\n",
    "# - informacje o kolumnach i typach danych\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838bcf78",
   "metadata": {},
   "source": [
    "### Zadanie 1.2: Eksploracja struktury danych\n",
    "Przeanalizuj strukƒô danych i zidentyfikuj zmienne numeryczne i kategoryczne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e3a0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Sprawd≈∫ brakujƒÖce warto≈õci\n",
    "\n",
    "\n",
    "# TODO: Wy≈õwietl statystyki opisowe dla zmiennych numerycznych\n",
    "\n",
    "\n",
    "# TODO: Zidentyfikuj kolumny kategoryczne i numeryczne\n",
    "categorical_columns = None\n",
    "numerical_columns = None\n",
    "\n",
    "print(f\"Kolumny kategoryczne: {categorical_columns}\")\n",
    "print(f\"Kolumny numeryczne: {numerical_columns}\")\n",
    "\n",
    "# TODO: Dla ka≈ºdej kolumny kategorycznej wy≈õwietl unikalne warto≈õci\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777f6f18",
   "metadata": {},
   "source": [
    "### Zadanie 1.3: Analiza zmiennej docelowej\n",
    "Przeanalizuj rozk≈Çad zmiennej, kt√≥rƒÖ bƒôdziemy przewidywaƒá"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff7ee0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Zidentyfikuj zmiennƒÖ docelowƒÖ (kt√≥rƒÖ chcemy przewidywaƒá)\n",
    "# Wskaz√≥wka: sprawd≈∫ nazwy kolumn i wybierz tƒô, kt√≥ra reprezentuje wyniki/oceny uczni√≥w\n",
    "target_column = None  # np. 'FinalGrade' lub podobna\n",
    "\n",
    "print(f\"Wybrana zmienna docelowa: {target_column}\")\n",
    "\n",
    "# TODO: Przeanalizuj rozk≈Çad zmiennej docelowej\n",
    "# - statystyki opisowe\n",
    "# - histogram\n",
    "# - sprawd≈∫ czy sƒÖ warto≈õci odstajƒÖce\n",
    "\n",
    "\n",
    "# TODO: Sprawd≈∫ czy zmienna docelowa ma rozk≈Çad normalny\n",
    "# U≈ºyj histogramu z krzywƒÖ KDE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a955f1",
   "metadata": {},
   "source": [
    "### Zadanie 1.4: Analiza korelacji\n",
    "Przebadaj zale≈ºno≈õci miƒôdzy zmiennymi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5960a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Oblicz macierz korelacji dla zmiennych numerycznych\n",
    "\n",
    "\n",
    "# TODO: Stw√≥rz heatmapƒô korelacji\n",
    "# U≈ºyj seaborn.heatmap z odpowiednimi parametrami (annot=True, cmap='coolwarm')\n",
    "\n",
    "\n",
    "# TODO: Znajd≈∫ zmienne najbardziej skorelowane ze zmiennƒÖ docelowƒÖ\n",
    "# Wy≈õwietl korelacje posortowane malejƒÖco\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07225e9",
   "metadata": {},
   "source": [
    "## 2. Przygotowanie danych\n",
    "\n",
    "### Zadanie 2.1: Czyszczenie danych\n",
    "Przygotuj dane do modelowania"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eadbb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Obs≈Çu≈º brakujƒÖce warto≈õci\n",
    "# Sprawd≈∫ czy sƒÖ brakujƒÖce warto≈õci i zdecyduj jak je obs≈Çu≈ºyƒá\n",
    "\n",
    "\n",
    "# TODO: Usu≈Ñ duplikaty je≈õli istniejƒÖ\n",
    "\n",
    "\n",
    "# TODO: Sprawd≈∫ i obs≈Çu≈º warto≈õci odstajƒÖce\n",
    "# U≈ºyj metody IQR lub Z-score dla zmiennej docelowej\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee21082b",
   "metadata": {},
   "source": [
    "### Zadanie 2.2: Kodowanie zmiennych kategorycznych\n",
    "Przekszta≈Çƒá zmienne kategoryczne na numeryczne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9840443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Zaimportuj niezbƒôdne funkcje do kodowania\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# TODO: Dla zmiennych binarnych u≈ºyj LabelEncoder\n",
    "# TODO: Dla zmiennych z wieloma kategoriami u≈ºyj OneHotEncoder\n",
    "\n",
    "# Przyk≈Çad struktury (dostosuj do swoich danych):\n",
    "# binary_columns = []  # kolumny binarne (np. 'Gender')\n",
    "# categorical_columns_multi = []  # kolumny z wieloma kategoriami\n",
    "\n",
    "# TODO: Zastosuj odpowiednie kodowanie i stw√≥rz nowy DataFrame\n",
    "df_encoded = df.copy()\n",
    "\n",
    "print(f\"Kszta≈Çt danych po kodowaniu: {df_encoded.shape}\")\n",
    "print(f\"Nowe kolumny: {df_encoded.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614abf13",
   "metadata": {},
   "source": [
    "### Zadanie 2.3: Podzia≈Ç danych\n",
    "Podziel dane na zbiory treningowy i testowy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813dcadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Zaimportuj train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# TODO: Zdefiniuj zmienne obja≈õniajƒÖce (X) i zmiennƒÖ docelowƒÖ (y)\n",
    "X = None  # wszystkie kolumny opr√≥cz zmiennej docelowej\n",
    "y = None  # zmienna docelowa\n",
    "\n",
    "print(f\"Kszta≈Çt X: {X.shape}\")\n",
    "print(f\"Kszta≈Çt y: {y.shape}\")\n",
    "\n",
    "# TODO: Podziel dane na zbiory treningowy i testowy (80/20)\n",
    "# U≈ºyj random_state=42 dla reprodukowalno≈õci\n",
    "X_train, X_test, y_train, y_test = None, None, None, None\n",
    "\n",
    "print(f\"Rozmiar zbioru treningowego: {X_train.shape[0]}\")\n",
    "print(f\"Rozmiar zbioru testowego: {X_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff945d3",
   "metadata": {},
   "source": [
    "## 3. Regresja liniowa - podstawy\n",
    "\n",
    "### Zadanie 3.1: Regresja liniowa pojedyncza\n",
    "Zbuduj model regresji liniowej z jednƒÖ zmiennƒÖ obja≈õniajƒÖcƒÖ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18cbe7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Zaimportuj LinearRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "# TODO: Wybierz jednƒÖ zmiennƒÖ najbardziej skorelowanƒÖ ze zmiennƒÖ docelowƒÖ\n",
    "best_feature = None  # nazwa kolumny\n",
    "\n",
    "# TODO: Stw√≥rz dane dla regresji pojedynczej\n",
    "X_single = None  # jedna kolumna\n",
    "y_single = y_train\n",
    "\n",
    "# TODO: Stw√≥rz i wytrenuj model regresji liniowej\n",
    "model_single = LinearRegression()\n",
    "# Wytrenuj model\n",
    "\n",
    "# TODO: Wykonaj predykcje na zbiorze treningowym\n",
    "y_pred_single = None\n",
    "\n",
    "print(f\"U≈ºyta zmienna: {best_feature}\")\n",
    "print(f\"R¬≤ Score: {r2_score(y_single, y_pred_single):.4f}\")\n",
    "print(f\"MSE: {mean_squared_error(y_single, y_pred_single):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e082ba",
   "metadata": {},
   "source": [
    "### Zadanie 3.2: Wizualizacja regresji pojedynczej\n",
    "Utworz wykres pokazujƒÖcy liniƒô regresji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7a3fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Stw√≥rz wykres punktowy pokazujƒÖcy:\n",
    "# - rzeczywiste warto≈õci (scatter plot)\n",
    "# - liniƒô regresji\n",
    "# - dodaj tytu≈Ç, opisy osi i legendƒô\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# TODO: Stw√≥rz wykres\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Scatter plot rzeczywistych warto≈õci\n",
    "\n",
    "# Linia regresji\n",
    "\n",
    "# Formatowanie wykresu\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# TODO: Wy≈õwietl wsp√≥≈Çczynniki modelu\n",
    "print(f\"Wsp√≥≈Çczynnik kierunkowy (slope): {model_single.coef_[0]:.4f}\")\n",
    "print(f\"Punkt przeciƒôcia (intercept): {model_single.intercept_:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e87c34",
   "metadata": {},
   "source": [
    "## 4. Regresja wielokrotna\n",
    "\n",
    "### Zadanie 4.1: Model z wieloma zmiennymi\n",
    "Zbuduj model regresji liniowej wykorzystujƒÖcy wszystkie dostƒôpne zmienne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23dc96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Stw√≥rz model regresji wielokrotnej\n",
    "model_multiple = LinearRegression()\n",
    "\n",
    "# TODO: Wytrenuj model na wszystkich dostƒôpnych zmiennych\n",
    "\n",
    "\n",
    "# TODO: Wykonaj predykcje na zbiorze treningowym i testowym\n",
    "y_train_pred = None\n",
    "y_test_pred = None\n",
    "\n",
    "# TODO: Oblicz metryki dla obu zbior√≥w\n",
    "print(\"=== ZBI√ìR TRENINGOWY ===\")\n",
    "print(f\"R¬≤ Score: {r2_score(y_train, y_train_pred):.4f}\")\n",
    "print(f\"MSE: {mean_squared_error(y_train, y_train_pred):.4f}\")\n",
    "print(f\"MAE: {mean_absolute_error(y_train, y_train_pred):.4f}\")\n",
    "\n",
    "print(\"\\n=== ZBI√ìR TESTOWY ===\")\n",
    "print(f\"R¬≤ Score: {r2_score(y_test, y_test_pred):.4f}\")\n",
    "print(f\"MSE: {mean_squared_error(y_test, y_test_pred):.4f}\")\n",
    "print(f\"MAE: {mean_absolute_error(y_test, y_test_pred):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f8d38f",
   "metadata": {},
   "source": [
    "### Zadanie 4.2: Analiza wa≈ºno≈õci cech\n",
    "Przeanalizuj kt√≥re zmienne majƒÖ najwiƒôkszy wp≈Çyw na predykcje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d94e765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Stw√≥rz DataFrame z wsp√≥≈Çczynnikami modelu\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X_train.columns,\n",
    "    'coefficient': model_multiple.coef_\n",
    "})\n",
    "\n",
    "# TODO: Posortuj wed≈Çug warto≈õci bezwzglƒôdnej wsp√≥≈Çczynnik√≥w\n",
    "feature_importance['abs_coefficient'] = None\n",
    "feature_importance = None  # posortuj\n",
    "\n",
    "print(\"Wa≈ºno≈õƒá cech (wsp√≥≈Çczynniki modelu):\")\n",
    "print(feature_importance)\n",
    "\n",
    "# TODO: Stw√≥rz wykres s≈Çupkowy pokazujƒÖcy wa≈ºno≈õƒá cech\n",
    "plt.figure(figsize=(12, 6))\n",
    "# U≈ºyj pierwszych 10 najwa≈ºniejszych cech\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ca6505",
   "metadata": {},
   "source": [
    "## 5. Regularyzacja (Ridge & Lasso)\n",
    "\n",
    "### Zadanie 5.1: Regresja Ridge\n",
    "Zastosuj regularyzacjƒô Ridge aby zmniejszyƒá overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c41645",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Zaimportuj Ridge\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# TODO: Przeskaluj dane (wa≈ºne dla regularyzacji)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = None\n",
    "X_test_scaled = None\n",
    "\n",
    "# TODO: Stw√≥rz i wytrenuj model Ridge z r√≥≈ºnymi warto≈õciami alpha\n",
    "alphas = [0.1, 1.0, 10.0, 100.0]\n",
    "ridge_results = []\n",
    "\n",
    "for alpha in alphas:\n",
    "    # TODO: Stw√≥rz model Ridge\n",
    "    ridge_model = None\n",
    "    \n",
    "    # TODO: Wytrenuj model\n",
    "    \n",
    "    # TODO: Wykonaj predykcje\n",
    "    y_pred_ridge = None\n",
    "    \n",
    "    # TODO: Oblicz R¬≤ score\n",
    "    r2 = None\n",
    "    \n",
    "    ridge_results.append({\n",
    "        'alpha': alpha,\n",
    "        'r2_score': r2\n",
    "    })\n",
    "    \n",
    "    print(f\"Ridge Alpha {alpha}: R¬≤ = {r2:.4f}\")\n",
    "\n",
    "# TODO: Znajd≈∫ najlepsze alpha\n",
    "best_ridge = max(ridge_results, key=lambda x: x['r2_score'])\n",
    "print(f\"\\nNajlepsze alpha dla Ridge: {best_ridge['alpha']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b969b40",
   "metadata": {},
   "source": [
    "### Zadanie 5.2: Regresja Lasso\n",
    "Zastosuj regularyzacjƒô Lasso do selekcji cech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442c4a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Zaimportuj Lasso\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# TODO: Stw√≥rz i wytrenuj model Lasso z r√≥≈ºnymi warto≈õciami alpha\n",
    "alphas_lasso = [0.01, 0.1, 1.0, 10.0]\n",
    "lasso_results = []\n",
    "\n",
    "for alpha in alphas_lasso:\n",
    "    # TODO: Stw√≥rz model Lasso\n",
    "    lasso_model = None\n",
    "    \n",
    "    # TODO: Wytrenuj model\n",
    "    \n",
    "    # TODO: Wykonaj predykcje\n",
    "    y_pred_lasso = None\n",
    "    \n",
    "    # TODO: Oblicz R¬≤ score\n",
    "    r2 = None\n",
    "    \n",
    "    # TODO: Policz ile cech zosta≈Ço wyzerowanych\n",
    "    non_zero_features = None\n",
    "    \n",
    "    lasso_results.append({\n",
    "        'alpha': alpha,\n",
    "        'r2_score': r2,\n",
    "        'non_zero_features': non_zero_features\n",
    "    })\n",
    "    \n",
    "    print(f\"Lasso Alpha {alpha}: R¬≤ = {r2:.4f}, Niezerowe cechy: {non_zero_features}\")\n",
    "\n",
    "# TODO: Znajd≈∫ najlepsze alpha dla Lasso\n",
    "best_lasso = max(lasso_results, key=lambda x: x['r2_score'])\n",
    "print(f\"\\nNajlepsze alpha dla Lasso: {best_lasso['alpha']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b7258e",
   "metadata": {},
   "source": [
    "### Zadanie 5.3: Por√≥wnanie modeli\n",
    "Por√≥wnaj wyniki wszystkich modeli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1da713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Stw√≥rz najlepsze modele z optymalnym alpha\n",
    "best_ridge_model = Ridge(alpha=best_ridge['alpha'])\n",
    "best_lasso_model = Lasso(alpha=best_lasso['alpha'])\n",
    "\n",
    "# TODO: Wytrenuj najlepsze modele\n",
    "\n",
    "\n",
    "# TODO: Wykonaj predykcje na zbiorze testowym dla wszystkich modeli\n",
    "y_test_pred_linear = model_multiple.predict(X_test)\n",
    "y_test_pred_ridge = None\n",
    "y_test_pred_lasso = None\n",
    "\n",
    "# TODO: Stw√≥rz por√≥wnanie wszystkich modeli\n",
    "models_comparison = pd.DataFrame({\n",
    "    'Model': ['Linear Regression', 'Ridge', 'Lasso'],\n",
    "    'R¬≤ Score': [\n",
    "        r2_score(y_test, y_test_pred_linear),\n",
    "        None,  # Ridge R¬≤\n",
    "        None   # Lasso R¬≤\n",
    "    ],\n",
    "    'MSE': [\n",
    "        mean_squared_error(y_test, y_test_pred_linear),\n",
    "        None,  # Ridge MSE\n",
    "        None   # Lasso MSE\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"Por√≥wnanie modeli na zbiorze testowym:\")\n",
    "print(models_comparison)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae30e48e",
   "metadata": {},
   "source": [
    "## 6. Ewaluacja modeli\n",
    "\n",
    "### Zadanie 6.1: Analiza residu√≥w\n",
    "Przeanalizuj reszty modelu aby sprawdziƒá za≈Ço≈ºenia regresji liniowej"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b528ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Oblicz residua (reszty) dla najlepszego modelu\n",
    "# Wybierz model z najwy≈ºszym R¬≤ score\n",
    "best_model = None  # wybierz najlepszy model\n",
    "y_pred_best = None  # predykcje najlepszego modelu\n",
    "\n",
    "residuals = y_test - y_pred_best\n",
    "\n",
    "# TODO: Stw√≥rz wykres residu√≥w vs predykcje\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# 1. Residua vs Predykcje\n",
    "axes[0, 0].scatter(y_pred_best, residuals, alpha=0.6)\n",
    "axes[0, 0].axhline(y=0, color='r', linestyle='--')\n",
    "axes[0, 0].set_xlabel('Predykcje')\n",
    "axes[0, 0].set_ylabel('Residua')\n",
    "axes[0, 0].set_title('Residua vs Predykcje')\n",
    "\n",
    "# 2. Histogram residu√≥w\n",
    "axes[0, 1].hist(residuals, bins=20, edgecolor='black', alpha=0.7)\n",
    "axes[0, 1].set_xlabel('Residua')\n",
    "axes[0, 1].set_ylabel('Czƒôsto≈õƒá')\n",
    "axes[0, 1].set_title('Rozk≈Çad residu√≥w')\n",
    "\n",
    "# 3. Q-Q plot\n",
    "from scipy import stats\n",
    "stats.probplot(residuals, dist=\"norm\", plot=axes[1, 0])\n",
    "axes[1, 0].set_title('Q-Q Plot')\n",
    "\n",
    "# 4. Rzeczywiste vs Predykcje\n",
    "axes[1, 1].scatter(y_test, y_pred_best, alpha=0.6)\n",
    "axes[1, 1].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
    "axes[1, 1].set_xlabel('Rzeczywiste warto≈õci')\n",
    "axes[1, 1].set_ylabel('Predykcje')\n",
    "axes[1, 1].set_title('Rzeczywiste vs Predykcje')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ad655f",
   "metadata": {},
   "source": [
    "### Zadanie 6.2: Dodatkowe metryki\n",
    "Oblicz dodatkowe metryki ewaluacji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d59ee0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Oblicz dodatkowe metryki\n",
    "from sklearn.metrics import explained_variance_score\n",
    "import numpy as np\n",
    "\n",
    "# TODO: Oblicz wszystkie metryki dla najlepszego modelu\n",
    "metrics = {\n",
    "    'R¬≤ Score': None,\n",
    "    'MSE': None,\n",
    "    'RMSE': None,  # pierwiastek z MSE\n",
    "    'MAE': None,\n",
    "    'Explained Variance': None,\n",
    "    'MAPE': None  # Mean Absolute Percentage Error\n",
    "}\n",
    "\n",
    "# TODO: Oblicz MAPE\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "metrics['MAPE'] = mean_absolute_percentage_error(y_test, y_pred_best)\n",
    "\n",
    "print(\"Szczeg√≥≈Çowe metryki najlepszego modelu:\")\n",
    "for metric, value in metrics.items():\n",
    "    print(f\"{metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1469d108",
   "metadata": {},
   "source": [
    "## 7. Walidacja krzy≈ºowa\n",
    "\n",
    "### Zadanie 7.1: Cross-validation\n",
    "Zastosuj walidacjƒô krzy≈ºowƒÖ dla lepszej oceny modeli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f510a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Zaimportuj funkcje do walidacji krzy≈ºowej\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "\n",
    "# TODO: Zdefiniuj walidacjƒô krzy≈ºowƒÖ\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# TODO: Przetestuj wszystkie modele z walidacjƒÖ krzy≈ºowƒÖ\n",
    "models_to_test = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Ridge': Ridge(alpha=best_ridge['alpha']),\n",
    "    'Lasso': Lasso(alpha=best_lasso['alpha'])\n",
    "}\n",
    "\n",
    "cv_results = {}\n",
    "\n",
    "for name, model in models_to_test.items():\n",
    "    # TODO: Wykonaj walidacjƒô krzy≈ºowƒÖ\n",
    "    # U≈ºyj przeskalowanych danych dla Ridge i Lasso\n",
    "    if name in ['Ridge', 'Lasso']:\n",
    "        scores = None  # cross_val_score z przeskalowanymi danymi\n",
    "    else:\n",
    "        scores = None  # cross_val_score z oryginalnymi danymi\n",
    "    \n",
    "    cv_results[name] = {\n",
    "        'mean_score': scores.mean(),\n",
    "        'std_score': scores.std(),\n",
    "        'scores': scores\n",
    "    }\n",
    "    \n",
    "    print(f\"{name}:\")\n",
    "    print(f\"  ≈öredni R¬≤ Score: {scores.mean():.4f} (+/- {scores.std() * 2:.4f})\")\n",
    "    print(f\"  Wszystkie wyniki: {scores}\")\n",
    "    print()\n",
    "\n",
    "# TODO: Znajd≈∫ najlepszy model na podstawie CV\n",
    "best_cv_model = max(cv_results.items(), key=lambda x: x[1]['mean_score'])\n",
    "print(f\"Najlepszy model (CV): {best_cv_model[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5378b6",
   "metadata": {},
   "source": [
    "## 8. Analiza wynik√≥w\n",
    "\n",
    "### Zadanie 8.1: Wizualizacja por√≥wnania modeli\n",
    "Stw√≥rz wykresy por√≥wnujƒÖce wszystkie modele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9bae15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Stw√≥rz wykres por√≥wnujƒÖcy wyniki CV wszystkich modeli\n",
    "model_names = list(cv_results.keys())\n",
    "mean_scores = [cv_results[name]['mean_score'] for name in model_names]\n",
    "std_scores = [cv_results[name]['std_score'] for name in model_names]\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# 1. Wykres s≈Çupkowy ≈õrednich wynik√≥w CV\n",
    "ax1.bar(model_names, mean_scores, yerr=std_scores, capsize=5, alpha=0.7)\n",
    "ax1.set_ylabel('R¬≤ Score')\n",
    "ax1.set_title('Por√≥wnanie modeli - Walidacja krzy≈ºowa')\n",
    "ax1.set_ylim(0, 1)\n",
    "\n",
    "# Dodaj warto≈õci na s≈Çupkach\n",
    "for i, (mean, std) in enumerate(zip(mean_scores, std_scores)):\n",
    "    ax1.text(i, mean + std + 0.01, f'{mean:.3f}', ha='center')\n",
    "\n",
    "# 2. Box plot wynik√≥w CV\n",
    "cv_scores_list = [cv_results[name]['scores'] for name in model_names]\n",
    "ax2.boxplot(cv_scores_list, labels=model_names)\n",
    "ax2.set_ylabel('R¬≤ Score')\n",
    "ax2.set_title('Rozk≈Çad wynik√≥w CV')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2277e0cc",
   "metadata": {},
   "source": [
    "### Zadanie 8.2: Interpretacja wynik√≥w\n",
    "Przeanalizuj i zinterpretuj otrzymane wyniki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ad5c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Stw√≥rz podsumowanie wynik√≥w\n",
    "print(\"=\" * 60)\n",
    "print(\"                    PODSUMOWANIE ANALIZY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nüéØ DATASET: Student Performance\")\n",
    "print(f\"   - Liczba obserwacji: {len(df)}\")\n",
    "print(f\"   - Liczba cech: {X.shape[1]}\")\n",
    "print(f\"   - Zmienna docelowa: {target_column}\")\n",
    "\n",
    "print(f\"\\nüìä NAJLEPSZY MODEL: {best_cv_model[0]}\")\n",
    "print(f\"   - R¬≤ Score (CV): {best_cv_model[1]['mean_score']:.4f} ¬± {best_cv_model[1]['std_score']:.4f}\")\n",
    "\n",
    "print(f\"\\nüìà KLUCZOWE ZMIENNE (Top 5):\")\n",
    "# TODO: Wy≈õwietl 5 najwa≈ºniejszych cech z najlepszego modelu\n",
    "top_features = feature_importance.head(5)\n",
    "for _, row in top_features.iterrows():\n",
    "    print(f\"   - {row['feature']}: {row['coefficient']:.4f}\")\n",
    "\n",
    "print(f\"\\nüîç WNIOSKI:\")\n",
    "# TODO: Napisz 3-5 wniosk√≥w z analizy\n",
    "print(\"   1. [Tw√≥j wniosek o najlepszym modelu]\")\n",
    "print(\"   2. [Tw√≥j wniosek o najwa≈ºniejszych cechach]\")\n",
    "print(\"   3. [Tw√≥j wniosek o jako≈õci predykcji]\")\n",
    "print(\"   4. [Tw√≥j wniosek o regularyzacji]\")\n",
    "print(\"   5. [Tw√≥j wniosek o zastosowaniu biznesowym]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d89411",
   "metadata": {},
   "source": [
    "## 9. Zadania dodatkowe\n",
    "\n",
    "### üéØ Zadanie Bonus 1: Selekcja cech\n",
    "Zastosuj r√≥≈ºne metody selekcji cech i por√≥wnaj wyniki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd00365d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Zaimportuj narzƒôdzia do selekcji cech\n",
    "from sklearn.feature_selection import SelectKBest, f_regression, RFE\n",
    "\n",
    "# TODO: 1. Univariate Feature Selection\n",
    "selector_k_best = SelectKBest(score_func=f_regression, k=5)\n",
    "# Dopasuj selektor i przekszta≈Çƒá dane\n",
    "\n",
    "# TODO: 2. Recursive Feature Elimination\n",
    "estimator = LinearRegression()\n",
    "selector_rfe = RFE(estimator, n_features_to_select=5)\n",
    "# Dopasuj selektor\n",
    "\n",
    "# TODO: 3. Por√≥wnaj wybrane cechy\n",
    "print(\"Cechy wybrane przez SelectKBest:\")\n",
    "print(\"Cechy wybrane przez RFE:\")\n",
    "\n",
    "# TODO: 4. Przetestuj modele z wybranymi cechami\n",
    "# Stw√≥rz modele regresji z wybranymi cechami i por√≥wnaj wyniki"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5077e8",
   "metadata": {},
   "source": [
    "### üéØ Zadanie Bonus 2: Regresja polinomialna\n",
    "Zbadaj czy dodanie cech wielomianowych poprawi model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29a03e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Zaimportuj PolynomialFeatures\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# TODO: Stw√≥rz pipeline z cechami wielomianowymi\n",
    "# U≈ºyj degree=2 aby nie przesadziƒá z z≈Ço≈ºono≈õciƒÖ\n",
    "poly_pipeline = Pipeline([\n",
    "    ('poly', PolynomialFeatures(degree=2, include_bias=False)),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('regressor', Ridge(alpha=1.0))\n",
    "])\n",
    "\n",
    "# TODO: Wytrenuj model wielomianowy\n",
    "\n",
    "# TODO: Oce≈Ñ model z walidacjƒÖ krzy≈ºowƒÖ\n",
    "\n",
    "# TODO: Por√≥wnaj z poprzednimi modelami\n",
    "print(\"Wyniki regresji wielomianowej:\")\n",
    "print(f\"R¬≤ Score (CV): {poly_scores.mean():.4f} ¬± {poly_scores.std():.4f}\")\n",
    "\n",
    "# TODO: Sprawd≈∫ czy model nie jest overfitted\n",
    "# Por√≥wnaj wyniki na zbiorze treningowym i testowym"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12d6779",
   "metadata": {},
   "source": [
    "### üéØ Zadanie Bonus 3: Hyperparameter tuning\n",
    "Zoptymalizuj hiperparametry najlepszego modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30551451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Zaimportuj GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# TODO: Zdefiniuj przestrze≈Ñ hiperparametr√≥w dla najlepszego modelu\n",
    "# Je≈õli najlepszy to Ridge/Lasso, zoptymalizuj alpha\n",
    "# Je≈õli Linear Regression, mo≈ºesz spr√≥bowaƒá ElasticNet\n",
    "\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "# Przyk≈Çad dla ElasticNet (kombinacja Ridge i Lasso)\n",
    "param_grid = {\n",
    "    'alpha': [0.01, 0.1, 1.0, 10.0],\n",
    "    'l1_ratio': [0.1, 0.3, 0.5, 0.7, 0.9]  # 0=Ridge, 1=Lasso\n",
    "}\n",
    "\n",
    "# TODO: Stw√≥rz GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    ElasticNet(random_state=42),\n",
    "    param_grid,\n",
    "    cv=5,\n",
    "    scoring='r2',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# TODO: Dopasuj na przeskalowanych danych\n",
    "\n",
    "# TODO: Wy≈õwietl najlepsze parametry i wynik\n",
    "print(f\"Najlepsze parametry: {grid_search.best_params_}\")\n",
    "print(f\"Najlepszy wynik CV: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# TODO: Przetestuj najlepszy model na zbiorze testowym"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440f69c1",
   "metadata": {},
   "source": [
    "## üéâNauczy≈Çe≈õ siƒô:\n",
    "\n",
    "‚úÖ **Eksploracji danych** - analizy rozk≈Çad√≥w, korelacji i przygotowania danych\n",
    "\n",
    "‚úÖ **Regresji liniowej** - od prostej regresji pojedynczej do z≈Ço≈ºonych modeli wielokrotnych\n",
    "\n",
    "‚úÖ **Regularyzacji** - technik Ridge i Lasso do kontroli overfittingu\n",
    "\n",
    "‚úÖ **Ewaluacji modeli** - r√≥≈ºnych metryk i technik walidacji\n",
    "\n",
    "‚úÖ **Walidacji krzy≈ºowej** - rzetelnej oceny wydajno≈õci modeli\n",
    "\n",
    "‚úÖ **Interpretacji wynik√≥w** - analizy wsp√≥≈Çczynnik√≥w i wyciƒÖgania wniosk√≥w biznesowych\n",
    "\n",
    "### üí° Nastƒôpne kroki:\n",
    "- Eksperymentuj z innymi algorytmami regresji (Random Forest, SVM)\n",
    "- Spr√≥buj feature engineering (tworzenie nowych cech)\n",
    "- Zastosuj technike ensemble (≈ÇƒÖczenie modeli)\n",
    "- Zbadaj advanced topics: regularyzacja elastyczna, regresja bayesowska\n",
    "\n",
    "### üìö Przydatne zasoby:\n",
    "- [Scikit-learn User Guide](https://scikit-learn.org/stable/user_guide.html)\n",
    "- [\"Hands-On Machine Learning\" - Aur√©lien G√©ron](https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/)\n",
    "- [Kaggle Learn - Intro to Machine Learning](https://www.kaggle.com/learn/intro-to-machine-learning)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
